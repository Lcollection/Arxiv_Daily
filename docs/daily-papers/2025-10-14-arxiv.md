# arxiv 2025-10-14

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| Ev4DGS：基于单目事件流的非刚性物体新视角渲染 | Takuya Nakabayashi | [PDF](http://arxiv.org/pdf/2510.11717v1) | 与传统同步操作的RGB相机相比，事件相机在新视角渲染方面具有多重优势，且近期文献已提出支持刚性场景的高效事件处理技术。然而针对非刚性物体，现有方法仍需依赖稀疏RGB输入，这在实际应用中存在明显局限——仅从事件流中能否学习类似模型仍是未知领域。本文对这一具有挑战性的开放性问题进行探索，首次提出Ev4DGS方法：通过单目事件流在显式观测空间（即RGB或灰度图像）中实现非刚性形变物体的新视角渲染。我们的方法通过以下途径回归可形变3D高斯泼溅表示：1）建立预估模型输出与二维事件观测空间关联的损失函数；2）基于事件生成的二值掩膜训练粗粒度三维形变模型。我们在现有合成数据集与新采集的真实非刚性物体数据集上进行实验对比，结果表明Ev4DGS具有有效性，且优于本设置中多个基线方法的性能。为促进研究，我们将公开评估所用模型与数据集，项目页面详见：https://4dqv.mpi-inf.mpg.de/Ev4DGS/。 |
| CodePlot-CoT：基于代码驱动图像的数学视觉推理方法

（注：该翻译采用学术术语规范，保留原名称"CodePlot-CoT"作为技术专有名词不译，"Thinking with Code-Driven Images"意译为"基于代码驱动图像的推理方法"，既准确传达"通过代码生成的图像进行思维推理"的技术内涵，又符合中文计算机学术论文的标题表述习惯。） | Chengqi Duan | [PDF](http://arxiv.org/pdf/2510.11718v1) | 近年来，大语言模型（LLMs）与视觉语言模型（VLMs）在数学推理领域取得显著进展，但在处理需要视觉辅助的问题时仍面临关键瓶颈——例如需要通过绘制辅助线或函数图像来解题的问题。当前大多数LLMs和VLMs仅限于纯文本推理链，而能够生成图文交织内容的多模态统一模型在此类任务中缺乏必要的精确度与可控性。为此，我们提出CodePlot-CoT——一种面向数学领域“视觉化思考”的代码驱动思维链范式。该方法通过VLM同步生成文本推理与可执行的绘图代码，并将代码渲染为“视觉思维”图像来解决数学问题。

为实现这一目标，我们首先构建了Math-VR——首个面向视觉推理数学问题的大规模双语数据集与基准测试集，包含17.8万样本。其次，为创建高质量训练数据，我们开发了专精于将复杂数学图形解析为代码的尖端图像-代码转换器。最终基于这些训练数据，我们训练出用于解决数学问题的CodePlot-CoT模型。实验结果表明，在我们的新基准测试中，该模型相较基线模型性能提升最高达21%，充分验证了所提出代码驱动推理范式的有效性。

本工作为多模态数学推理开辟了新方向，并为学界提供了首个大规模数据集、综合基准测试体系及强效解决方案。为促进后续研究，我们已将数据集、代码与预训练模型在https://github.com/HKU-MMLab/Math-VR-CodePlot-CoT 开源。 |
| 点提示：基于视频扩散模型的反事实追踪

（翻译说明：
1. 专业术语对应："Point Prompting"译为"点提示"，指通过空间坐标点进行引导的交互方式；"Counterfactual Tracking"译为"反事实追踪"，是计算机视觉中分析假设性场景的追踪技术；"Video Diffusion Models"译为"视频扩散模型"，保持生成式AI领域的标准译法
2. 句式结构：采用中文技术文献常见的"基于...的..."句式，突出方法的核心技术载体
3. 领域适配：整体表述符合计算机视觉与多媒体分析领域的学术表达规范） | Ayush Shrivastava | [PDF](http://arxiv.org/pdf/2510.11715v1) | 追踪器与视频生成器解决的是密切相关的问题：前者分析运动，后者合成运动。我们证明这种关联性使得预训练视频扩散模型能够执行零样本点追踪——只需提示模型在时间维度上可视化标记运动轨迹点即可实现。具体方法是在查询点放置颜色鲜明的标记，然后从中等噪声级别开始重新生成视频剩余部分。这一操作使标记在帧间传递，从而描绘出点的运动轨迹。为确保标记在这种反事实生成过程中保持可见（尽管自然视频中很少出现此类标记），我们使用未经编辑的初始帧作为负向提示。通过对多个图像条件化视频扩散模型的实验，我们发现这些"涌现式"轨迹线优于现有零样本方法，并能持续穿透遮挡物，其表现往往可与专业自监督模型相媲美。 |
| 大型推理模型是否可中断？ | Tsung-Han Wu | [PDF](http://arxiv.org/pdf/2510.11713v1) | 大型推理模型（LRM）在复杂推理任务中表现卓越，但传统评估方式始终基于静态的“冻结世界”设定：假定模型响应瞬时完成，且请求上下文在响应期间保持不变。这种假设虽适用于短期任务，但在现代推理场景（如辅助编程）中明显失效——模型可能耗费数小时进行思考，而从开始推理到最终输出的过程中，代码可能已发生巨大变化。本研究通过两种现实动态场景挑战冻结世界假设：其一是中断测试，即在有限资源下检验模型部分输出的质量；其二是动态上下文测试，即评估模型对实时变化的适应能力。在需要长链条推理的数学与编程基准测试中，静态评估持续高估了模型鲁棒性：即便在静态环境中达到高精度的顶尖LRM，在遭遇中断或面对动态上下文时仍会出现不可预测的失效，当更新发生在推理后期时性能降幅高达60%。我们的分析进一步揭示了若干新型失效模式：包括推理泄漏（模型被中断时将推理过程折叠进最终答案）、恐慌（时间压力下完全放弃推理直接返回错误答案）以及自我怀疑（整合更新信息时性能持续劣化）。 |
| DiT360：通过混合训练实现高保真全景图像生成 | Haoran Feng | [PDF](http://arxiv.org/pdf/2510.11712v1) | 本研究提出DiT360——基于扩散变换器的全景图像生成框架，通过透视数据与全景数据的混合训练解决生成质量中几何保真度与照片真实感的平衡问题。我们认为当前生成质量瓶颈主要源于缺乏大规模高质量真实全景数据集，这种以数据为核心的视角区别于先前聚焦于模型设计的方法。DiT360核心包含跨域转换与域内增强的关键模块，分别作用于VAE前端的图像层级与VAE后端的标记层级。在图像层级，通过透视图像引导与全景精细化注入跨域知识，在提升感知质量的同时规范多样性与照片真实感；在标记层级，采用混合监督机制整合环形填充（保障边界连续性）、偏航损失（增强旋转鲁棒性）和立方体损失（优化畸变感知）等多模块协同优化。在文本生成全景图、图像修复与外延生成任务上的大量实验表明，本方法在十一项量化指标中均实现了更优的边界一致性与图像保真度。代码已开源：https://github.com/Insta360-Research-Team/DiT360。 |
| 用于摊销采样的强化序贯蒙特卡洛方法 | Sanghyeok Choi | [PDF](http://arxiv.org/pdf/2510.11711v1) | 本文提出了一种结合摊还式与基于粒子方法的新策略，用于从非归一化密度函数定义的分布中进行采样。我们建立了序列蒙特卡洛（SMC）与通过最大熵强化学习（MaxEnt RL）训练的神经序列采样器之间的关联——其中习得的采样策略与价值函数分别定义了建议核函数与扭曲函数。基于这一关联，我们引入了一种离策略强化学习训练流程：使用SMC生成的样本（以训练后的采样器作为建议分布）作为行为策略，从而更有效地探索目标分布。我们提出了建议分布与扭曲函数的稳定联合训练技术，以及降低训练信号方差的自适应权重退火方案。此外，针对既往使用经验回放指导神经采样器训练的尝试，我们推导出在回放缓冲区中结合历史样本与退火重要性采样权重的创新方法。通过在连续/离散空间的合成多峰目标分布及丙氨酸二肽构象的玻尔兹曼分布上的实验证明，相较于传统摊还式方法与蒙特卡洛方法，本方法在真实分布逼近精度与训练稳定性方面均展现出显著提升。 |
| 对抗性攻击利用叠加特征间的干扰效应 | Edward Stevinson | [PDF](http://arxiv.org/pdf/2510.11709v1) | 关于神经网络中对抗样本何时以及为何产生的基本问题仍存争议，现有对立观点分别将其描述为决策边界不规则性的产物，或对非稳健输入特征敏感度的结果。本文提出新见解：对抗性漏洞可能源于神经网络的高效信息编码机制。具体而言，我们揭示了“叠加态”——即网络用有限维度表征超额特征时——会形成潜在表征的特定排列，从而被攻击者利用。我们论证了对抗扰动通过利用叠加特征间的干涉效应发挥作用，使得攻击模式可通过特征排列进行预测。本框架为两个已知现象提供了机制性解释：具有相似训练模式模型间的对抗攻击可迁移性，以及特定类别的漏洞模式。在精确控制叠加态的合成环境中，我们证实叠加态足以引发对抗性漏洞。随后在CIFAR-10数据集训练的ViT模型中验证了这些发现的普适性。这些研究结果揭示：对抗性漏洞可能是网络表征压缩的副产品，而非学习过程缺陷或非稳健输入所致。 |
| 贝叶斯拓扑卷积神经网络 | Sarah Harkins Dayton | [PDF](http://arxiv.org/pdf/2510.11704v1) | 卷积神经网络（CNN）已被确立为图像数据处理的主要工具，但其训练需要大量数据，常产生过度自信的预测结果，且往往无法量化预测的不确定性。为解决这些问题，我们提出了一种新型贝叶斯拓扑卷积神经网络，通过拓扑感知学习与贝叶斯采样之间的创新交互机制实现突破。该模型通过提取重要流形信息加速训练过程，同时通过对网络参数设置先验分布并准确学习相应后验分布来降低校准误差。本研究的重要创新在于在学习代价函数中引入一致性条件，该条件能有效修正先验分布以提升新型网络架构的性能。我们在基准图像分类数据集上评估该模型，证明其性能优于传统CNN、贝叶斯神经网络（BNN）及拓扑CNN。特别值得关注的是，我们的方法在训练数据有限或存在噪声的场景中展现出显著优势。此外，相较于标准BNN，新模型能更精准识别未经训练的分布外数据样本，从而提供更优异的不确定性量化能力。研究结果充分证明了这种新型混合方法在实现更高效、更鲁棒的图像分类方面具有巨大潜力。 |
| 揭秘强化学习在自主推理中的应用 | Zhaochen Yu | [PDF](http://arxiv.org/pdf/2510.11701v1) | 近期，具身强化学习的兴起表明强化学习同样能有效提升大语言模型的自主推理能力，但核心设计原则与最佳实践方案仍不明确。本研究通过数据、算法与推理模式三个关键维度，开展全面系统的探索以揭示强化学习在自主推理中的作用机制。我们提炼出以下核心发现：（1）使用真实端到端工具调用轨迹替代拼接式合成轨迹，可形成更强大的监督微调初始化基础；具有高多样性且适配模型特性的数据集能持续促进探索，显著提升强化学习性能。（2）探索友好型技术对具身强化学习至关重要，例如提高奖励裁剪阈值、实施长周期奖励塑形、保持适当策略熵值等技巧可有效提升训练效率。（3）采用精简工具调用的审慎推理策略，相较于频繁工具调用或冗长自我推理更具优势，既能提升工具使用效率又能提高最终准确率。这些简洁实践方案可协同提升自主推理能力与训练效率，使小规模模型在挑战性基准测试中取得优异表现，为未来具身强化学习研究奠定实用基准。除实证发现外，我们进一步贡献了高质量的真实端到端自主监督微调数据集与强化学习数据集，并在AIME2024/AIME2025、GPQA-Diamond及LiveCodeBench-v6四大挑战性基准上验证了所提方案对增强大语言模型自主推理能力的有效性。应用本方案后，40亿参数模型可达成优于320亿参数模型的自主推理性能。代码与模型：https://github.com/Gen-Verse/Open-AgentRL |
| QeRL：超越效率——面向大语言模型的量化增强强化学习 | Wei Huang | [PDF](http://arxiv.org/pdf/2510.11696v1) | 我们提出QeRL——一种面向大语言模型（LLM）的量化增强强化学习框架。尽管强化学习对LLM的推理能力至关重要，但其资源消耗巨大，需要大量GPU内存和长周期的策略展开。QeRL通过融合NVFP4量化技术与低秩自适应（LoRA）方法，在降低内存开销的同时显著加速强化学习的策略展开阶段。除效率提升外，研究发现量化噪声能增加策略熵值，增强探索能力，从而帮助模型在强化学习过程中发现更优策略。为进一步优化探索过程，QeRL引入了自适应量化噪声（AQN）机制，可在训练过程中动态调节噪声强度。实验表明，QeRL在策略展开阶段实现超过1.5倍的加速比。该框架首次实现了320亿参数LLM在单张H100 80GB GPU上的强化学习训练，同时全面提升RL训练速度。相较于16位LoRA和QLoRA，QeRL不仅获得更快的奖励增长曲线和更高最终准确率，在7B模型的数学基准测试（GSM8K达90.8%，MATH 500达77.4%）中更实现了与全参数微调相当的性能。这些成果确立了QeRL作为高效强大LLM强化学习框架的地位。 |
