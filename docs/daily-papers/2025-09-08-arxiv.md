# arxiv 2025-09-08

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| FlowSeek：基于深度基础模型与运动基元的光流计算简化框架

（注：采用学术翻译中常见的"框架/系统"隐性补充译法，保留核心术语"optical flow"译为"光流"，"depth foundation models"译为"深度基础模型"，"motion bases"译为"运动基元"。通过"简化"对应"made easier"的语义，使用冒号结构保持原标题的层次关系，符合中文论文标题的表述规范。） | Matteo Poggi | [PDF](http://arxiv.org/pdf/2509.05297v1) | 我们提出FlowSeek——一种新型光流计算框架，其训练过程仅需极少的硬件资源。该框架将光流网络设计领域的最新进展、前沿的单图像深度基础模型与经典的低维运动参数化方法相结合，构建出结构紧凑却精度优异的架构。FlowSeek仅需使用单张消费级GPU进行训练，硬件需求较现有主流方法降低约8倍，同时在Sintel Final和KITTI数据集上实现了卓越的跨数据集泛化能力：相较于先前最优方法SEA-RAFT分别获得10%和15%的相对性能提升，在Spring和LayeredFlow数据集上也展现出同等优势。 |
| WinT3R：基于窗口式相机令牌池的流式重建方法

（注：翻译采用学术论文标题的规范处理方式：
1. 保留算法名称"WinT3R"的原始大写格式
2. "Window-Based"译为"基于窗口式"符合计算机视觉领域术语惯例
3. "Streaming Reconstruction"译为"流式重建"准确表达实时连续重建的技术含义
4. "Camera Token Pool"译为"相机令牌池"保持计算机视觉与Transformer架构的专业术语一致性
5. 整体采用"方法"作为中文标题的收尾词，符合中文论文标题命名规范） | Zizun Li | [PDF](http://arxiv.org/pdf/2509.05296v1) | 我们提出WinT3R——一种能够在线预测精确相机位姿并生成高质量点云图的前馈式重建模型。现有方法往往面临重建质量与实时性能之间的权衡困境。为解决这一问题，我们首先引入滑动窗口机制，确保窗口内帧间充分的信息交互，从而在不增加大量计算负担的前提下提升几何预测质量。此外，我们采用紧凑的相机参数表示法并维护全局相机令牌池，在不牺牲效率的情况下增强相机位姿估计的可靠性。经多个数据集上的大量实验验证，这些设计使WinT3R在在线重建质量、相机位姿估计精度和重建速度方面均达到最先进性能。代码与模型已开源：https://github.com/LiZizun/WinT3R。

（注：根据学术翻译规范：
1. 专业术语如"feed-forward"译为"前馈式"，"camera poses"译为"相机位姿"，"point maps"译为"点云图"
2. 技术表述采用"滑动窗口机制"、"几何预测"、"相机令牌池"等标准译法
3. 保留项目名称"WinT3R"及开源平台URL的原始形式
4. 使用分号保持长句的逻辑层次，符合中文科技文献表达习惯） |
| 非终止性证明：突破1亿行代码及其超越 | Julien Vanegue | [PDF](http://arxiv.org/pdf/2509.05293v1) | 我们介绍了自主研发的工具Pulse Infinite，该工具采用证明技术来检测大型程序中的非终止（发散）问题。Pulse Infinite采用组合式分析与欠近似验证双轨机制：前者保障分析规模的可扩展性，后者确保发散证明的可靠性。既往研究多聚焦于数十至数百行代码的小型基准测试，规模限制使其实际应用受限——单个企业的代码库可能达到数千万甚至数亿行代码量。我们将Pulse Infinite应用于超过一亿行的C、C++和Hack语言编写的开源及专有软件，成功识别出30余个此前未知的问题，为现实代码库中的发散检测确立了新的技术标杆。 |
| Pinterest广告推荐系统中基于深度强化学习的排序效用调优

（注：该翻译严格遵循学术规范，保留核心术语"Deep Reinforcement Learning"(深度强化学习)、"Ranking Utility Tuning"(排序效用调优)、"Ad Recommender System"(广告推荐系统)的专业译法，同时准确传达介词结构"for...in..."所体现的技术应用关系，符合计算机领域学术文献的标题翻译标准。） | Xiao Yang | [PDF](http://arxiv.org/pdf/2509.05292v1) | 广告推荐系统中的排序效用函数通过线性组合多个业务目标的预测结果，在平衡平台、广告主和用户三方价值方面发挥着核心作用。传统人工调参方法虽然具有简洁性和可解释性，但由于其调优目标缺乏理论依据、参数组合空间巨大，且无法实现个性化及季节性适应，往往导致次优结果。本研究提出一种基于深度强化学习的个性化效用调优通用框架（DRL-PUT），以解决广告推荐系统中多目标优化的挑战。我们的核心贡献包括：1）将问题构建为强化学习任务：根据广告请求状态预测最优超参数，以最大化预设奖励；2）开发直接通过在线服务日志学习最优策略模型的方法，避免估计价值函数——该过程因即时奖励的高方差和分布不均衡而存在固有困难。通过在Pinterest广告推荐系统中进行在线A/B实验评估，与基线人工调参方法相比，DRL-PUT在实验组中将点击率提升9.7%，长点击率提升7.7%。我们针对不同奖励定义的影响进行了详细消融研究，并分析了所学策略模型的个性化特性。 |
| 跨时间编码追踪：大型语言模型预训练中语言表征的涌现与固化过程

（注：翻译严格遵循学术术语规范：
1. "Crosscoding Through Time" 译为"跨时间编码追踪"，体现时序分析特性
2. "Emergence & Consolidation" 采用认知科学标准译法"涌现与固化"
3. "Linguistic Representations" 保留计算语言学领域专业表述"语言表征"
4. "LLM Pretraining" 完整译为"大型语言模型预训练"，避免缩写确保准确性） | Deniz Bayazit | [PDF](http://arxiv.org/pdf/2509.05291v1) | 大型语言模型（LLM）在预训练过程中习得了非平凡的抽象能力，例如检测不规则复数名词主语。然而，由于传统评估方法（如基准测试）难以揭示模型如何习得概念与能力，特定语言能力何时及如何形成尚未得到充分理解。为填补这一空白并在概念层面深入理解模型训练过程，我们采用稀疏交叉编码器来发现并对齐不同模型检查点间的特征。通过这种方法，我们追踪了预训练过程中语言特征的演化轨迹。

我们在性能表现和表征呈现显著跃迁的开源检查点三元组上训练交叉编码器，并引入创新指标——相对间接效应（RelIE），用以追溯个体特征在训练过程中何时开始对任务表现产生关键因果影响。研究表明，交叉编码器能够有效检测预训练期间特征的出现、维持及消失。该方法兼具架构无关性与可扩展性，为在预训练全过程中实现更具可解释性和细粒度的表征学习分析开辟了新路径。 |
| 超越线性与时间同质性：具有时变非线性效应的关系型超事件模型

（注：翻译严格遵循以下原则：
1. 专业术语准确对应："Relational Hyper Event Models"译为"关系型超事件模型"，"Time-Varying Non-Linear Effects"译为"时变非线性效应"
2. 学术表述规范：采用"超越"对应"Beyond"，"时间同质性"对应"Time-homogeneity"
3. 保持原文结构：完整保留冒号的层级关系，准确传达主标题与副标题的逻辑
4. 符合中文科技文献表达习惯：使用"型"字体现模型类别特征，"效应"对应"Effects"的专业译法） | Martina Boschi | [PDF](http://arxiv.org/pdf/2509.05289v1) | 近年来，随着技术的进步，收集具有时间戳的、连接两个或多个实体的大型复杂关系事件网络变得更为便捷。关系超事件模型（RHEMs）旨在通过将事件发生率建模为基于历史数据和外部信息的统计函数，来解释这些事件的动态变化规律。

然而，尽管数据复杂度日益提升，当前大多数RHEM方法仍依赖于线性假设来建模这种关系。本研究通过引入更具灵活性的模型来解决这一局限性，该模型允许统计效应呈现非线性特征并随时间动态变化。虽然时变和非线性效应已在关系事件建模中得到应用，但我们通过使用张量积平滑法对联合时变与非线性的效应进行建模，进一步推动了该领域的发展。

我们通过合成数据和实证数据对方法进行了验证。特别地，我们运用RHEMs研究了科研合作模式与影响力的动态演变规律。该方法能够更深入地解析驱动关系超事件的动态因素，从而帮助我们评估线性模型无法识别的潜在非单调性模式。 |
| 使用图神经网络学习加速分布式ADMM | Henri Doerks | [PDF](http://arxiv.org/pdf/2509.05288v1) | 分布式优化是大规模机器学习与控制应用中的基础技术。在现有方法中，交替方向乘子法（ADMM）因其强大的收敛保证和去中心化计算的适用性而广受欢迎。然而，ADMM通常存在收敛速度慢和对超参数选择敏感的问题。本研究通过将分布式ADMM迭代过程自然映射到图神经网络（GNN）的消息传递框架中，提出采用图神经网络根据迭代状态预测超参数，从而学习自适应步长与通信权重。通过固定次数的ADMM展开迭代，我们对网络参数进行端到端训练，以最小化特定问题类别的最终迭代误差，同时保持算法的收敛特性。数值实验表明，与标准ADMM相比，我们提出的学习版本能持续提升收敛速度和求解质量。代码详见https://github.com/paulhausner/learning-distributed-admm。 |
| 阐明线性注意力中衰减机制的设计空间 | Zhen Qin | [PDF](http://arxiv.org/pdf/2509.05282v1) | 本文对线性复杂度序列模型中固有的衰减机制进行了全面研究。我们系统性地从四个关键维度划分了衰减机制的设计空间：参数化策略，指计算衰减的计算方法；参数共享，涉及使用辅助参数进行衰减计算；衰减粒度，比较标量与基于向量的衰减方式；以及与相对位置编码方法（如旋转位置编码RoPE）的兼容性。通过在多样化语言建模任务上进行的大量实验，我们获得了若干重要发现。首先，衰减参数化策略的设计需要细致考量。研究结果表明，有效配置通常局限于特定参数范围内。其次，参数共享不能随意使用，否则可能导致衰减值过大或过小，从而显著影响模型性能。第三，在相同参数化策略下，标量衰减的表现通常逊于向量衰减。但在采用替代参数化策略的某些场景中，标量衰减反而可能意外超越向量衰减的效果。最后，我们的分析表明，RoPE作为常用的相对位置编码方法，通常无法为大多数线性注意力机制带来实质性提升。 |
| 双分支卷积框架：基于空间与频域的图像伪造检测 | Naman Tyagi | [PDF](http://arxiv.org/pdf/2509.05281v1) | 随着深度伪造和数字图像篡改技术的快速蔓延，确保图像真实性正变得日益困难。本报告提出了一种结合空域与频域特征的伪造检测框架，通过双分支卷积神经网络分别处理从空域和频域提取的特征。两个分支的特征在孪生网络中进行融合比对，生成64维嵌入向量用于分类。在CASIA 2.0数据集上的测试表明，该方法达到77.9%的准确率，优于传统统计方法。尽管相较于更庞大复杂的检测流程性能稍弱，但本方案在计算复杂度与检测可靠性间取得了平衡，具备实际部署条件。该研究为数字图像司法鉴定提供了有效方法论，从更广义层面推动了视觉取证技术的发展，有效应对了媒体验证、执法监督和数字内容可信性评估等领域的迫切需求。 |
| 脉冲大脑技术报告：脉冲式仿脑大模型

（注：此处采用"脉冲"对应"Spiking"的神经科学术语规范，"仿脑"准确传达"Brain-inspired"的仿生学概念，"大模型"符合当前人工智能领域对"Large Models"的标准译法，整体表述既保持学术严谨性又符合中文技术文献的表达习惯。） | Yuqi Pan | [PDF](http://arxiv.org/pdf/2509.05276v1) | Mainstream Transformer-based large language models face major efficiency
bottlenecks: training compu [翻译失败] |
