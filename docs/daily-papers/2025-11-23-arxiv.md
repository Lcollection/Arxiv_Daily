# arxiv 2025-11-23

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 面向预训练自监督视觉模型的数据集蒸馏 | George Cazenavette | [PDF](https://arxiv.org/pdf/2511.16674v1) | 数据集蒸馏任务旨在通过合成少量图像，使得基于这些图像训练的模型能够达到与使用大量真实样本训练时相当的性能。现有蒸馏方法主要聚焦于合成能训练随机初始化模型的数据集，然而当前最先进的视觉方法正日益依赖于大规模预训练的自监督模型，而非从零开始训练。本文研究如何通过蒸馏数据集，在此类大规模预训练视觉模型之上实现线性分类器的最优训练。我们提出名为线性梯度匹配的数据集蒸馏方法，该方法通过优化合成图像，使其经过预训练特征提取器后，在线性分类器中产生的梯度与真实数据产生的梯度相似。我们的方法生成的合成数据表现优于所有真实图像基线，且显著具备跨预训练视觉模型的泛化能力——例如通过DINO骨干网络蒸馏得到的数据集，可训练出具有竞争力的CLIP线性分类器。此外，我们证明所蒸馏的数据集在细粒度分类任务中表现卓越，并为模型可解释性研究提供了重要工具：既能基于理想表征假说预测两个模型嵌入空间的相似度，又能识别模型是否对对抗数据集中的伪相关性敏感。 |
| EvoLMM：基于持续奖励机制的自演进大型多模态模型

解析：
1. "Self-Evolving"译为"自演进" - 准确体现模型具备自主进化能力的技术特性
2. "Continuous Rewards"译为"持续奖励机制" - 完整保留强化学习领域的专业表述
3. 采用"大型多模态模型"作为"Large Multimodal Models"的标准译法，符合计算机视觉与自然语言处理交叉领域术语规范
4. 整体结构保持"技术名称：技术特征说明"的学术标题格式，确保专业性与可读性统一 | Omkat Thawakar | [PDF](https://arxiv.org/pdf/2511.16672v1) | 大规模多模态模型（LMM）近期取得的进展已展现出卓越的推理与感知能力，然而现有训练流程仍主要依赖人工标注数据或外部验证的奖励模型，这限制了其自主性与可扩展性。本研究致力于以纯无监督方式（无需任何标注数据或奖励蒸馏）提升LMM的推理能力。为此，我们提出名为EvoLMM的自演进框架：通过单一骨干模型实例化两个协同智能体——提案者生成多样化的图像关联问题，求解者通过内部一致性进行解答，整个学习过程通过持续自我奖励机制推进。这种动态反馈机制既能促进信息量丰富的查询生成，又可精化结构化推理过程，且无需依赖真实标签或人工评判。当以主流模型Qwen2.5-VL作为基础时，我们的EvoLMM仅使用原始训练图像，就在多模态数学推理基准（包括ChartQA、MathVista和MathVision）上实现了最高约3%的稳定性能提升。我们希望这一简洁高效的方法能为未来全无监督自改进LMM研究奠定坚实基础。代码与模型已开源：https://github.com/mbzuai-oryx/EvoLMM。 |
| NoPo-Avatar：无需人体姿态输入的稀疏数据驱动通用可动虚拟化身系统

（注：翻译采用学术论文标题的简洁规范，通过以下方式实现专业表达：
1. 保留核心术语"NoPo-Avatar"作为技术名称
2. "Generalizable"译为"通用"体现系统泛化能力
3. "Animatable"译为"可动"强调动态生成特性
4. "Sparse Inputs"译为"稀疏数据"准确传达技术特征
5. 补充"驱动系统"明确技术架构，同时通过"无需人体姿态输入"精准对应"without Human Poses"的技术突破点，完整呈现原文的技术内涵与创新性） | Jing Wen | [PDF](https://arxiv.org/pdf/2511.16673v1) | 我们致力于从单张或稀疏图像集中恢复可动画化的三维人体虚拟形象。针对该任务，现有多数先进方法除图像集外，还需在测试阶段依赖精确的“真实值”相机位姿和人体姿态作为重建引导。我们证明，当姿态估计存在噪声时，依赖姿态的重建方法会导致结果显著劣化。为解决此问题，我们提出NoPo-Avatar模型，该模型仅通过图像即可完成虚拟形象重建，无需任何姿态输入。通过消除测试阶段重建对人体姿态的依赖，NoPo-Avatar不受噪声姿态估计的影响，从而具有更广泛的应用潜力。在THuman2.0、XHuman和HuGe100K等挑战性数据集上的实验表明：NoPo-Avatar在实际场景（无真实值姿态）中优于现有基线方法，在实验室场景（具备真实值姿态）中亦可达到相当的重建效果。 |
| 边生成边思考：在视觉生成中交织文本推理 | Ziyu Guo | [PDF](https://arxiv.org/pdf/2511.16671v1) | 视觉生成领域的最新进展正不断探索推理能力的整合。现有方法虽引入了文本推理（即在生成前作为预规划或生成后作为精细化处理），但缺乏生成过程中的实时多模态交互。在本初步研究中，我们提出"边生成边推理"（TwiG）框架——首个实现文本推理与视觉生成全过程交织共演的交错式架构。该框架在视觉内容渐进生成的同时，交错进行文本推理：既指导后续局部区域的生成，又对已合成内容进行反思。这种动态交互产生了更具上下文感知能力与语义丰富性的视觉输出。为挖掘该框架潜力，我们探索了三种实现策略：零样本提示、基于自建TwiG-50K数据集的有监督微调，以及通过定制化TwiG-GRPO策略的强化学习，每种策略都为交错推理的动态机制提供了独特视角。我们期待本研究能推动文本推理与视觉生成交错融合的深入探索。代码将发布于：https://github.com/ZiyuGuo99/Thinking-while-Generating。 |
| 为视觉语言模型学习快速与慢速思考 | Chenyu Lin | [PDF](https://arxiv.org/pdf/2511.16670v1) | 面对复杂问题时，我们往往倾向于慢速思考；反之，对于简单问题则会快速思考。这种双系统思维机制使我们能高效分配认知资源——对简单问题快速决策，对复杂挑战则保留深度分析能力。然而，现有面向推理的视觉语言模型（VLMs）无论是通过显式思维链标注还是基于规则的强化学习奖励进行训练，都主要追求冗长细致的推理链条，这往往导致过高的计算成本。本研究提出一种简洁的强化学习方法，使视觉语言模型能根据任务难度自动切换快慢思考模式。该方法包含两个阶段：第一阶段根据模型输出长度标注数据所需的思考模式（快速或慢速），这一设计灵感来源于预训练视觉语言模型通常会对不同类型问题生成不同长度答案的观察；第二阶段结合思考模式标签与GRPO训练策略，培养模型的双模式思维能力。尽管方法简洁，我们提出的DualMindVLM模型在显著超越基础模型的同时，与最先进的视觉推理模型性能相当，且保持了极高的标记效率。 |
| 视频即答案：基于联合GRPO的下一视频事件预测与生成 | Junhao Cheng | [PDF](https://arxiv.org/pdf/2511.16669v1) | 尽管语言模型已在众多实际应用中产生重要影响，视频生成领域仍主要局限于娱乐用途。受视频与生俱来的物理世界信息呈现能力启发（例如仅通过文字指导他人打领带的困难），我们发现将视频拓展为下一代事件预测（NEP）新型答案模态的潜力尚未被充分挖掘，由此提出视频化下一代事件预测（VNEP）框架。传统NEP任务通过输入流程性视频与预测性问题来生成文本形式的下一个事件，而VNEP则要求动态视频作为响应。这种从“讲述”到“呈现”的转变，为流程化学习和创意探索开启了更直观、可定制的解答方式。然而该任务对现有模型仍具挑战性，因其需要理解多模态输入、执行指令条件推理，并生成视觉与语义一致的视频。为此，我们提出VANS模型，通过强化学习将视觉语言模型（VLM）与视频扩散模型（VDM）协同对齐以实现VNEP。该模型核心是我们设计的联合生成强化策略优化（Joint-GRPO）机制，使VLM与VDM作为整体协同工作：基于各自输出的共享奖励信号，既优化VLM生成既准确又易于可视化的描述文本，同时引导VDM生成符合文本描述与输入视觉语境的视频。为支撑该学习过程，我们构建了专用于VNEP任务的VANS-Data-100K数据集。在流程性与预测性基准测试上的实验表明，VANS在视频事件预测与可视化方面均达到最先进性能。代码已发布于https://github.com/KlingTeam/VANS。 |
| V-ReasonBench：面向视频生成模型的统一推理基准测试套件

（解析：该标题翻译遵循了学术术语的规范处理方式：
1. 保留核心专有名词"V-ReasonBench"的原始形式
2.将"Benchmark Suite"译为专业术语"基准测试套件"
3.采用"面向...的"结构准确传达"for"的学术语境
4.保持"Video Generation Models"（视频生成模型）和"Unified Reasoning"（统一推理）的标准译法
5.通过冒号维持原标题的层次结构，符合中文学术标题的表述习惯） | Yang Luo | [PDF](https://arxiv.org/pdf/2511.16668v1) | 近期生成式视频模型（如Veo-3）的研究进展展现出惊人的零样本推理能力，这催生了对系统化、可靠性评估的迫切需求。我们推出V-ReasonBench基准测试框架，旨在从四个关键维度评估视频推理能力：结构化问题解决、空间认知、模式推理与物理动态理解。该基准集成了合成与真实世界图像序列，提供一系列可验证答案的多样化任务，具备可复现、可扩展及无歧义特性。通过对六个前沿视频模型的评估，我们发现不同维度存在显著能力差异，尤其在结构化、空间、模式推理和物理推理方面表现参差。我们进一步将视频模型与强图像模型进行对比，分析常见幻觉行为，并探究视频时长对帧序列推理链的影响。总体而言，V-ReasonBench为衡量视频推理能力提供了统一可复现的框架，致力于推动构建具有更可靠、更符合人类思维的推理能力的模型发展。 |
| 场景设计师：具备九自由度姿态操控的可控多物体图像生成系统

（注：采用"场景设计师"作为SceneDesigner的意译，既保留工具属性又体现中文语境；"九自由度姿态操控"准确传达9-DoF Pose Manipulation的技术内涵；"可控多物体图像生成系统"完整呈现Controllable Multi-Object Image Generation的核心功能，通过添加"系统"二字强化技术实现的完整性） | Zhenyuan Qin | [PDF](https://arxiv.org/pdf/2511.16666v1) | 可控图像生成近年来日益受到关注，它使用户能够对身份、风格等视觉内容进行操控。然而，如何实现对多个物体9维位姿（位置、尺寸和朝向）的同步控制仍是亟待解决的挑战。尽管研究已取得进展，现有方法仍存在可控性有限和生成质量下降的问题，难以实现全面的多物体9维位姿控制。为解决这些局限，我们提出SceneDesigner方法，可实现精准灵活的多物体9自由度位姿操控。该方法在预训练基础模型中引入分支网络，并采用新型表征CNOCS映射——一种从摄像机视角编码9维位姿信息的表示方法。该表征具有优异的几何解释特性，可实现更高效稳定的训练。为支持训练，我们构建了ObjectPose9D数据集，汇集了多源图像数据及其9维位姿标注。针对数据不平衡问题（特别是低频位姿的性能衰减），我们提出基于强化学习的双阶段训练策略：第二阶段通过在重平衡数据上采用奖励目标对模型进行微调。在推理阶段，我们提出解耦物体采样技术，有效缓解复杂多物体场景中物体生成不足和概念混淆的问题。此外，通过集成用户特定的个性化权重，SceneDesigner能够对参考主体实现定制化位姿控制。大量定性与定量实验表明，SceneDesigner在可控性和生成质量方面均显著优于现有方法。代码已开源：https://github.com/FudanCVL/SceneDesigner。 |
| 驯服长尾分布：基于自适应草稿机制的高效推理强化学习训练

（注：该翻译在保持学术严谨性的同时实现了三个技术要点：
1. "Taming"译为"驯服"准确体现对复杂分布的掌控意图
2. "Adaptive Drafter"采用"自适应草稿机制"的译法，既保留机制特性又符合中文术语习惯
3. 通过"高效推理强化学习训练"的语序调整，确保符合中文科技文献的表达逻辑） | Qinghao Hu | [PDF](https://arxiv.org/pdf/2511.16665v1) | 具备强大推理能力的大语言模型（LLM）的涌现标志着重要里程碑，为复杂问题解决开启了新前沿。然而，这类推理模型通常采用强化学习（RL）进行训练，存在关键效率瓶颈：RL训练中的响应生成呈现持续的长尾分布，少数极长响应主导执行时间，导致资源浪费与成本激增。为此，我们提出TLT系统，通过集成自适应推测解码实现无损的推理RL训练加速。在RL中应用推测解码面临三重挑战：动态工作负载、持续演进的目标模型以及草稿模型训练开销。TLT通过两个协同组件突破这些障碍：（1）自适应草稿模型——在长尾生成期间利用空闲GPU持续训练的轻量级模型，零成本保持与目标模型对齐；（2）自适应推演引擎——维护内存高效的预捕获CUDA图池，并为每个输入批次自适应选择合适推测解码策略。评估表明，TLT相较最先进系统实现超过1.7倍的端到端RL训练加速，保持模型精度，并免费获得适用于高效部署的高质量草稿模型。代码已发布于https://github.com/mit-han-lab/fastrl。 |
| Nemotron弹性模型：迈向高效多任务推理大语言模型之路 | Ali Taghibakhshi | [PDF](https://arxiv.org/pdf/2511.16664v1) | 针对多尺度与部署目标训练大型语言模型家族成本极高，每个不同规模的模型都需要独立训练。近期通过剪枝与知识蒸馏实现的模型压缩技术虽降低了成本，但每个压缩模型仍需耗费数万亿标记的训练开销。本文提出Nemotron Elastic框架，用于构建面向推理的混合Mamba-Attention架构大语言模型，该框架可在单一父模型中嵌入多个嵌套子模型，每个子模型针对不同部署配置与预算进行优化。这些子模型与父模型共享权重，部署时无需额外训练或微调即可实现零样本提取。我们通过端到端训练的路由器实现该功能，该路由器与专为推理模型设计的两阶段训练课程紧密耦合。我们还提出：保持Mamba结构约束的分组感知SSM弹性化技术、异构MLP弹性化技术、基于归一化MSE的层重要性评估以改进深度选择，以及支持多预算同步优化的知识蒸馏方法。将Nemotron Elastic应用于Nemotron Nano V2 12B模型，仅用1100亿训练标记即可同步生成90亿与60亿参数模型，相比从头训练模型家族成本降低超360倍，相较现有最优压缩技术降低约7倍。所有嵌套模型在准确度上均达到或超越现有最优水平。此外，与其他压缩方法不同，本方案的嵌套特性可实现“多合一”推理模型，其部署内存占用随模型家族数量增加保持恒定。 |
