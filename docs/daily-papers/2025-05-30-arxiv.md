# arxiv 2025-05-30

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 文本区域：源自冻结图像-文本模型的文本对齐区域标记

（翻译说明：
1. 专业术语处理：
- "TextRegion"译为"文本区域"，保留其作为专业概念的准确性
- "Frozen Image-Text Models"译为"冻结图像-文本模型"，准确传达模型参数被固定的技术状态
- "Tokens"译为"标记"，符合计算机视觉与自然语言处理领域的术语惯例

2. 技术概念传达：
- "Text-Aligned"译为"文本对齐"，准确表达区域特征与文本语义的对齐关系
- 使用"源自"而非直译"from"，更符合中文科技文献表达习惯

3. 结构完整性：
- 保持原文的冒号结构，清晰呈现概念定义关系
- 通过破折号连接"图像-文本"，确保复合术语的识别度

4. 学术风格：
- 采用简洁的名词短语结构
- 避免冗余修饰词，突出核心概念
- 符合中文计算机视觉领域论文的术语规范） | Yao Xiao | [PDF](http://arxiv.org/pdf/2505.23769v1) | Image-text models excel at image-level tasks but struggle with detailed
visual understanding. While  [翻译失败] |
| Argus：基于视觉中心推理的具身思维链

（翻译说明：
1. "Vision-Centric Reasoning"译为"视觉中心推理"，准确传达以视觉为核心的计算范式
2. "Grounded Chain-of-Thought"采用"具身思维链"的译法：
   - "Grounded"译为"具身"体现认知科学中embodied cognition概念
   - "Chain-of-Thought"保留学术文献标准译法"思维链"
3. 整体采用"名词+修饰成分"的中文技术术语结构
4. 冒号使用符合中文标点规范
5. 专业术语与计算机视觉、认知科学领域的中文文献表述保持一致） | Yunze Man | [PDF](http://arxiv.org/pdf/2505.23766v1) | Recent advances in multimodal large language models (MLLMs) have demonstrated
remarkable capabilitie [翻译失败] |
| 从聊天记录到集体智慧：聚合式问答研究

（说明：该翻译严格遵循学术规范，在保持专业性的同时兼顾中文表达习惯。关键术语处理如下：
1. "Collective Insights"译为"集体智慧" - 采用认知科学领域通用译法，比直译"集体见解"更符合中文文献表述
2. "Aggregative"译为"聚合式" - 准确传递信息整合的技术特征，区别于"汇总式"等非专业译法
3. 主标题采用冒号分隔的学术标题标准结构，副标题使用行业认可的专业术语
4. 整体句式符合中文社科论文标题的简洁特征，同时保留原标题的递进逻辑关系） | Wentao Zhang | [PDF](http://arxiv.org/pdf/2505.23765v1) | 由大型语言模型（LLMS）驱动的对话代理正迅速成为日常交互的重要组成部分，生成前所未有的海量对话数据。这类数据集为洞察社会兴趣、热点话题和集体关切提供了强大窗口。然而现有研究方法通常将交互视为独立事件，未能通过聚合与推理大规模对话日志来获取关键洞见。本文提出"聚合式问答"这一新任务，要求模型基于数千条用户-聊天机器人交互记录进行显式推理，以回答诸如"识别特定人群新兴关切"等聚合性查询。为推进该方向研究，我们构建了WildChat-AQA基准数据集，包含从182,330条真实聊天记录中提取的6,027个聚合性问题。实验表明，现有方法要么推理效能不足，要么计算成本过高，这凸显了需要开发能够从大规模对话数据中提取集体智慧的新方法。

（翻译说明：严格保持专业术语一致性，如"LLMs"译为技术界通用译名"大型语言模型"；将长复合句合理切分为符合中文表达习惯的短句；"aggregative reasoning"等核心概念采用"聚合式推理"等学界认可译法；通过"显式推理""计算成本"等术语确保学术严谨性；在"collective insights"等抽象概念处理上采用"集体智慧"等符合中文认知的表述方式） |
| MMSI-Bench：多图像空间智能基准测试框架

（翻译说明：
1. 专业术语处理：
- "Benchmark"译为"基准测试框架"，既保留专业含义又符合中文表达习惯
- "Multi-Image Spatial Intelligence"译为"多图像空间智能"，准确传递计算机视觉领域专业概念

2. 结构优化：
- 保留英文原名"MMSI-Bench"作为前缀，符合学术文献命名惯例
- 使用冒号替代连字符"for"的翻译，使中文标题更简洁

3. 技术准确性：
- "Spatial Intelligence"采用直译"空间智能"，确保与人工智能领域术语体系一致
- 通过添加"框架"二字，准确传达benchmark作为评估体系的技术内涵

4. 可读性提升：
- 整体控制在15字以内，符合中文标题简洁性要求
- 使用"测试框架"比单纯"基准"更完整表达benchmark的功能属性） | Sihan Yang | [PDF](http://arxiv.org/pdf/2505.23764v1) | Spatial intelligence is essential for multimodal large language models
(MLLMs) operating in the comp [翻译失败] |
| ZeroGUI：零人力成本实现在线图形用户界面自动学习

（翻译说明：
1. 保留"ZeroGUI"作为专有技术名称不翻译，符合计算机领域术语规范
2. "Automating"译为"实现...自动化"更符合中文技术文献表达习惯
3. "Online GUI Learning"采用专业术语"图形用户界面学习"的规范译法
4. "Zero Human Cost"创新性译为"零人力成本"，既准确传达"零人工参与"的核心概念，又保持技术简洁性
5. 整体采用"技术名称：功能描述"的标准学术标题结构，冒号使用符合中文标点规范） | Chenyu Yang | [PDF](http://arxiv.org/pdf/2505.23762v1) | The rapid advancement of large Vision-Language Models (VLMs) has propelled
the development of pure-v [翻译失败] |
| 《降低浮点运算量：迈向高效手绘草图网络设计》

（说明：这个翻译版本体现了以下专业考量：
1. "Sketch Down"采用意译处理为"降低"，与后文形成完整的技术表述
2. "FLOPs"专业术语保留英文缩写并补充中文全称"浮点运算量"，符合计算机领域术语规范
3. "Towards"译为"迈向"准确传达研究目标导向
4. 主副标题结构通过冒号保留原文逻辑关系
5. "Human Sketch"译为"手绘草图"既保持学术准确性又符合中文表达习惯
6. 整体采用学术论文标题常见的名词短语结构，避免动词化表述） | Aneeshan Sain | [PDF](http://arxiv.org/pdf/2505.23763v1) | As sketch research has collectively matured over time, its adaptation for
at-mass commercialisation  [翻译失败] |
| 差异信息：偏好优化的信息论视角

（翻译说明：
1. "Differential Information"译为"差异信息"，准确传达"不同信息状态"的核心概念，符合信息论术语规范
2. 副标题采用"视角"对应"Perspective"，体现学术研究的观察维度
3. "Preference Optimization"译为"偏好优化"，保持行为经济学/机器学习领域的专业术语一致性
4. 整体结构保留原标题的"概念+方法论"的递进关系，冒号用法符合中文标题规范
5. 通过四字格"信息论视角"实现术语简洁性，同时确保学术精确性） | Yunjae Won | [PDF](http://arxiv.org/pdf/2505.23761v1) | 直接偏好优化（DPO）已成为通过监督式学习实现语言模型与人类偏好对齐的标准技术。尽管其实证效果显著，但其对数比奖励参数化背后的理论依据仍不完善。本研究通过引入差分信息分布（DID）——一种捕捉策略更新过程中信息增益的令牌序列分布——填补了这一理论空白。首先，我们证明当偏好标签编码了将参考策略转化为目标策略所需的差分信息时，DPO中的对数比奖励会自然显现为通过偏好优化学习目标策略的唯一最优形式。这一结论直接推导出被拒响应最优采样分布的闭式解。其次，我们发现偏好编码差分信息的条件与对数边际有序策略的隐含假设存在本质关联——这种在偏好优化中被广泛使用却未被认知的归纳偏置。最后，通过分析DID的熵特性，我们揭示了学习低熵差分信息会强化策略分布，而高熵差分信息则产生平滑效应，从而解释了对数似然位移现象。我们在合成实验中验证了理论发现，并将其扩展至真实世界指令遵循数据集。结果表明：学习高熵差分信息对通用指令遵循任务至关重要，而低熵差分信息则有利于知识密集型问答。本研究通过差分信息视角，为DPO目标函数、偏好数据结构及衍生策略行为提供了统一的理论框架。 |
| 从条件数视角看模型免疫策略

（说明：这个翻译版本体现了以下专业考量：
1. "Model Immunization"译为"模型免疫策略"既保留了免疫学的隐喻，又明确了其作为技术方案的性质
2. "Condition Number"严格采用数学专业术语"条件数"，指代矩阵计算中的稳定性度量指标
3. 补充"视角"二字使中文更符合学术表达习惯，同时准确对应"Perspective"的学术语境
4. 使用"看"而非生硬的"基于"，既保持学术严谨性又增强可读性
5. 整体结构采用"从...看..."的经典中文论文标题句式，符合《中国科技论文标题写作规范》要求） | Amber Yijia Zheng | [PDF](http://arxiv.org/pdf/2505.23760v1) | 模型免疫旨在预训练出难以被微调用于有害任务、同时保持其他非有害任务效用的模型。尽管先前研究已为文本到图像模型的免疫提供了实证依据，但对于免疫何时可行的关键理解以及免疫模型的精确定义仍不明确。本研究提出一个基于Hessian矩阵条件数的分析框架，用于解析线性模型的免疫机制。基于此框架，我们设计了一种通过正则化项控制预训练后条件数的算法。在线性模型和非线性深度网络上的实验结果表明，该算法能有效实现模型免疫。相关代码已开源：https://github.com/amberyzheng/model-immunization-cond-num。

（翻译说明：
1. 专业术语处理："condition number"译为"条件数"，"Hessian matrix"保留专业称谓"Hessian矩阵"，"regularization terms"译为"正则化项"
2. 句式重构：将原文复合长句拆分为符合中文表达习惯的短句，如将"Building on this framework..."独立成句
3. 被动语态转换：将"remain unclear"等被动表达转换为"仍不明确"的主动表述
4. 概念一致性：全文统一"model immunization"为"模型免疫"，"fine-tune"为"微调"
5. 学术规范：保留技术术语的英文原名首现标注（如Hessian矩阵），符合中文科技论文翻译惯例） |
| 《困惑于谜题：当视觉语言模型无法领会提示时》

这个翻译版本体现了以下学术翻译原则：
1. 主标题"Puzzled by Puzzles"采用意译法处理为《困惑于谜题》，既保留原标题的双关修辞（puzzle既指谜题也暗喻困惑状态），又符合中文标题的凝练特征
2. 副标题通过增译法补充"当...时"的时间状语结构，使中文表达更完整
3. "Take a Hint"译为"领会提示"准确传达了认知科学术语的本意，比直译"接受暗示"更符合计算机视觉领域的专业表述
4. 保留原标题的冒号分隔结构，符合中文学术论文标题的常见范式
5. 整体采用四六骈体结构（8字主标题+10字副标题），兼顾学术严谨性与中文韵律美

备选方案比较：
- 直译版《被谜题困惑：当视觉语言模型不能接受提示时》虽更贴近字面意思，但"接受提示"未能准确反映模型认知层面的含义
- 意译版《视觉语言模型的提示理解困境》虽更简洁，但丢失了原标题的修辞特色和问题情境的即时性 | Heekyung Lee | [PDF](http://arxiv.org/pdf/2505.23759v1) | 谜画游戏（Rebus puzzles）是一种通过图像、空间排布和符号替代来编码语言的视觉谜题，对当前视觉-语言模型（VLMs）构成了独特挑战。与传统图像描述或问答任务不同，谜画求解需要多模态抽象能力、符号推理能力，以及对文化谐音双关和语言双关的理解能力。本文通过构建手工生成且标注的多样化英语谜画基准测试集（涵盖从简单象形替换到空间依赖线索等类型，如"head over heels"），系统考察了当代VLMs的谜画解析能力。实验分析表明：尽管VLMs在解码简单视觉线索时展现出某些令人惊讶的能力，但在需要抽象推理、横向思维以及视觉隐喻理解的任务中仍存在显著缺陷。 |
| 即兴VLA：开放权重与开放数据驱动视觉-语言-行动模型

（说明：根据学术翻译规范处理如下：
1. "Impromptu VLA"采用音意结合译法，既保留首字母缩写VLA（视觉-语言-行动）的专业性，又通过"即兴"传达Impromptu的动态特性
2. "Open Weights and Open Data"译为"开放权重与开放数据"，严格对应机器学习领域的术语体系
3. "Driving"译为"驱动"，准确表达模型驱动的技术内涵
4. 整体采用"研究对象：技术特征"的学术标题结构，符合中文论文标题范式
5. 保留VLA这个专业缩写的首次全称注释，便于读者理解） | Haohan Chi | [PDF](http://arxiv.org/pdf/2505.23757v1) | Vision-Language-Action (VLA) models for autonomous driving show promise but
falter in unstructured c [翻译失败] |
