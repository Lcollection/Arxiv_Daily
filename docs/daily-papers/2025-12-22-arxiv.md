# arxiv 2025-12-22

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 语义与重构并重：为文本到图像生成与编辑优化表征编码器 | Shilong Zhang | [PDF](https://arxiv.org/pdf/2512.17909v1) | 现代潜在扩散模型（LDM）通常在低层变分自编码器（VAE）潜在空间中运行，这些空间主要针对像素级重建进行优化。为了统一视觉生成与理解，新兴趋势是采用表征编码器的高维特征作为生成潜在空间。然而，我们通过实验发现该范式存在两个根本性障碍：（1）判别性特征空间缺乏紧凑的正则化，导致扩散模型容易产生偏离流形的潜在表示，从而生成不准确的物体结构；（2）编码器固有的弱像素级重建能力阻碍生成器学习精确的细粒度几何与纹理特征。本文提出一个系统性框架，将面向理解的编码器特征适配于生成任务。我们引入语义-像素联合重建目标来正则化潜在空间，使其能够将语义信息与细粒度细节共同压缩为高度紧凑的表示（96通道且空间下采样16倍）。该设计确保潜在空间既保持语义丰富性、实现最先进的图像重建效果，又具备足够紧凑性以支持精确生成。基于此表征，我们设计了统一的文本到图像（T2I）生成与图像编辑模型。通过对多种特征空间的基准测试，我们证明该方法在重建质量上达到最优水平，具有更快的收敛速度，并在T2I生成与编辑任务中取得显著性能提升，验证了表征编码器能够有效转化为鲁棒的生成组件。 |
| 重深度万物：通过自监督重照明的测试时深度优化 | Ananta R. Bhattarai | [PDF](https://arxiv.org/pdf/2512.17908v1) | 单目深度估计仍具挑战性，因为近期的基础模型（如Depth Anything V2，简称DA-V2）在处理与训练分布差异较大的真实世界图像时表现欠佳。我们提出Re-Depth Anything——一种测试时自监督框架，通过融合DA-V2与大规模二维扩散模型的强大先验知识来弥合这一领域差距。该方法直接在输入图像上进行无标签优化，通过对预测深度图进行重光照处理并增强输入数据。这种重合成方法以生成式语境下的分数蒸馏采样（SDS）技术，结合明暗形状（SfS）线索，替代了传统的光度重建方案。为防止优化崩溃，本框架采用定向优化策略：冻结编码器参数，仅更新中间嵌入表征并微调解码器，而非直接优化深度或完整微调模型。在多样化基准测试中，Re-Depth Anything相较于DA-V2在深度精度与真实感方面实现显著提升，为通过增强几何推理实现自监督开辟了新路径。 |
| 灵巧世界模型 | Byungjun Kim | [PDF](https://arxiv.org/pdf/2512.17907v1) | 三维重建技术的最新进展使得从日常环境中创建逼真的数字孪生体变得容易。然而，当前数字孪生体大多仍保持静态，仅限于导航和视图合成，缺乏具身交互能力。为弥补这一不足，我们提出了灵巧世界模型——一种基于场景-动作条件的视频扩散框架，该模型能够模拟灵巧的人类动作如何引发静态三维场景的动态变化。

给定静态三维场景渲染结果与第一人称手部运动序列，灵巧世界模型可生成时间连贯的视频，描绘合理的人-场景交互过程。我们的方法通过以下两个条件控制视频生成：(1) 沿特定相机轨迹的静态场景渲染，确保空间一致性；(2) 编码几何与运动信息的第一人称手部网格渲染，直接建模动作驱动的动态变化。为训练该模型，我们构建了混合交互视频数据集：合成第一人称交互数据为联合移动与操作学习提供完全对齐的监督信号，固定视角真实世界视频则贡献了多样且真实的物体动态。

实验表明，灵巧世界模型能够实现逼真且符合物理规律的交互（如抓握、开启和移动物体），同时保持相机视角与场景一致性。该框架标志着向基于视频扩散的交互式数字孪生体迈出了第一步，实现了从第一人称动作出发的具身模拟。 |
| 开放基础模型中视觉对抗鲁棒性的研究 | Jonathon Fox | [PDF](https://arxiv.org/pdf/2512.17902v1) | 随着深度学习的发展，理解人工智能系统识别物体的模型变得越来越困难。因此，攻击者可能通过在图像中添加不可见的元素来修改图像，从而干扰人工智能对实体的识别。本文研究了LLaVA-1.5-13B和Meta的Llama 3.2 Vision-8B-2的对抗鲁棒性。针对视觉输入模态，对这两种模型进行了无目标投影梯度下降（PGD）攻击测试，并在视觉问答（VQA）v2数据集的子集上进行了实证评估。随后，使用标准的VQA准确率指标对这些对抗攻击的结果进行了量化分析。该评估结果进一步与LLaVA和Llama 3.2 Vision的准确率下降情况进行了比较。一个关键发现是，尽管Llama 3.2 Vision在此设置下的基准准确率较低，但在遭受攻击时，其性能下降幅度小于LLaVA，尤其是在较高扰动水平下。总体而言，研究结果证实视觉模态是降低当代开放权重视觉语言模型（包括Meta的Llama 3.2 Vision）性能的有效攻击途径。此外，这些发现还表明，对抗鲁棒性并不一定与标准基准性能直接相关，可能受到底层架构和训练因素的影响。 |
| 当推理遭遇其法则 | Junyu Zhang | [PDF](https://arxiv.org/pdf/2512.17901v1) | 尽管大型推理模型（LRMs）展现出卓越的性能，但其推理行为往往与直觉相悖，导致推理能力未能达到最优水平。为从理论上形式化描述理想的推理行为，本文提出《推理法则》（LoRe）——一个用于刻画大型推理模型内在推理模式的统一框架。我们首先提出计算法则，其核心假设是推理计算量应与问题复杂度呈线性比例关系。除计算维度外，我们通过补充准确率法则进一步扩展了LoRe框架。鉴于问题复杂度在实践中难以量化，我们通过法则的两个可验证属性——单调性与组合性来检验这些假设。为此，我们构建了LoRe-Bench基准测试平台，系统化评估大型推理模型在这两个可量化属性上的表现。评估结果表明，大多数推理模型展现出合理的单调性，但普遍缺乏组合性。针对此问题，我们开发了一种有效的微调方法，以强化计算法则的组合性。大量实证研究表明，更好地遵循计算法则能在多个基准测试中持续提升推理性能，并揭示出不同属性与法则之间的协同效应。项目主页：https://lore-project.github.io/ |
| 多智能体交互序列建模中的扩散驱动机制 | Vongani H. Maluleke | [PDF](https://arxiv.org/pdf/2512.17900v1) | 理解与生成多人交互是一个具有广泛机器人学和社会计算应用价值的基础性挑战。尽管人类天生具备群体协调能力，但由于交互过程时间跨度长、智能体间依赖性强以及群体规模多变，对此类交互进行建模仍然十分困难。现有运动生成方法大多针对特定任务，难以推广至灵活的多智能体生成场景。我们提出MAGNet（多智能体扩散驱动变换器），这是一个统一的自回归扩散框架，通过灵活的约束条件与采样机制，支持广泛的多智能体运动生成交互任务。该模型在单一架构中实现了二元运动预测、伙伴运动补全及完整多智能体运动生成，并能自回归生成长达数百帧的超长序列。基于扩散驱动技术，我们引入关键改进方案，在自回归去噪过程中显式建模智能体间耦合关系，从而实现跨智能体的协调一致性。这使得MAGNet既能捕捉高度同步的活动（如舞蹈、拳击），也能呈现松散结构化的社会交互。我们的方法在二元基准测试中与专用模型性能相当，同时通过可扩展的架构设计，自然延伸至涉及三人及以上交互的多元场景，且对智能体数量具有普适性。建议读者参阅补充视频，其中生成交互的时序动态与空间协调性展现得尤为清晰。项目页面：https://von31.github.io/MAGNet/ |
| 分布鲁棒模仿学习：可认证自主性的分层控制架构 | Aditya Gahlawat | [PDF](https://arxiv.org/pdf/2512.17899v1) | 模仿学习（IL）通过从专家演示中学习来实现自主行为。尽管相较于强化学习等替代方法具有更高的样本效率，但IL对分布偏移引发的累积误差较为敏感。在系统中应用基于IL的反馈律时，存在两类主要的分布偏移源：由策略误差引起的分布偏移，以及由外部干扰和因学习不足导致的内生模型误差引起的分布偏移。我们先前提出的泰勒级数模仿学习（TaSIL）和$\mathcal{L}_1$分布鲁棒自适应控制（$\ell$1DRAC）方法，以互补方式应对分布偏移的挑战：TaSIL针对策略误差引起的分布偏移提供鲁棒性，而$\ell$1DRAC则针对由偶然性和认知性不确定性导致的分布偏移提供鲁棒性。为实现对学习型和/或不确定动态系统的可验证IL，我们提出\textit{分布鲁棒模仿策略（DRIP）}架构——一种集成TaSIL与$\ell$1DRAC的分层控制架构（LCA）。通过审慎设计以各层为中心的输入输出要求，我们证明了如何为整个控制流程提供可验证的保证。该解决方案通过将基于学习的组件（如感知模块）与可验证的基于模型的决策模块，通过所提出的LCA方法相结合，为设计完全可验证的自主系统流程开辟了道路。 |
| 类人化人工智能设计提升拟人化感知，但在全球范围内对用户参与度与信任度产生分化影响。 | Robin Schimmelpfennig | [PDF](https://arxiv.org/pdf/2512.17898v1) | 全球有超过十亿用户与日益精密的AI系统互动，这些系统被设计得越来越接近人类特质。这一转变引发了关于拟人化（即将人类特征赋予合成智能体）及其可能引发错误信任或情感依赖的紧迫讨论。然而，更具人类特征的AI设计如何影响用户参与度和信任度，尚未在全球用户群体的真实人机交互中得到验证。现行的安全框架仍依赖于源自西方人群的理论假设，忽视了全球AI用户的多样性。本研究通过两项覆盖10个不同国家的大规模跨国实验（N=3,500），让用户与AI系统进行实时开放式互动，填补了这些研究空白。我们发现，用户在评估AI的拟人程度时，较少关注政策文件中常引用的理论维度（如感知能力或意识），而更注重对话流畅度、理解用户视角等实际交互线索。实验还证明，拟人化设计确实能引发用户更强的拟人化感知，但并未如既往理论所言普遍提升用户参与度和信任度的行为指标。实际上，拟人化与行为结果间的关联存在文化裂隙：某些促进特定群体（如巴西）对AI系统自我报告信任度的设计选择，在其他群体（如日本）可能引发相反效果。这些发现挑战了当前关于拟人化AI设计必然存在风险的普遍论述，揭示了一个受文化调节的、多层次的人机交互图景，要求我们在AI治理中超越"一刀切"的固有模式。 |
| RadarGen：基于摄像头的汽车雷达点云生成技术 | Tomer Borreda | [PDF](https://arxiv.org/pdf/2512.17897v1) | 我们提出RadarGen，一种基于扩散模型的生成方法，用于从多视角相机图像合成逼真的汽车雷达点云。该方法通过将雷达测量数据编码为鸟瞰图形式——同时包含空间结构、雷达散射截面（RCS）及多普勒属性，将高效的图像隐空间扩散技术适配至雷达领域。通过轻量级重建步骤，可从生成的特征图中恢复点云数据。为增强生成结果与视觉场景的一致性，RadarGen融合了从预训练基础模型中提取的鸟瞰图对齐深度、语义及运动线索，这些线索引导随机生成过程产生符合物理规律的雷达模式。基于图像的条件生成机制使该方法原则上能够广泛兼容现有视觉数据集与仿真框架，为多模态生成式仿真提供了可扩展的技术路径。在大规模驾驶数据上的评估表明，RadarGen能够准确捕捉雷达测量的特征分布，并缩小与基于真实数据训练的感知模型之间的性能差距，标志着跨传感模态统一生成式仿真研究迈出了重要一步。 |
| 探究基矢旋转对神经网络量子态性能的影响 | Sven Benjamin Kožić | [PDF](https://arxiv.org/pdf/2512.17893v1) | 神经量子态（NQS）利用神经网络表示量子多体系统的波函数，但其性能依赖于基矢的选择，且其内在机制尚不明确。我们通过一个完全可解的一维伊辛模型证明：局部基矢旋转不会改变损失函数的景观，但会使精确波函数在参数空间中发生位移，从而显著增大其与典型初始化位置之间的几何距离。通过扫描旋转角度，我们计算量子费舍尔信息与富比尼-研究距离，以量化旋转后波函数在损失景观中的移动轨迹。采用量子自然梯度训练的浅层架构（以受限玻尔兹曼机为重点）根据旋转角度的不同更易陷入鞍点区域：虽然能获得较低的能量误差，却无法复现正确的系数分布。在铁磁情形中，近简并的本征态会形成高曲率势垒，将优化过程困于中等保真度区间。我们建立了一个基于解析可解旋转伊辛模型的理论框架，通过研究目标波函数在固定损失景观中的位移如何暴露信息几何障碍（如鞍点与高曲率区域），揭示了这些障碍对浅层NQS优化的阻碍作用，从而凸显了在变分训练中构建景观感知模型设计的必要性。 |
