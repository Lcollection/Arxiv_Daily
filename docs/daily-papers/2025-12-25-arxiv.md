# arxiv 2025-12-25

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| HiStream：通过冗余消除流式处理实现高效高分辨率视频生成 | Haonan Qiu | [PDF](https://arxiv.org/pdf/2512.21338v1) | 高分辨率视频生成虽对数字媒体与电影至关重要，但其计算效率受限于扩散模型二次方复杂度带来的瓶颈，导致实际推理难以实现。为此，我们提出HiStream——一种高效的自回归框架，通过三个维度系统性消除冗余：一）空间压缩：先以低分辨率去噪，再利用缓存特征进行高分辨率细化；二）时间压缩：采用分块处理策略配合固定尺寸锚点缓存，确保推理速度稳定；三）时间步压缩：对后续基于缓存条件的分块应用更少的去噪步骤。在1080p基准测试中，我们的核心HiStream模型（一+二）在实现顶尖视觉质量的同时，去噪速度较Wan2.1基线提升最高达76.2倍，且质量损失可忽略不计。我们的加速变体HiStream+融合全部三项优化（一+二+三），相比基线实现107.5倍加速，在速度与质量间达成卓越平衡，从而使高分辨率视频生成兼具实用性与可扩展性。 |
| 超越记忆：揭示视觉语言模型中流行度偏见的多元序数回归基准测试

（注：翻译力求准确传达原文的学术含义，同时保持中文表达的流畅性。"Multi-Modal Ordinal Regression Benchmark"译为"多元序数回归基准测试"，既保留了"Ordinal Regression"作为统计学专业术语的准确性，又通过"基准测试"明确了其评估性质。"Expose Popularity Bias"译为"揭示...流行度偏见"，其中"Expose"采用"揭示"以符合学术语境，"Popularity Bias"作为机器学习领域的特定概念译为"流行度偏见"。标题结构采用主副标题形式，冒号前为研究核心主张，后为具体方法说明，符合中文科技文献标题惯例。） | Li-Zhong Szu-Tu | [PDF](https://arxiv.org/pdf/2512.21337v1) | 我们揭示了当前最先进的视觉语言模型（VLMs）中存在显著的流行度偏差：这些模型在识别著名建筑时的准确率比普通建筑高出34%，表明其依赖记忆而非可泛化的理解能力。为系统研究此问题，我们构建了该领域最大的开放基准数据集——YearGuessr，包含来自157个国家的55,546张建筑图像，每张图像均标注了连续序数形式的建造年份（1001-2024年）、GPS数据，并以页面浏览量作为流行度指标。基于该数据集，我们将建造年份预测任务构建为序数回归问题，并提出考虑流行度的区间准确率度量方法以量化此类偏差。通过对30余个模型（包括我们提出的YearCLIP模型）的测试，基准实验证实：视觉语言模型擅长处理流行且被记忆的项目，但在识别非知名对象时表现显著受限，这暴露了其推理能力的关键缺陷。项目页面：https://sytwu.github.io/BeyondMemo/ |
| 通过量化不确定性优化掩码扩散模型中的解码路径 | Ziyu Chen | [PDF](https://arxiv.org/pdf/2512.21336v1) | 掩码扩散模型（MDMs）具备灵活的非自回归生成能力，但这种自由度也带来了挑战：最终输出质量对解码顺序高度敏感。我们首次将这一问题形式化，指出输出质量的波动源于生成路径中累积的预测不确定性。为量化这种不确定性，我们提出了"去噪熵"这一可计算指标，作为评估生成过程的内部信号。基于该指标，我们设计了两种优化解码路径的算法：后验选择方法与实时引导策略。实验表明，我们的熵引导方法显著提升了生成质量，在具有挑战性的推理、规划和代码基准测试中持续提高准确率。本研究确立了去噪熵作为理解和控制生成过程的原理性工具，成功将MDMs中的不确定性从缺陷转化为发现高质量解决方案的关键优势。 |
| 计算型即时检测传感器的自主不确定性量化 | Artem Goncharov | [PDF](https://arxiv.org/pdf/2512.21335v1) | 计算型即时检测传感器能够在缺乏集中医疗设施的紧急、偏远及资源有限地区实现快速、低成本且易于获取的诊断。这些系统可利用基于神经网络的算法，从快速诊断测试或传感器产生的信号中准确推断诊断结果。然而，基于神经网络的诊断模型易产生幻觉现象，可能导致错误预测，从而带来误诊和临床决策不准确的风险。为应对这一挑战，本研究提出一种专为即时检测诊断开发的自主不确定性量化技术。我们以用于莱姆病（全球最常见的蜱传疾病）快速即时诊断的纸基计算型垂直流检测平台作为实验平台。该平台集成了可抛弃式纸基检测装置、手持式光学读取器及基于神经网络的推理算法，仅需20微升患者血清即可在20分钟内实现快速、低成本的莱姆病诊断。通过将基于蒙特卡洛随机失活的不确定性量化方法融入诊断流程，系统能自主识别并排除高不确定性的错误预测，在无需患者真实诊断信息的情况下，显著提升了检测平台的灵敏度和可靠性。采用新患者样本的盲测结果显示，诊断灵敏度从88.2%提升至95.7%，这证实了基于蒙特卡洛随机失活的不确定性量化方法能有效增强神经网络驱动的计算型即时检测传感系统的鲁棒性。 |
| 流媒体视频指令调优 | Jiaer Xia | [PDF](https://arxiv.org/pdf/2512.21334v1) | 我们提出Streamo，一种实时流式视频大语言模型，可作为通用交互式助手。与现有专注于问答或字幕生成的在线视频模型不同，Streamo能够执行广泛的流式视频任务，包括实时解说、动作理解、事件描述、时序事件定位以及时效性问答。为实现这种多功能性，我们构建了Streamo-Instruct-465K——一个专为流式视频理解定制的大规模指令遵循数据集。该数据集涵盖多样化时序语境与多任务监督，支持跨异构流式任务的统一训练。通过简化的训练流程对指令数据集进行端到端训练后，Streamo在多种流式视频基准测试中展现出强大的时序推理能力、灵敏的交互响应以及广泛的泛化性能。大量实验表明，Streamo弥合了离线视频感知模型与实时多模态助手之间的鸿沟，为连续视频流中的统一智能视频理解迈出了重要一步。 |
| 快速SAM2结合文本驱动的令牌剪枝 | Avilasha Mandal | [PDF](https://arxiv.org/pdf/2512.21333v1) | Segment Anything Model 2（SAM2）作为视觉基础模型，在提示驱动的视频目标分割领域取得了显著进展，但其实际部署仍受限于跨时间处理密集视觉标记时的高计算与内存成本。现有SAM2流程通常将图像编码器生成的全部视觉标记传递至下游时序推理模块，无论其与目标对象的相关性如何，这种处理方式因二次内存注意力开销而限制了模型的可扩展性。

本研究提出一种文本引导的标记剪枝框架，通过在时序传播前选择性降低标记密度来提升推理效率，且无需修改底层分割架构。该方法在视觉编码之后、基于记忆的传播之前运行，通过轻量级路由机制对标记进行排序，该机制整合了局部视觉上下文、源自以对象为中心的文本描述（用户提供或自动生成）的语义相关性，以及有助于保留模糊或边界关键区域的不确定性线索。通过仅保留最具信息量的标记进行下游处理，所提方法在维持分割保真度的同时减少了冗余计算。

在多个高难度视频分割基准上的大量实验表明，编码后标记剪枝为实现高效、提示感知的视频分割提供了切实有效的路径：与未剪枝的基准SAM2相比，推理速度最高提升42.50%，GPU内存使用降低37.41%，同时保持了具有竞争力的J和F性能指标。这些结果凸显了早期标记选择在提升基于Transformer的视频分割系统可扩展性方面的潜力，尤其适用于实时性与资源受限的应用场景。 |
| C2LLM技术报告：基于自适应交叉注意力池化的代码检索新前沿 | Jin Qin | [PDF](https://arxiv.org/pdf/2512.21332v1) | 我们推出C2LLM——对比式代码大语言模型系列，包含0.5B与7B两种规模的代码嵌入模型。该系列基于Qwen-2.5-Coder架构构建，创新性地采用多头注意力池化模块，从词元嵌入中生成序列嵌入。该设计具有三重优势：其一，有效利用大语言模型在预训练阶段获得的因果表征能力；其二，能够聚合序列中全部词元的信息，突破传统基于序列结束符的嵌入方法存在的信息瓶颈；其三，支持嵌入维度的灵活适配，可作为多表示学习方法的替代方案。通过在300万公开数据上进行训练，C2LLM系列在同等规模模型中刷新了MTEB-Code基准测试记录，其中C2LLM-7B版本荣登综合排行榜首位。 |
| TICON：一种用于组织病理学表征学习的切片级图块上下文建模器 | Varun Belagali | [PDF](https://arxiv.org/pdf/2512.21331v1) | 在大型全切片图像（WSI）中解读小图块通常需要更大的图像上下文。我们提出TICON——一种基于Transformer的图块表征上下文化模型，能够为计算病理学中的"任意"应用生成丰富的上下文化嵌入向量。传统的基于图块编码器的流程会提取脱离上下文的图块嵌入，无法建模对局部和全局任务都至关重要的丰富切片级信息。此外，不同图块编码器在不同下游任务中表现各异，因此需要统一模型来对"任意"图块级基础模型生成的嵌入进行上下文化。TICON通过单一共享编码器解决这一需求，该编码器采用掩码建模目标进行预训练，能够同时统一并上下文化来自不同图块级病理基础模型的表征。实验表明，经TICON上下文化的嵌入向量在多项任务中显著提升性能，在图块级基准测试（如HEST-Bench、THUNDER、CATCH）和切片级基准测试（如Patho-Bench）中均创下最新最优记录。最后，我们在TICON基础上预训练聚合器构建切片级基础模型，仅使用1.1万张WSI即超越当前最优的切片级基础模型（后者使用高达35万张WSI进行预训练）。 |
| 您的推理基准可能并未真正测试推理：揭示抽象推理基准中的感知瓶颈问题 | Xinhe Wang | [PDF](https://arxiv.org/pdf/2512.21329v1) | 诸如抽象与推理语料库（ARC）及其扩展版本ARC-AGI等推理基准被广泛用于评估人工智能的发展水平，并常被视为对核心“流体”推理能力的检验。尽管这些任务对人类而言看似简单，但对前沿视觉语言模型（VLMs）来说仍具挑战性，这一差距通常被归因于机器推理能力的不足。我们对此解释提出质疑，并提出假设：这一差距主要源于视觉感知的局限性，而非归纳推理的缺陷。

为验证这一假设，我们设计了一个两阶段实验流程，明确分离感知与推理过程。在感知阶段，每张图像被独立转换为自然语言描述；在推理阶段，模型基于这些描述归纳规则并加以应用。该设计避免了跨图像归纳信号的泄露，并将推理过程与感知瓶颈相隔离。通过在Mini-ARC、ACRE和Bongard-LOGO三个ARC风格数据集上的实验，我们对比两阶段流程与标准端到端单阶段评估，证明感知能力是导致观测性能差距的主导因素。对VLM输出推理轨迹的人工检查进一步揭示，约80%的模型失败源于感知错误。

综合来看，这些结果表明ARC风格基准将感知与推理挑战混为一谈，观测到的性能差距可能过度放大了机器推理的缺陷。我们的发现强调，在评估机器智能进展时，需要建立能够区分感知与推理的评估标准。 |
| 全面测量大语言模型评估中的各类噪声 | Sida Wang | [PDF](https://arxiv.org/pdf/2512.21326v1) | 从噪声中分离信号是实验科学的核心。将成熟的统计方法有效应用于大语言模型评估，需充分考虑其独特的噪声特性。我们明确定义并测量了三种噪声类型：针对给定问题生成不同答案产生的预测噪声、问题抽样形成的数据噪声，以及遵循全方差定律的二者叠加总噪声。为强化相对比较并提升统计效力，我们提出全配对分析方法——该方法对所有大语言模型组合实施配对分析，并基于数百万条跨多评估场景的问题级预测数据测量全部噪声成分。

测量结果呈现出清晰规律：首先，每个评估在所有模型配对中都表现出特定且高度可预测的总噪声水平；其次，配对预测噪声通常超过配对数据噪声，这意味着通过均值化降低预测噪声能显著提升统计效力。这些发现使实践者无需定制化测试即可评估显著性，并能在控制实验中检测更微小的效应差异。 |
