# arxiv 2025-06-04

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| IllumiCraft：面向可控视频生成的三维几何与光照扩散统一框架

（翻译说明：
1. 专业术语处理：
- "Unified Geometry and Illumination"译为"三维几何与光照统一"，其中Geometry根据计算机图形学规范译为"三维几何"
- "Diffusion"保留扩散模型技术含义，译为"扩散"
- "Controllable Video Generation"译为"可控视频生成"，符合计算机视觉领域术语标准

2. 结构优化：
- 采用"框架"作为核心概念词，比直译"扩散"更能体现系统级解决方案的特性
- 使用破折号替代原标题的冒号，更符合中文技术文献标题规范

3. 技术内涵传达：
- 通过"面向"二字明确技术应用方向
- "三维几何与光照"的并置结构突出论文在3D空间建模与光照模拟的双重创新

4. 简洁性：
- 在18个汉字内完成表达，符合中文标题简洁要求
- 避免使用"的"字结构，保持标题紧凑性） | Yuanze Lin | [PDF](http://arxiv.org/pdf/2506.03150v1) | Although diffusion-based models can generate high-quality and high-resolution
video sequences from t [翻译失败] |
| 分词偏差的因果效应估计

（说明：该翻译严格遵循学术术语规范，其中：
1. "Causal Estimation"译为"因果效应估计" - 采用因果推断领域的标准译法
2. "Tokenisation"译为"分词" - 保持自然语言处理领域的术语一致性
3. "Bias"译为"偏差" - 区别于"偏见"等非技术性译法，准确反映机器学习中的技术概念
译文采用名词化结构处理英语动名词，符合中文科技文献表达习惯，同时通过"效应"二字明示因果关系的技术内涵） | Pietro Lesci | [PDF](http://arxiv.org/pdf/2506.03149v1) | 现代语言模型通常在子词序列上进行训练，但最终定义的是对字符串的概率分布。理想情况下，分词器（即将字符串映射为子词的组件）的选择不应影响对底层字符串的概率分配；然而实践中却会产生影响。我们将这种偏差定义为分词偏差。本研究量化了一种特定类型的分词偏差：考察某个子词（如$\langle hello \rangle$）是否被纳入分词器词汇表时，对训练后模型赋予对应字符串（即\textit{``hello''}）概率的影响。由于每个模型仅使用单一分词器训练，评估这种影响具有挑战性。我们通过将分词偏差构建为因果效应，并采用断点回归设计进行估计来解决该问题。具体而言，我们利用分词算法会对子词排序并选取前$K$个加入词汇表的特性（其中$K$为任意截断点），通过比较截断点附近相似子词来估计因果效应。实验发现，分词选择会持续影响不同规模、词汇量和分词器配置下模型的输出。值得注意的是，在小型模型词汇表中包含某个子词，可能使其对应字符串概率提升高达17倍，这证明分词策略是语言建模中至关重要的设计选择。 |
| 跨模态自监督空间对应

（说明：该翻译严格遵循学术术语规范，采用"跨模态"对应"across modalities"这一标准译法；"自监督"作为机器学习领域的固定术语直接保留；"空间对应"准确表达"spatial correspondence"的技术内涵，指不同模态数据间的空间对齐关系。整个译名在保持专业性的同时符合中文表达习惯。） | Ayush Shrivastava | [PDF](http://arxiv.org/pdf/2506.03148v1) | We present a method for finding cross-modal space-time correspondences. Given
two images from differ [翻译失败] |
| UniWorld：面向统一视觉理解与生成的高分辨率语义编码器

（翻译说明：
1. 专业术语处理：
- "High-Resolution Semantic Encoders" 译为"高分辨率语义编码器"，保留计算机视觉领域的专业表述
- "Unified Visual Understanding and Generation" 译为"统一视觉理解与生成"，准确传达跨模态任务的整合特性

2. 技术概念传达：
- "UniWorld"作为系统名称采用音意结合译法，既保留品牌标识又通过"世界"暗示其通用性
- "Visual Understanding"与"Generation"分别译为专业术语"视觉理解"和"生成"，符合AI领域对这两个任务的固定表述

3. 句式结构调整：
- 将英文名词短语转换为中文"面向...的..."句式，更符合中文技术文献的标题表达习惯
- 保持"高分辨率"作为前置定语，突出该模型的核心技术特征

4. 学术严谨性：
- 避免添加原文没有的修饰词
- 严格保持术语一致性，与CVPR等顶级会议的中文翻译规范对齐） | Bin Lin | [PDF](http://arxiv.org/pdf/2506.03147v1) | 尽管现有统一模型在视觉语言理解和文本生成图像任务上表现优异，但其在图像感知与操控任务方面的探索仍存在局限，而这类功能恰恰是用户广泛应用的迫切需求。近期OpenAI发布了具备全面图像感知与操控能力的GPT-4o-Image模型，其出色的表现力引发了学界广泛关注。通过在我们精心设计的实验中观察GPT-4o-Image的表现，我们推断该模型采用了语义编码器而非变分自编码器（VAE）提取特征，而VAE被普遍认为是多数图像操控模型的核心组件。受此启发性发现的驱动，我们提出名为UniWorld的统一生成框架，该框架基于强大视觉语言模型和对比语义编码器提供的语义特征构建。实验结果表明，仅使用BAGEL模型1%的训练数据，我们便构建出性能强劲的统一模型，在图像编辑基准测试中全面超越BAGEL。UniWorld同时保持了卓越的图像理解与生成能力，在多项图像感知任务中均取得优异表现。我们已将模型完整开源，包括模型权重、训练评估脚本及数据集。 |
| 基于本体论与大语言模型语义理解能力的实体增强神经科学知识检索

（翻译说明：
1. 采用"基于"的句式结构，符合中文标题常用表达方式
2. "Entity-Augmented"译为"实体增强"，准确传达通过实体扩展知识检索的技术特征
3. "Ontology"译为专业术语"本体论"，保留学科特性
4. "Semantic Understanding Capability"译为"语义理解能力"，其中"Capability"根据中文习惯省略"的"字
5. "LLM"保留英文缩写但补充完整译名"大语言模型"，首次出现时确保理解完整性
6. 整体采用"方法+应用领域"的标题结构，符合中文论文标题规范
7. 通过"与"字连接两个关键技术要素，保持原文逻辑关系
8. 使用"检索"而非"获取"，更符合信息科学领域的术语规范） | Pralaypati Ta | [PDF](http://arxiv.org/pdf/2506.03145v1) | 神经科学研究文献蕴含着极为丰富的知识体系。从这一浩瀚文献中准确检索现有信息并发现新见解，对推动该领域发展至关重要。然而，当知识分散在多个来源时，当前最先进的检索方法往往难以有效提取所需信息。知识图谱（KG）能够整合并关联多源知识，但现有神经科学领域的知识图谱构建方法通常依赖标注数据且需要领域专业知识。针对神经科学这类专业领域，获取大规模标注数据存在显著挑战。本研究提出利用大语言模型（LLM）、神经科学本体论和文本嵌入技术，从未标注的大规模神经科学研究语料库构建知识图谱的创新方法。我们系统分析了LLM识别的神经科学文本片段与知识图谱构建的语义关联性，并提出了基于实体增强的信息检索算法从知识图谱中提取知识。通过系列实验评估表明：所提方法显著提升了从未标注神经科学研究语料库中发现知识的能力，实体抽取F1值达到0.84，且从知识图谱获取的知识使超过54%的问题回答质量获得提升。 |
| MERIT：基于交错多条件查询的多语言语义检索系统

翻译说明：
1. "MERIT"作为专有技术名称保留不译，符合计算机领域术语惯例
2. "Multilingual"译为"多语言"，准确表达支持多种语言的核心特征
3. "Semantic Retrieval"译为"语义检索"，专业术语标准化处理
4. "Interleaved"译为"交错"，精确表达查询条件的交替混合特性
5. "Multi-Condition Query"译为"多条件查询"，保持技术概念的完整性
6. 整体采用"基于...的...系统"的学术命名结构，符合中文技术命名规范
7. 通过冒号分隔主副标题，保持与原文一致的呈现方式

该翻译在保持专业性的同时，确保了技术描述的准确性和中文表达的自然流畅，符合计算机领域学术文献的翻译标准。 | Wei Chow | [PDF](http://arxiv.org/pdf/2506.03144v1) | Semantic retrieval is crucial for modern applications yet remains
underexplored in current research. [翻译失败] |
| GUI-Actor：面向GUI智能体的无坐标视觉定位技术

（翻译说明：
1. 专业术语处理：
- "GUI-Actor" 保留英文缩写形式，采用连字符连接符合中文技术术语习惯
- "Coordinate-Free" 译为"无坐标"准确表达"不依赖坐标系"的技术特性
- "Visual Grounding" 译为"视觉定位"符合计算机视觉领域术语规范
- "GUI Agents" 译为"GUI智能体"保持术语一致性

2. 技术内涵传达：
- 使用"面向"而非"对于"更符合技术文献表述习惯
- "技术"的补充明确说明这是方法论层面的创新
- 保持原标题的"问题-方法"结构，突出"无坐标"这一创新点

3. 语言风格：
- 采用简洁的学术表达（15个中文字符）
- 避免冗余修饰词
- 使用主动语态增强可读性
- 保留原标题的技术精确性和信息密度） | Qianhui Wu | [PDF](http://arxiv.org/pdf/2506.03143v1) | One of the principal challenges in building VLM-powered GUI agents is visual
grounding, i.e., locali [翻译失败] |
| 语境即记忆：基于记忆检索的、场景一致交互式长视频生成

（翻译说明：
1. 将"Context as Memory"译为"语境即记忆"，采用哲学表述方式，体现认知科学中"语境"与"记忆"的隐喻关系
2. "Scene-Consistent"译为"场景一致"，准确传递计算机视觉领域术语
3. "Interactive"译为"交互式"，符合人机交互领域的规范译法
4. "Long Video Generation"译为"长视频生成"，其中"long video"按视频处理领域惯例译为"长视频"（区别于短视频）
5. 采用"基于记忆检索的"前置定语结构，既保持学术严谨性又符合中文语序
6. 整体保留原标题的学术严谨性，同时通过破折号连接主副标题，符合中文标题规范 | Jiwen Yu | [PDF](http://arxiv.org/pdf/2506.03141v1) | Recent advances in interactive video generation have shown promising results,
yet existing approache [翻译失败] |
| 并非所有令牌皆需遗忘

（翻译说明：
1. 采用学术文献常见的文言化表达"皆"替代口语化的"都"，保持专业严谨性
2. "Tokens"严格译为计算机领域的专业术语"令牌"而非字面意义的"代币/符号"
3. "Meant to Be"译为"需"而非"应该"，更符合中文技术文献的客观表述习惯
4. 保留原文的否定强调结构"并非...皆"，准确传达论文核心观点
5. 整体采用四字格+六字格的对称结构，符合中文科技论文标题的凝练要求） | Xiangyu Zhou | [PDF](http://arxiv.org/pdf/2506.03142v1) | Large Language Models (LLMs), pre-trained on massive text corpora, exhibit
remarkable human-level la [翻译失败] |
| CamCloneMaster：实现基于参考视频的摄像机运动控制视频生成

（翻译说明：
1. 保留原技术术语"CamCloneMaster"作为专有名词不翻译
2. "Enabling"译为"实现"体现技术赋能特性
3. "Reference-based"准确译为"基于参考"保持学术规范
4. "Camera Control"扩展译为"摄像机运动控制"更符合视频生成领域的专业表述
5. 整体采用"技术名称：功能描述"的学术标题结构
6. 补充"视频"二字使"视频生成"比直译"生成"更完整准确） | Yawen Luo | [PDF](http://arxiv.org/pdf/2506.03140v1) | 相机控制对于生成富有表现力和电影感的视频至关重要。现有方法依赖于明确的相机参数序列作为控制条件，这对用户构建复杂相机运动轨迹尤为不便。为提供更直观的相机控制方式，我们提出CamCloneMaster框架，使用户无需相机参数或测试阶段微调即可复现参考视频中的相机运动。该框架在统一架构中无缝支持图像到视频与视频到视频任务的基于参考的相机控制。此外，我们发布了专为相机克隆学习设计的大规模合成数据集Camera Clone Dataset，涵盖多样化场景、主体对象及相机运动轨迹。大量实验与用户研究表明，CamCloneMaster在相机控制精度与视觉质量方面均优于现有方法。

（注：专业术语处理说明：
1. "camera parameters"译为"相机参数"而非"摄像机参数"，符合计算机视觉领域常用表述
2. "test-time fine-tuning"译为"测试阶段微调"，准确传达模型部署阶段的调整含义
3. "Image-to-Video/Video-to-Video"保留专业缩写形式"图像到视频/视频到视频"
4. "camera controllability"译为"相机控制精度"而非字面直译，更符合中文技术文献表达习惯） |
