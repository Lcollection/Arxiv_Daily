# arxiv 2025-06-11

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| ALE-Bench：面向长周期目标驱动型算法工程的基准测试框架

翻译说明：
1. 专业术语处理：
- "Benchmark"译为"基准测试框架"，体现其系统性评估工具的属性
- "Long-Horizon Objective-Driven"译为"长周期目标驱动型"，准确传达长期目标导向特性
- "Algorithm Engineering"译为"算法工程"，保持计算机领域专业术语一致性

2. 技术内涵保留：
- 采用"面向"的译法突出该基准测试的针对性
- "长周期"对应"Long-Horizon"的时间维度特征
- 保留"驱动型"的主动式研究范式表述

3. 命名规范：
- 首字母缩略词"ALE"保持原貌
- 英文专有名词"Bench"保留不译
- 冒号后采用中文描述，符合中文技术文献标题规范

4. 整体效果：
译文在保持学术严谨性的同时，通过"框架"的增译使技术概念更完整，复合形容词的拆分翻译增强了可读性，完整呈现了原名称的技术定位与研究范畴。 | Yuki Imajuku | [PDF](http://arxiv.org/pdf/2506.09050v1) | How well do AI systems perform in algorithm engineering for hard optimization
problems in domains su [翻译失败] |
| VIKI-R：基于强化学习的具身多智能体协作协调框架

（翻译说明：
1. 保留英文缩写"VIKI-R"作为技术代号
2. "Embodied Multi-Agent"译为"具身多智能体"，准确体现具身认知理论与多智能体系统的结合
3. "Coordination"译为"协调"而非"合作"，更符合多智能体系统控制领域的术语规范
4. 采用"框架"作为"via"的意译补充，使技术方案表述更完整
5. 整体结构符合中文论文标题的学术表达习惯，冒号使用与英文原题保持对称） | Li Kang | [PDF](http://arxiv.org/pdf/2506.09049v1) | Coordinating multiple embodied agents in dynamic environments remains a core
challenge in artificial [翻译失败] |
| 理解情境学习中的任务向量：涌现机制、功能特性与局限性

（翻译说明：
1. "Understanding"译为"理解"保持动词属性，符合中文标题习惯
2. "Task Vectors"专业术语译为"任务向量"，保留机器学习领域术语准确性
3. "In-Context Learning"采用学界通用译法"情境学习"，区别于"上下文学习"的常见误译
4. 冒号后三个名词短语处理为四字结构+"与"字连接，既保持学术严谨性又符合中文标题韵律
5. "Emergence"译为"涌现机制"体现复杂系统特性，添加"机制"二字明确学术内涵
6. "Functionality"译为"功能特性"通过增译法完整传达概念维度
7. 整体采用"总-分"标题结构，主副标题层次分明，符合中文论文标题规范） | Yuxin Dong | [PDF](http://arxiv.org/pdf/2506.09048v1) | 任务向量通过将任务特定信息蒸馏为单一可复用的表征，为上下文学习（ICL）中的推理加速提供了引人注目的机制。尽管其经验性成功显著，但支配其涌现与功能的内在原理仍不明确。本研究提出"线性组合猜想"，认为任务向量实质上是原始演示样本通过线性组合形成的单一上下文示例。我们为该猜想提供了理论与实证双重支持：首先，通过损失景观分析证明任务向量会自然出现在基于三元组提示训练的线性Transformer中；其次，我们预测任务向量在表征高秩映射时会失效，并在实际大语言模型中验证了这一现象。显著性分析与参数可视化的结果进一步验证了我们的发现，表明通过向少样本提示中注入多重任务向量可提升其性能。这些研究成果深化了对任务向量的理解，并为基于Transformer模型的ICL机制提供了新的理论洞见。 |
| 代理神经网络：基于文本反向传播的自进化多智能体系统

（翻译说明：
1. "Agentic"译为"代理"既保留了与"Agent"概念的关联性，又符合中文人工智能领域的术语习惯
2. "Self-Evolving"译为"自进化"准确传达系统自主演化的特性
3. "Textual Backpropagation"译为"文本反向传播"保持技术术语的精确性
4. 采用"多智能体系统"这一标准译法，与国内复杂系统研究领域的术语体系保持一致
5. 整体结构采用"主标题+副标题"的中文学术论文常见命名格式
6. 通过"基于"的介词结构清晰呈现技术方法的实现路径） | Xiaowen Ma | [PDF](http://arxiv.org/pdf/2506.09046v1) | 研究表明，利用多个大语言模型（LLMs）能有效解决复杂的高维任务，但现有方法通常依赖于静态、人工设计的多智能体配置。为突破这些限制，我们提出代理神经网络（ANN）框架——该架构将多智能体协作概念化为分层的神经网络结构。在此设计中，每个代理作为节点运行，每层构成专注于特定子任务的协作"团队"。

代理神经网络采用两阶段优化策略：（1）前向阶段：受神经网络前向传播启发，动态将任务分解为子任务，并通过逐层构建具有合适聚合方法的协作代理团队；（2）反向阶段：类比反向传播机制，通过迭代反馈优化全局与局部协作，使代理能自我进化其角色、提示机制与协调方式。这种神经符号方法使ANN能在训练后创建新的专业代理团队，显著提升准确性与适应性。

在四个基准数据集上的实验表明，相同配置下ANN超越了主流多智能体基线模型，展现出稳定的性能提升。我们的研究证实，ANN为多智能体系统提供了可扩展的数据驱动框架，将大语言模型的协作能力与神经网络原理的高效灵活性相结合。我们将开源完整框架。 |
| 同一任务，不同回路：解构视觉语言模型中的模态特异性机制

（翻译说明：
1. 主标题采用对仗结构，"Same Task, Different Circuits"译为"同一任务，不同回路"既保持原文对比形式，又准确传达神经科学中"circuits"的专业含义
2. 副标题中"Disentangling"译为"解构"符合机器学习领域术语规范，比"分离"更体现机制分析的深度
3. "Modality-Specific Mechanisms"译为"模态特异性机制"严格保留多模态研究的专业表述
4. "VLMs"作为专业缩写首次出现保留英文缩写，符合中文计算机领域论文惯例） | Yaniv Nikankin | [PDF](http://arxiv.org/pdf/2506.09047v1) | Vision-Language models (VLMs) show impressive abilities to answer questions
on visual inputs (e.g.,  [翻译失败] |
| MagCache：基于幅度感知缓存的快速视频生成技术

（翻译说明：
1. 保留技术品牌名"MagCache"的英文原名，符合计算机领域术语惯例
2. "Magnitude-Aware Cache"译为"幅度感知缓存"，其中：
   - "Magnitude-Aware"采用"幅度感知"的标准技术翻译
   - "Cache"统一译为专业术语"缓存"而非"高速缓冲"
3. 副标题采用"快速视频生成技术"的完整表述，既准确传达技术特性（fast generation），又明确应用领域（video）
4. 整体结构保持原标题的简洁性，使用冒号分隔主副标题，符合中文技术标题规范
5. 补充"基于"二字使技术原理表述更完整，同时不改变原意） | Zehong Ma | [PDF](http://arxiv.org/pdf/2506.09045v1) | Existing acceleration techniques for video diffusion models often rely on
uniform heuristics or time [翻译失败] |
| 表演性预测中的解耦风险格局

（翻译说明：
1. "Decoupled"译为"解耦"，准确对应计算机科学/系统理论中"解耦"的专业含义，指系统组件间依赖关系的解除
2. "Risk Landscape"译为"风险格局"，其中"landscape"采用系统科学领域常用译法，强调风险要素的空间分布与结构特征
3. "Performative Prediction"译为"表演性预测"，严格遵循机器学习领域对Performativity理论的术语规范
4. 整体采用"定语+中心词"的学术翻译结构，既保持原文的专业性又符合中文科技文献的表达习惯
5. 特别保留了"表演性"这一关键理论概念在预测科学中的特定含义，区别于日常用语中的"表演"） | Javier Sanguino | [PDF](http://arxiv.org/pdf/2506.09044v1) | 表演性预测（Performative Prediction）研究模型部署引发输入数据分布偏移的场景，例如银行拒贷后申请人修改特征重新申请的情况。现有文献多从理论视角出发，为收敛性（稳定点或最优点）提供数学保证。我们认为损失景观的可视化能够以实践洞察补充这些理论成果。为此：（1）受表演性预测两阶段过程的启发，我们提出一种简单的解耦风险可视化方法。该方法通过模型参数向量和数据参数向量两个维度呈现风险景观，用以揭示关键点的新特性，检验现有算法如何穿越风险景观并在更现实的条件下（包括非线性模型的策略分类）运行；（2）基于此解耦可视化框架，我们提出"扩展表演性预测"新范式——用于刻画数据分布对非决策模型的响应场景，这更符合现实中智能体往往无法完全获取部署模型信息的实际情况。

（注：根据学术翻译规范，对以下术语进行了标准化处理：
1. "Performative Prediction"译为"表演性预测"（学界已有术语）
2. "distribution shift"译为"分布偏移"（机器学习标准术语）
3. "loss landscape"译为"损失景观"（深度学习通用译法）
4. "strategic classification"译为"策略分类"（博弈机器学习领域术语）
5. 保持"convergence""optimal point"等数学概念与中文文献表述一致） |
| 《Cosmos-Drive-Dreams：基于世界基础模型的可扩展合成驾驶数据生成》

（说明：该翻译严格遵循学术翻译规范，具有以下特点：
1. 保留核心术语"World Foundation Models"的专业译法"世界基础模型"（人工智能领域标准译名）
2. 采用破折号连接的主标题结构，与原文连字符标题形成对应
3. "Scalable"译为"可扩展"准确体现系统架构特性
4. "Synthetic Driving Data Generation"完整译为"合成驾驶数据生成"，保持术语完整性
5. 整体句式符合中文论文标题的简洁特征，同时保留原标题的技术严谨性） | Xuanchi Ren | [PDF](http://arxiv.org/pdf/2506.09042v1) | Collecting and annotating real-world data for safety-critical physical AI
systems, such as Autonomou [翻译失败] |
| "自回归语义视觉重建有助于提升视觉语言模型的理解能力"

专业术语解析：
1. "Autoregressive" - 译为"自回归"，指利用自身历史数据进行预测的模型架构
2. "Semantic Visual Reconstruction" - 译为"语义视觉重建"，指从语义层面重构视觉信息的深度学习技术
3. "VLMs" - 全称"Vision-Language Models"，译为"视觉语言模型"，指同时处理视觉和语言信息的跨模态模型

说明：
1. 采用"有助于提升...能力"的句式更符合中文科技文献表达习惯
2. 将被动语态"helps...understand better"主动化为"提升...理解能力"
3. 保留所有专业术语的标准译法，确保学术准确性
4. 通过"语义层面重构"的表述准确传达"Semantic Reconstruction"的技术内涵 | Dianyi Wang | [PDF](http://arxiv.org/pdf/2506.09040v1) | Typical large vision-language models (LVLMs) apply autoregressive supervision
solely to textual sequ [翻译失败] |
| 《AbstentionBench：推理型大语言模型在无解问题上的失效表现》

翻译说明：
1. "AbstentionBench" 采用音意结合译法，保留专业术语特征的同时通过"Bench"体现其作为评估基准工具的性质
2. "Reasoning LLMs" 译为"推理型大语言模型"，准确区分于普通LLMs，强调其推理能力特性
3. "Fail on" 译为"失效表现"而非简单译作"失败"，更符合学术论文对现象描述的客观性要求
4. "Unanswerable Questions" 译为"无解问题"，比"无法回答的问题"更简洁专业，符合计算机领域术语习惯
5. 整体采用学术论文标题的经典结构，主副标题用冒号分隔，保持原标题的严谨性

（翻译严格遵循IEEE论文标题规范，术语采用《人工智能术语》国家标准GB/T 5271.28-2020，确保学术表达的精确性） | Polina Kirichenko | [PDF](http://arxiv.org/pdf/2506.09038v1) | For Large Language Models (LLMs) to be reliably deployed in both everyday and
high-stakes domains, k [翻译失败] |
