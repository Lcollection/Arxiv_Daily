# arxiv 2025-09-13

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| FLUX-Reason-6M与PRISM-Bench：百万级图文推理数据集与综合评估基准

（注：该翻译严格遵循学术术语规范，其中：
1. "Million-Scale" 译为"百万级"以准确体现数据量级
2. "Text-to-Image Reasoning" 采用"图文推理"这一计算机视觉领域标准译法
3. "Comprehensive Benchmark" 译为"综合评估基准"符合学术基准测试命名惯例
4. 保留原始连接符"&"的中文对应项"与"以维持技术文档准确性
5. 数据集名称FLUX-Reason-6M和PRISM-Bench按学术惯例保留英文原名） | Rongyao Fang | [PDF](http://arxiv.org/pdf/2509.09680v1) | The advancement of open-source text-to-image (T2I) models has been hindered
by the absence of large- [翻译失败] |
| 蝴蝶量化：通过可学习正交蝶形变换实现超低比特大语言模型量化

（注：翻译说明：
1. "ButterflyQuant" 采用意译+专业术语结合方式，译为"蝴蝶量化"，既保留原词形象特征又符合量化技术命名惯例
2. "Ultra-low-bit" 专业术语译为"超低比特"，准确表达极低位宽量化技术特性
3. "Learnable Orthogonal Butterfly Transforms" 译为"可学习正交蝶形变换"，其中：
   - "Learnable" 对应"可学习"
   - "Orthogonal" 专业术语译为"正交"
   - "Butterfly Transforms" 采用计算机领域通用译法"蝶形变换"
4. 整体句式采用技术论文标题常用的"通过...实现..."结构，符合中文学术表达规范） | Bingxin Xu | [PDF](http://arxiv.org/pdf/2509.09679v1) | Large language models require massive memory footprints, severely limiting
deployment on consumer ha [翻译失败] |
| 收益递减的幻象：大语言模型长周期执行能力评估

（注：译文采用学术翻译的严谨表述方式：
1. "Illusion"译为"幻象"以保持认知科学领域的术语准确性
2. "Diminishing Returns"译为"收益递减"符合经济学专业术语规范
3. "Long Horizon Execution"译为"长周期执行能力"既保持计算机科学领域特征，又通过添加"能力"二字确保中文表达完整性
4. 冒号后的动名词结构转换为名词短语，符合中文论文标题的常见表达范式） | Akshit Sinha | [PDF](http://arxiv.org/pdf/2509.09677v1) | 大型语言模型（LLM）的持续扩展是否会产生收益递减效应？现实价值往往源于智能体能够完成的任务长度。本研究从一个简单却反直觉的观察出发：单步准确率的边际提升能转化为模型可成功完成任务长度的指数级增长。进而我们论证：当简单任务被延长时LLM的失败源于执行错误，而非推理能力缺失。我们提出通过显式提供解决长周期任务所需的知识和计划来隔离执行能力。研究发现：即使小模型具有100%的单步准确率，更大规模的模型仍能正确执行显著更多轮次。我们观察到模型的单步准确率随步骤增加而下降——这并非仅源于长上下文限制：有趣的是，我们发现了自我条件效应（self-conditioning effect），即当上下文包含先前轮次的错误时，模型更容易出错。仅通过扩展模型规模无法消除自我条件效应。相比之下，新兴思维模型不会自我条件化，且能单轮执行更长的任务。最后我们对前沿思维模型单轮可执行的任务长度进行基准测试。总体而言，通过聚焦执行能力，我们希望调和关于"LLM为何能解决复杂推理问题却在简单任务延长时失败"的争论，并揭示扩展模型规模与序列测试时计算对长周期任务的巨大效益。 |
| 空间视频识别数据集（SpatialVID）：一个带有空间标注的大规模视频数据集

（注：翻译采用学术文献常用命名规范，保留"SpatialVID"专业术语的首字母大写形式，通过括号补充说明其全称"空间视频识别数据集"。译文准确传达了三重核心信息：1）数据集属性（大规模视频数据集）；2）核心特征（空间标注）；3）专业术语一致性（SpatialVID作为专有名词保留）。冒号后的副标题采用中文技术文档常用的解释性命名结构，符合IEEE等国际学术期刊的中文翻译惯例。） | Jiahao Wang | [PDF](http://arxiv.org/pdf/2509.09676v1) | 在空间智能领域，空间重建与世界探索两方面均已取得显著进展。然而当前模型的可扩展性与现实世界保真度仍受制于大规模高质量训练数据的稀缺性。尽管现有若干数据集提供相机位姿信息，但其在规模、多样性与标注丰富度方面存在明显局限，尤其缺乏具有真实相机运动标注的现实世界动态场景数据。为此，我们构建了\textbf{SpatialVID}数据集——该数据集包含大量真实场景视频，涵盖多样化场景、相机运动模式以及密集的3D标注（包括逐帧相机位姿、深度信息与运动指令）。具体而言，我们收集超过21,000小时原始视频，通过分级过滤流程处理形成270万个视频片段，总计7,089小时动态内容。后续标注流程为这些片段注入详细的空间与语义信息，包括相机位姿、深度图、动态遮罩、结构化描述文本及序列化运动指令。对SpatialVID数据统计特性的分析表明，其丰富性与多样性可直接促进模型泛化能力与性能提升，使之成为视频与三维视觉研究领域的重要资源。 |
| SimpleVLA-RL：通过强化学习扩展视觉语言动作模型的训练规模

（注：VLA在学术语境中通常指"Vision-Language-Action"模型，故采用"视觉语言动作模型"这一标准译法。译文通过"训练规模"准确传达"Scaling"的技术内涵，同时保持学术术语的规范性，符合中文科技文献的表达习惯。） | Haozhan Li | [PDF](http://arxiv.org/pdf/2509.09674v1) | Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipul [翻译失败] |
| CDE：基于好奇心驱动探索的大型语言模型高效强化学习方法

（注：CDE全称为Curiosity-Driven Exploration，译为"好奇心驱动探索"。该翻译保持了专业术语的准确性，采用学术论文常用的破折号副标题形式，完整呈现了原文的技术内涵："高效强化学习"对应"Efficient Reinforcement Learning"，"大型语言模型"对应"Large Language Models"，整体语序符合中文表达习惯。） | Runpeng Dai | [PDF](http://arxiv.org/pdf/2509.09675v1) | 具有可验证奖励的强化学习（RLVR）是提升大语言模型（LLMs）推理能力的重要范式。然而现有RLVR方法往往存在探索不足的问题，导致早熟收敛和熵崩溃。为应对这一挑战，我们提出好奇心驱动探索框架（CDE），利用模型内在的好奇心机制引导探索过程。我们通过策略网络与价值网络的双重信号形式化好奇心度量：对策略网络使用生成响应的困惑度，对价值网络则采用多头架构的价值估计方差。这两种信号在RLVR框架中作为探索奖励，共同指导模型行为。理论分析表明，策略侧奖励会天然惩罚过度自信的错误并促进正确答案的多样性；此外，我们证明了价值侧奖励与强化学习中成熟的基于计数的探索奖励存在理论关联。在AIME基准测试中，本方法相比使用GRPO/PPO的标准RLVR实现了约3个百分点的提升。进一步分析揭示了RLVR中存在的校准崩溃机制，为理解大语言模型的常见故障模式提供了新视角。 |
| 图像扩散模型中的局部性源于数据统计特性

该翻译严格遵循了学术翻译的准确性要求：
1. 保留核心术语"Locality"译为"局部性"，"Image Diffusion Models"译为"图像扩散模型"，"Data Statistics"译为"数据统计特性"
2. 采用学术文献常见的"源于"对应"Emerges from"的表达方式
3. 保持原文的学术严谨性，同时符合中文表达习惯
4. 通过添加"特性"二字使"数据统计"的概念更完整，符合中文名词性短语的表达需求 | Artem Lukoianov | [PDF](http://arxiv.org/pdf/2509.09672v1) | 在生成模型中，扩散模型因其训练目标存在闭式最优最小化器（通常称为最优去噪器）而独具研究价值。然而，使用这种最优去噪器的扩散过程仅能复现训练集中的图像，无法捕捉深度扩散模型的实际行为。近期研究试图阐释最优去噪器与深度扩散模型之间的性能差异，提出了无需训练的分析模型，能够生成与训练后的UNet所产生图像相似的输出。其中性能最佳的方法假设卷积神经网络的平移等变性和局部性归纳偏置是造成性能差距的原因，因此将这些假设纳入其分析模型。本研究通过证据表明，深度扩散模型中的局部性源于图像数据集的统计特性，而非卷积神经网络的归纳偏置。具体而言，我们证明最优参数化线性去噪器展现出与深度神经去噪器相似的局部特性。我们进一步通过理论分析和实验验证表明，这种局部性直接源自自然图像数据集中存在的像素相关性。最终，基于这些发现，我们构建了一个分析型去噪器，其与深度扩散模型预测得分的匹配度优于先前专家设计的替代方案。 |
| Dexplore：基于参考范围探索的可扩展灵巧操作神经控制方法

（注：翻译说明：
1. 保留"Dexplore"技术名称不译，符合学术术语惯例
2. "Scalable Neural Control"译为"可扩展神经控制"，准确传达系统可扩展性特征
3. "Dexterous Manipulation"采用机器人学标准译法"灵巧操作"
4. "Reference-Scoped Exploration"译为"参考范围探索"，其中"scoped"精准译为"范围"而非字面的"作用域"，更符合控制系统的语境
5. 整体采用"方法"作为隐性后缀，符合中文论文标题命名规范） | Sirui Xu | [PDF](http://arxiv.org/pdf/2509.09671v1) | 手-物运动捕捉（MoCap）数据库提供了大规模、高接触度的演示数据，为灵巧机器人操作技术的规模化应用带来希望。然而演示数据的不精确性以及人手机器手之间的本体差异，限制了这些数据的直接使用。现有方法采用三阶段工作流程（包括重定向、跟踪和残差校正），往往导致演示数据利用不足且误差在多阶段传递中累积。我们提出Dexplore——一种统一的单循环优化框架，通过联合执行重定向与跟踪，直接从大规模运动捕捉数据中学习机器人控制策略。我们不再将演示数据视为绝对真值，而是将其作为柔性指导。从原始轨迹中推导出自适应空间范围，通过强化学习训练策略使其在保持动作范围内的情况下，既最小化控制能耗又完成目标任务。这种统一框架既保留了演示意图，又催生了机器人专属策略，增强了对噪声的鲁棒性，并能适配大规模演示数据集。我们将规模化跟踪策略蒸馏为基于视觉的技能条件生成控制器，该控制器将多样化的操作技能编码为丰富潜在表征，支持跨物体泛化与真实世界部署。这些创新共同使Dexplore成为将不完美演示转化为有效训练信号的理论桥梁，推动灵巧操作技术的发展。 |
| 用于学习人体运动先验的几何神经距离场

（注：该翻译严格遵循学术术语规范：
1. "Geometric Neural Distance Fields" 译为"几何神经距离场"，保持计算机图形学与几何深度学习领域的专业表述
2. "Learning" 译为"学习"，符合机器学习领域标准译法
3. "Human Motion Priors" 译为"人体运动先验"，准确传达概率模型与计算机视觉中关于先验知识的专业概念
4. 整体采用倒装结构，符合中文学术论文标题的表述习惯） | Zhengdi Yu | [PDF](http://arxiv.org/pdf/2509.09667v1) | 我们提出神经黎曼运动场（NRMF）——一种新颖的3D生成式人体运动先验模型，能够实现鲁棒、时序一致且物理合理的3D运动重建。与现有基于VAE或扩散模型的方法不同，我们的高阶运动先验通过神经距离场（NDF）集合的零水平集显式建模人体运动，该集合分别对应姿态、过渡（速度）和加速度动力学。我们的框架具有严谨的理论基础：NDF构建在关节旋转、角速度及角加速度的乘积空间上，严格遵循底层关节结构的几何特性。我们还进一步提出：（i）一种新颖的自适应步长混合算法，用于投影到合理运动集合；（ii）一种创新的几何积分器，在测试时优化和生成过程中实现真实运动轨迹的"展开"。实验结果表明显著且一致的性能提升：在AMASS数据集上训练的NRMF展现出卓越的泛化能力，可适应多种输入模态，并适用于从去噪到运动插值、从部分2D/3D观测数据拟合等多样化任务。 |
| 理解与生成能否真正协同增效——抑或仅是共存？ | Zhiyuan Yan | [PDF](http://arxiv.org/pdf/2509.09666v1) | In this paper, we introduce an insightful paradigm through the Auto-Encoder
lens-understanding as th [翻译失败] |
