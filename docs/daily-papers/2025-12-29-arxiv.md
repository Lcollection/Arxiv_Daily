# arxiv 2025-12-29

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 见少识广：双向感知塑造在多模态推理中的应用 | Shuoshuo Zhang | [PDF](https://arxiv.org/pdf/2512.22120v1) | 大型视觉语言模型（VLMs）通常受益于中间视觉线索的辅助，这些线索或通过外部工具注入，或在推理过程中生成为潜在视觉标记，但现有机制仍存在以下局限：忽视细粒度视觉证据（如图表中的折线）、跨领域泛化能力不足，且推理时计算成本高昂。本文提出双向感知塑形方法（BiPS），该方法将问题导向的掩码视图转化为双向视觉引导信号，在训练过程中动态塑造模型的感知机制。BiPS首先在原始图像与证据保留视图之间施加KL一致性约束——后者仅保留问题相关区域，从而确保对支撑性像素实现粗粒度但完整的覆盖；随后在原始图像与证据消融视图之间施加KL分离约束——后者通过掩码关键像素使图像无法支撑原答案，以此抑制纯文本捷径（即仅依赖文本作答），并强化对细粒度视觉特征的依赖。在八项基准测试中，BiPS使Qwen2.5-VL-7B模型平均性能提升8.2%，并在未见数据集与图像类型上展现出强大的跨领域泛化能力。 |
| ProEdit：基于提示词反演的精准编辑技术 | Zhi Ouyang | [PDF](https://arxiv.org/pdf/2512.22118v1) | 基于反转的视觉编辑提供了一种无需训练即可根据用户指令编辑图像或视频的有效方法。现有方法通常在采样过程中注入源图像信息以保持编辑一致性。然而，这种采样策略过度依赖源信息，会对目标图像的编辑产生负面影响（例如无法按指令改变主体的姿态、数量或颜色等属性）。本研究提出ProEdit方法，从注意力机制和潜在空间两个层面解决这一问题。在注意力层面，我们引入KV混合机制，在编辑区域混合源图像与目标图像的键值特征，既减轻源图像对编辑区域的影响，又保持背景一致性。在潜在空间层面，我们提出潜在偏移技术，通过对源潜在空间的编辑区域施加扰动，消除反转潜在向量对采样的影响。在多个图像与视频编辑基准测试上的大量实验表明，我们的方法达到了当前最优性能。此外，我们的设计具备即插即用特性，可无缝集成到现有反转与编辑方法中，例如RF-Solver、FireFlow和UniEdit等。 |
| 面向云应用代码相关事件根因分析的代理结构化图遍历方法 | Shengkun Cui | [PDF](https://arxiv.org/pdf/2512.22113v1) | 云服务故障在生产环境中构成重大运营挑战，未解决的云端生产事故平均每小时造成超过200万美元损失。已有研究指出，代码与配置相关问题构成云事故根本原因的主要类别。本文提出PRAISIS——一个用于诊断代码与配置引发云事故的智能体工作流编排器。该系统采用大语言模型驱动的结构化遍历机制，对两类图谱进行协同分析：（1）记录微服务级依赖关系的服务依赖图；（2）为每个微服务构建的代码级依赖关系程序依赖图。通过融合微服务与代码双重依赖信息，大语言模型作为图谱遍历策略引擎，在服务节点与代码依赖路径间动态定位故障根源并生成解释。相较于前沿的ReAct基线方法，PRAXIS将根本原因分析准确率最高提升3.1倍，同时降低3.8倍令牌消耗量。该系统已在30个涵盖多场景的真实事故案例中得到验证，相关数据集正在整合为根本原因分析基准测试集。 |
| 剪枝如博弈：基于均衡驱动的神经网络稀疏化 | Zubair Shah | [PDF](https://arxiv.org/pdf/2512.22106v1) | 神经网络剪枝被广泛用于减小模型规模与计算开销。然而，现有方法大多将稀疏性视为外部强加的约束，通过启发式重要性评分或训练时正则化实现。本研究提出一个根本不同的视角：将剪枝视为模型组件间策略交互的均衡结果。我们将权重、神经元或滤波器等参数组建模为连续非合作博弈中的参与者，每个参与者通过选择其在网络中的参与程度，以平衡自身贡献与冗余度及竞争关系。在此框架下，当持续参与在均衡状态下成为被支配策略时，稀疏性便自然涌现。我们分析了由此产生的博弈过程，证明在温和条件下被支配的参与者会收敛至零参与度，从而为剪枝行为提供了理论解释。基于这一洞见，我们推导出一种简单的均衡驱动剪枝算法，该算法无需依赖显式重要性评分，可同步更新网络参数与参与变量。本研究侧重于建立剪枝作为均衡现象的理论框架并进行实证验证，而非追求架构探索或大规模基准测试。在标准基准上的实验表明，所提方法在实现具有竞争力的稀疏度-精度权衡的同时，为现有剪枝方法提供了可解释且理论依据充分的替代方案。 |
| 通过轨迹检测匹配实现多目标跟踪中的关联学习 | Momir Adžemović | [PDF](https://arxiv.org/pdf/2512.22105v1) | 多目标跟踪旨在通过关联视频帧间的检测结果，在时间维度上维持目标身份的一致性。现有研究主要存在两种主流范式：基于检测的跟踪方法计算效率高，但依赖人工设计的关联启发式规则；端到端方法虽能从数据中学习关联关系，却以更高的计算复杂度为代价。本文提出轨迹-检测链接预测方法，这是一种基于检测的跟踪框架，通过轨迹与检测结果之间的链接预测实现逐帧关联，即在每一帧预测每条轨迹的正确延续路径。该方法在架构设计上主要针对边界框等几何特征进行优化，同时可选择性地融合姿态、外观等附加线索。与基于启发式规则的方法不同，TDLP无需人工规则即可直接从数据中学习关联关系，同时相较于端到端跟踪器仍保持模块化特性与计算高效性。在多个基准测试上的大量实验表明，TDLP在基于检测的跟踪与端到端方法中均持续超越现有最优性能。最后，我们通过详细分析对比了链接预测与基于度量学习的关联方法，证明链接预测在处理检测边界框等异构特征时更具优势。代码已开源：\href{https://github.com/Robotmurlock/TDLP}{https://github.com/Robotmurlock/TDLP}。 |
| 可解释多模态回归：基于信息分解的方法 | Zhaozhao Ma | [PDF](https://arxiv.org/pdf/2512.22102v1) | 多模态回归旨在从异构输入源中预测连续目标，通常依赖于早期或晚期融合等策略。然而，现有方法缺乏系统化工具来解耦和量化各模态的个体贡献及其交互作用，限制了多模态融合的可解释性。我们提出了一种基于部分信息分解（PID）的新型多模态回归框架，该框架将模态特定表征分解为独特、冗余和协同三个组成部分。基础PID框架本身具有欠定性，为解决这一问题，我们通过强制潜在表征与变换后响应变量（经逆正态变换后）的联合分布满足高斯性来引入归纳偏置，从而实现对PID项的解析计算。此外，我们推导出闭式条件独立性正则化器，以促进各模态内独特信息的分离。在六个真实世界数据集（包括基于多模态神经影像数据的大规模脑年龄预测案例研究）上的实验表明，我们的框架在预测准确性和可解释性方面均优于现有先进方法，同时还能为高效推理提供基于信息的模态选择方案。代码实现详见 https://github.com/zhaozhaoma/PIDReg。 |
| A2P-Vis：一种面向视觉洞察生成与报告的分析器至呈现器代理流程 | Shuyu Gan | [PDF](https://arxiv.org/pdf/2512.22101v1) | 利用AI智能体实现端到端数据科学流程的自动化，目前仍面临两大瓶颈：生成具有洞察力且多样化的可视化证据，以及将其整合为条理清晰的专业报告。我们提出A2P-Vis——一个由两部分构成的多智能体流程，能够将原始数据集转化为高质量的数据可视化报告。数据分析器负责统筹数据画像分析，提出多样化的可视化方向，生成并执行绘图代码，通过可读性检查器筛选低质量图表，并提取候选洞察点，这些洞察点将自动从深度、准确性、特异性、深刻性和可操作性五个维度进行评分。随后，报告生成器对主题进行排序，基于评分最高的洞察点撰写以图表为支撑的叙述内容，补充合理的过渡衔接，并对文档进行清晰度与一致性的修订，最终形成条理清晰、可直接交付的完整报告。这两个智能体协同工作，无需人工干预即可将原始数据转化为精编材料（图表+验证过的洞察点），并组织成可读性强的叙述文本。我们认为，通过将质量可控的分析器与叙事型报告生成器相结合，A2P-Vis实现了端到端的协同分析操作化，提升了自动化数据分析在实际应用中的实用价值。完整数据集报告详见：https://www.visagent.org/api/output/f2a3486d-2c3b-4825-98d4-5af25a819f56。 |
| 引入TrGLUE与SentiTurca：土耳其语通用语言理解与情感分析综合基准测试集 | Duygu Altinok | [PDF](https://arxiv.org/pdf/2512.22100v1) | 评估各类模型架构（如Transformer、大语言模型及其他自然语言处理系统）的性能，需要能够从多维度衡量性能的综合基准。其中，自然语言理解能力的评估尤为关键，因其是衡量模型能力的根本标准。因此，建立能够从多角度对自然语言理解能力进行全面评估与分析的基准至关重要。尽管GLUE基准已为英语自然语言理解评估树立了标准，其他语言也相继开发了类似基准，如中文的CLUE、法语的FLUE和日语的JGLUE。然而，目前土耳其语尚缺乏可与之比肩的评估基准。为填补这一空白，我们推出了TrGLUE——一个涵盖多种土耳其语自然语言理解任务的综合基准。此外，我们还提出了专门用于情感分析的SentiTurca基准。为支持研究者，我们同时提供了基于Transformer模型的微调与评估代码，以促进这些基准的有效使用。TrGLUE包含精心构建的土耳其语原生语料库，其设计旨在反映GLUE式评估的领域范围与任务框架，标签通过半自动化流程获取——该流程融合了基于大语言模型的强标注、跨模型一致性校验及后续人工验证。这一设计优先保障语言自然度，最大限度减少直接翻译带来的伪影，并形成了可扩展、可复现的工作流程。通过TrGLUE，我们的目标是建立坚实的土耳其语自然语言理解评估框架，为研究者提供宝贵资源，并为生成高质量半自动化数据集提供方法论洞见。 |
| Yume-1.5：一种基于文本控制的交互式世界生成模型 | Xiaofeng Mao | [PDF](https://arxiv.org/pdf/2512.22096v1) | 近期研究展示了利用扩散模型生成交互式可探索世界的潜力。然而，现有方法大多面临参数量过大、依赖冗长推理步骤、历史上下文快速增长等关键挑战，严重制约实时性能且缺乏文本控制生成能力。为应对这些挑战，我们提出\method——一个从单张图像或文本提示生成逼真、交互式连续世界的新型框架。该框架通过精心设计的架构支持基于键盘的生成世界探索，其核心包含三个组成部分：(1) 融合统一上下文压缩与线性注意力的长视频生成框架；(2) 基于双向注意力蒸馏与增强文本嵌入方案的实时流式加速策略；(3) 面向世界事件生成的文本控制方法。相关代码库已附于补充材料中。 |
| 统一学习动态与泛化：Transformer缩放定律研究 | Chiwun Yang | [PDF](https://arxiv.org/pdf/2512.22088v1) | 缩放定律作为大语言模型（LLM）发展的基石，其核心在于预测模型性能会随着计算资源的增加而提升。尽管该定律已得到实证验证，但其理论根基仍不甚明晰。本研究将基于Transformer的语言模型学习动态形式化为常微分方程（ODE）系统，进而将该过程近似为核行为。与先前简化模型分析不同，我们严格分析了多层Transformer在任意数据分布的序列到序列数据上采用随机梯度下降（SGD）训练的过程，紧密贴合现实场景。通过分析，我们刻画了泛化误差随计算资源与数据规模扩展而收敛至固有风险的过程，特别是在优化阶段的表现。

我们建立了具有明显相变特征的超额风险理论上界。在初始优化阶段，超额风险相对于计算成本${\sf C}$呈指数级衰减。然而，当超过特定资源分配阈值后，系统进入统计阶段，此时泛化误差遵循$Θ(\mathsf{C}^{-1/6})$的幂律衰减规律。在此统一框架之外，我们的理论还推导出模型规模、训练时长与数据集规模的独立缩放定律，阐明了各变量如何分别主导泛化误差的上界。 |
