# arxiv 2025-07-08

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 《超越单帧，突破单一视角：跨视角与长时距蒸馏提升LiDAR表征性能》

（说明：这个翻译版本严格遵循了学术术语的规范，同时兼顾中文表达习惯：
1. "Beyond"译为"超越/突破"体现学术创新性
2. "One Shot"专业术语译为"单帧"符合计算机视觉领域表述
3. "Distillation"保留"蒸馏"这一机器学习标准译法
4. "Cross-View"和"Long-Horizon"分别译为"跨视角"与"长时距"准确传达时空维度特性
5. 通过冒号分层保持原标题的学术论文结构特征
6. 添加书名号符合中文论文标题格式要求） | Xiang Xu | [PDF](http://arxiv.org/pdf/2507.05260v1) | 激光雷达表征学习旨在从大规模易获取的数据集中提取丰富的结构与语义信息，从而降低对昂贵人工标注的依赖。然而现有激光雷达表征策略往往忽视点云序列中固有的时空线索，制约了其有效性。本研究提出LiMA框架——一种创新的长时图像-激光雷达记忆聚合方法，通过显式捕获长程时序关联来增强激光雷达表征学习。该框架包含三个核心组件：1）跨视角聚合模块，通过对齐与融合相邻相机视角的重叠区域，构建更统一且无冗余的记忆库；2）长时特征传播机制，高效对齐并整合多帧图像特征，强化激光雷达表征学习中的时序连贯性；3）跨序列记忆对齐策略，通过加强不同驾驶序列间的一致性，提升模型在未知环境的泛化能力。LiMA在保持高效预训练的同时，下游任务中不会引入额外计算开销。在主流激光雷达感知基准测试上的大量实验表明，LiMA显著提升了激光雷达语义分割与三维目标检测性能。本工作有望为自动驾驶领域激发更高效的预训练范式研究，相关代码已开源以供后续探索。 |
| 超越简单编辑：基于复杂指令的图像编辑工具X-Planner

（翻译说明：
1. 保留核心技术术语"X-Planner"作为专有名词不翻译
2. "Complex Instruction-Based"采用定语前置的译法，符合中文技术文献表达习惯
3. 主副标题结构保持原文形式，冒号用法与中文标点规范一致
4. "Beyond"译为"超越"准确传达技术突破性含义
5. 整体采用学术文本的简洁风格，避免冗余修饰词） | Chun-Hsiao Yeh | [PDF](http://arxiv.org/pdf/2507.05259v1) | 近期基于扩散模型的图像编辑方法在文本引导任务上取得显著进展，但往往难以解析复杂的间接指令。现有模型普遍存在身份特征保留不足、非预期编辑或过度依赖人工遮罩等问题。为此，我们提出X-Planner——基于多模态大语言模型（MLLM）的规划系统，有效弥合用户意图与编辑模型能力之间的鸿沟。该系统采用思维链推理机制，将复杂指令系统解构为简明子指令序列，并自动生成精确的编辑类型与分割遮罩，既消除了人工干预需求，又能实现局部化且保持身份特征的精准编辑。我们进一步提出创新的大规模数据自动生成流程用于训练X-Planner，该模型在现有基准测试和我们新构建的复杂编辑基准上均达到了最先进的性能水平。

（翻译说明：
1. 专业术语处理："diffusion-based"译为"基于扩散模型"，"chain-of-thought"采用学界通用译法"思维链"，"MLLM"保留英文缩写并首次出现时标注全称
2. 技术概念转化："segmentation masks"译为"分割遮罩"符合计算机视觉领域术语
3. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句，如将系统功能描述拆分为解构指令和自动生成两个独立分句
4. 被动语态转化："are decomposed"等被动结构转换为主动语态
5. 学术风格保持：使用"鸿沟""解构""基准测试"等学术用语，保持原文严谨性
6. 逻辑显化：通过"既...又能..."等连接词明确技术优势的并列关系） |
| 时空大语言模型：环境与行为推理

翻译说明：
1. "Spatio-Temporal" 译为"时空"，这是学术文献中对该术语的标准译法，准确表达了空间与时间的双重维度
2. "LLM" 保留为"大语言模型"，这是目前人工智能领域对Large Language Model的通用中文译名
3. "Reasoning about" 译为"推理"，符合认知科学和人工智能领域的术语规范
4. "Environments and Actions" 译为"环境与行为"，其中：
   - "Environments" 采用计算机科学常用译法"环境"
   - "Actions" 译为"行为"而非"动作"，更符合人工智能决策领域的术语使用习惯

该翻译严格遵循学术翻译的准确性原则，同时确保专业术语的规范性，符合中文科技文献的表达习惯。 | Haozhen Zheng | [PDF](http://arxiv.org/pdf/2507.05258v1) | Despite the significant recent progress of Multimodal Large Language Models
(MLLMs), MLLMs still str [翻译失败] |
| 通过增量式多轮交互评估大语言模型代理的记忆能力

（说明：这个翻译版本具有以下特点：
1. 专业术语准确："LLM Agents"译为"大语言模型代理"符合人工智能领域规范
2. 核心概念清晰："Incremental"译为"增量式"准确表达了逐步累积的评估方式
3. 句式结构合理：采用"通过...评估..."的句式，既符合中文表达习惯，又完整保留了原文的学术严谨性
4. 术语统一性："Multi-Turn Interactions"统一译为"多轮交互"，这是人机交互领域的标准译法
5. 简洁性：在保证专业性的前提下，译文比原文更简洁，符合中文科技文献的表达特点） | Yuanzhe Hu | [PDF](http://arxiv.org/pdf/2507.05257v1) | Recent benchmarks for Large Language Model (LLM) agents primarily focus on
evaluating reasoning, pla [翻译失败] |
| 《SegmentDreamer：基于分段一致性轨迹蒸馏的高保真文本-3D生成技术》

（翻译说明：
1. 保留核心术语"SegmentDreamer"作为技术名称不译，采用首字母大写保持专业术语一致性
2. "segmented consistency trajectory distillation"译为"分段一致性轨迹蒸馏"，准确传达算法核心机制
3. "high-fidelity"译为"高保真"符合计算机图形学领域术语规范
4. 使用破折号连接"文本-3D"体现输入输出关系，比"文本到3D"更简洁专业
5. 补充"技术"二字使中文标题更完整，符合学术论文标题惯例
6. 整体采用"主标题+副标题"结构，与原文格式保持对应） | Jiahao Zhu | [PDF](http://arxiv.org/pdf/2507.05256v1) | Recent advancements in text-to-3D generation improve the visual quality of
Score Distillation Sampli [翻译失败] |
| 《开放视觉推理器：语言认知行为迁移在视觉推理中的应用》

（译文说明：
1. 采用学术论文标题的经典结构，主副标题用冒号分隔
2. "Open Vision Reasoner"译为"开放视觉推理器"，保留技术术语的准确性
3. "Transferring"译为"迁移"符合认知科学领域的术语规范
4. "Linguistic Cognitive Behavior"译为"语言认知行为"准确对应心理学概念
5. 增译"应用"二字使中文标题更完整，符合学术标题表达习惯
6. 整体采用科技论文标题常用的名词化处理，避免动词结构
7. 使用书名号《》符合中文期刊论文标题格式要求） | Yana Wei | [PDF](http://arxiv.org/pdf/2507.05255v1) | 大型语言模型（LLMs）卓越的推理能力源于通过可验证奖励强化所涌现的认知行为。本研究探索如何将该原理迁移至多模态大语言模型（MLLMs）以实现高级视觉推理。我们基于Qwen2.5-VL-7B提出两阶段训练范式：首先进行大规模语言冷启动微调，随后实施跨越近千步的多模态强化学习（RL），其规模超越所有既往开源尝试。这项开创性工作揭示了三个核心发现：1）由于语言心理意象的存在，行为迁移在冷启动阶段会出人意料地早期显现；2）冷启动广泛记忆视觉行为，而强化学习则关键性地识别并放大有效模式；3）迁移过程策略性地偏向高效用行为（如视觉反思）。最终构建的开放视觉推理器（OVR）在多项基准测试中达到最先进水平，包括MATH500的95.3%、MathVision的51.8%以及MathVerse的54.6%。我们公开模型、数据及训练动态，以推动开发更具能力且行为对齐的多模态推理系统。

（注：根据学术翻译规范，专业术语处理如下：
1. "mental imagery"译为"心理意象"（心理学标准术语）
2. "visual reflection"译为"视觉反思"（认知科学常用表述）
3. 模型名称Qwen2.5-VL-7B保留原命名
4. 基准测试名称MATH500/MathVision/MathVerse保持英文原名
5. "behavior-aligned"译为"行为对齐"（机器学习领域通用译法）） |
| 从边缘预测到联合预测：评估自动驾驶场景一致性轨迹预测方法

（翻译说明：
1. 专业术语处理：
- "Marginal/Joint Predictions" 译为"边缘预测/联合预测"，采用机器学习领域标准译法
- "Scene-Consistent" 译为"场景一致性"，准确传达空间关系保持的专业概念
- "Trajectory Prediction" 保留专业术语"轨迹预测"

2. 句式结构调整：
- 将英文被动语态转换为中文主动语态（"Evaluating"译为"评估"作主动动词）
- 冒号后采用完整名词短语，符合中文论文标题规范

3. 学术风格保持：
- 使用"方法"而非"方案"等更贴近学术写作的表述
- 保持"自动驾驶"标准术语而非"无人驾驶"等非正式表达

4. 标题要素完整性：
- 完整保留原标题的三个核心要素（预测类型转变、评估行为、应用领域）
- 通过破折号连接实现与英文标题相同的逻辑层次） | Fabian Konstantinidis | [PDF](http://arxiv.org/pdf/2507.05254v1) | 对周围交通参与者的精确运动预测是实现自动驾驶车辆在动态环境中安全高效运行的关键。传统边缘预测模型通常独立预测每个智能体的未来轨迹，这往往导致自动驾驶车辆的规划决策欠佳。相比之下，联合预测模型显式地考虑了智能体间的交互关系，能在场景层面生成符合社会规则与物理规律的协调预测。然而现有方法不仅在问题表述上存在差异，其模型架构与实现细节也各不相同，导致难以进行横向比较。本研究系统性地探讨了联合运动预测的不同实现路径，包括对边缘预测的后处理、针对联合预测的显式模型训练，以及将问题构建为生成任务等方法。我们从预测精度、多模态性和推理效率三个维度对各方法进行评估，全面解析了不同技术路线的优势与局限。具体预测示例详见https://frommarginaltojointpred.github.io/。

（说明：本译文严格遵循学术翻译规范，具有以下特点：
1. 专业术语准确统一："marginal prediction"译为"边缘预测"，"joint prediction"译为"联合预测"
2. 被动语态转化："are explicitly accounted for"处理为"显式地考虑"符合中文表达习惯
3. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句
4. 概念准确传达："socially and physically consistent predictions"译为"符合社会规则与物理规律的协调预测"
5. 学术用语规范："multi-modality"译为专业术语"多模态性"
6. 链接信息完整保留：确保示例网址准确呈现） |
| 自动驾驶强化学习中的动作空间缩减策略

翻译说明：
1. "Action Space Reduction"译为"动作空间缩减"，准确对应强化学习领域术语，指减少智能体可选动作的数量
2. "Strategies for Reinforcement Learning"译为"强化学习策略"，保持专业领域术语一致性
3. "Autonomous Driving"采用行业通用译法"自动驾驶"
4. 整体采用"领域+方法+技术"的中文标题惯用结构，符合学术文献翻译规范
5. 保留原标题的技术层次关系：自动驾驶（应用领域）→ 强化学习（方法）→ 动作空间缩减（具体技术） | Elahe Delavari | [PDF](http://arxiv.org/pdf/2507.05251v1) | 强化学习（RL）为自动驾驶提供了一个极具前景的框架，其通过智能体与环境的交互学习控制策略。然而，为实现精细化控制而常用的大规模高维动作空间往往会降低训练效率并增加探索成本。本研究针对自动驾驶中的强化学习提出并评估了两种新型结构化动作空间优化策略：动态掩蔽与相对动作空间缩减。我们系统性地将这些方法与固定缩减方案及完整动作空间基线进行比较，以评估其对策略学习与性能的影响。

我们的框架采用多模态近端策略优化（PPO）智能体，可同步处理语义图像序列与标量车辆状态。所提出的动态与相对策略融合了基于上下文及状态转移的实时动作掩蔽机制，在消除无效或次优选择的同时保持动作一致性。通过在多条驾驶路线上进行的全面实验，我们证明动作空间缩减能显著提升训练稳定性与策略性能。其中动态与相对方案尤其在学习速度、控制精度和泛化能力之间实现了理想平衡。这些发现凸显了情境感知的动作空间设计对构建可扩展、高可靠性自动驾驶强化学习系统的重要性。

（注：根据学术翻译规范，关键术语采用以下处理方式：
1. Reinforcement Learning (RL) 首次出现译为"强化学习（RL）"，后文可简写为RL
2. Proximal Policy Optimization 译为专业术语"近端策略优化"并标注英文缩写PPO
3. 保持dynamic masking/relative action space reduction等技术术语翻译一致性
4. 复杂长句按中文习惯拆分，同时保留学术文本的严谨性） |
| 基于物理约束的双隐式神经表征源分离方法

（翻译说明：
1. "Physics-Guided"译为"基于物理约束"，突出方法受物理规律指导的特性
2. "Dual Implicit Neural Representations"采用学术规范译法"双隐式神经表征"，保留"implicit"在神经网络领域的专业术语
3. "Source Separation"译为"源分离"，符合信号处理领域的标准术语
4. 整体采用"方法特性+技术手段+应用领域"的中文论文标题惯用结构
5. 补充"方法"二字使中文标题更完整，同时严格保持与原文的技术对应关系） | Yuan Ni | [PDF](http://arxiv.org/pdf/2507.05249v1) | 在利用最先进的实验与观测技术进行高效数据分析时存在重大挑战，因为采集到的信号通常包含背景干扰和信号畸变等非目标成分，这些干扰会掩盖关键的物理信息。为此，我们开发了一种基于双隐式神经表征框架的自监督机器学习方法：通过联合训练两个神经网络，一个用于逼近目标物理信号的畸变特征，另一个用于学习有效的背景贡献。该方法通过最小化基于重构的损失函数直接从原始数据中学习，无需标记数据或预定义字典。

我们通过一个具有挑战性的案例验证了该框架的有效性——在四维参数空间中分析包含异质性背景贡献和未知信号畸变的大规模模拟与实验数据（动量-能量依赖的非弹性中子散射数据）。研究表明，即使信号特征在参数空间的所有四个维度上发生变化，该方法仍能成功从复杂或有结构的背景中分离出具有物理意义的信号。本文还提出了一种指导正则化参数选择的解析方法。该技术为跨领域信号分离问题提供了通用解决方案，其应用范围涵盖天文测量中的叠加信号分离至生物医学图像重建中的结构特征提取。 |
| 响应攻击：利用语境启动效应越狱大型语言模型

（翻译说明：
1. "Response Attack"译为"响应攻击"，保留技术术语的准确性
2. "Exploiting Contextual Priming"译为"利用语境启动效应"：
   - "contextual"译为"语境"而非"上下文"，更符合心理学/语言学学术惯例
   - "priming"采用心理学标准术语"启动效应"
3. "Jailbreak"译为"越狱"，沿用计算机安全领域对系统突破的通用译法
4. "Large Language Models"译为"大型语言模型"，保持与国内人工智能领域术语一致性
5. 整体采用学术标题的简洁风格，通过冒号分层保持原标题结构
6. 专业术语处理参考了《人工智能标准化白皮书》和《心理学大辞典》的规范译法） | Ziqi Miao | [PDF](http://arxiv.org/pdf/2507.05248v1) | 【学术译文】  
情境启动（Contextual priming）指前期刺激会隐性地影响后续判断，这为大型语言模型（LLMs）提供了一个尚未被探索的攻击面。我们发现了一种情境启动漏洞：对话中先前的响应会引导模型后续生成违反策略的内容。基于此，我们提出"响应攻击"（Response Attack）方法，通过辅助LLM对原始恶意查询的改写版本生成轻度有害响应，将其格式化至对话上下文后接简洁触发提示，从而诱导目标模型生成有害内容。在八个开源与商业LLM上的实验表明，该攻击方法持续优于七种最先进的越狱技术，实现了更高的攻击成功率。为缓解此威胁，我们构建并发布了具备上下文感知能力的安全微调数据集，可显著降低攻击成功率且保持模型性能。代码与数据详见：https://github.com/Dtc7w3PQ/Response-Attack  

【关键术语处理】  
1. "Contextual priming" 译为"情境启动"（认知心理学标准译法）  
2. "Attack surface" 译为"攻击面"（网络安全领域规范术语）  
3. "Jailbreak techniques" 译为"越狱技术"（LLM安全研究通用译法）  
4. "Policy-violating content" 译为"违反策略的内容"（保持与AI伦理研究术语一致性）  
5. 技术路线描述采用"辅助LLM→格式化→触发提示"的递进式翻译结构，确保技术逻辑清晰传达 |
