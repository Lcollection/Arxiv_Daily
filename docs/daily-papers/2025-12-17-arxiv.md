# arxiv 2025-12-17

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| MemFlow：流动自适应记忆机制——实现长视频叙事一致性与高效性的创新方法 | Sihui Ji | [PDF](https://arxiv.org/pdf/2512.14699v1) | 流式视频生成的核心挑战在于保持长上下文中的内容一致性，这对内存设计提出了极高要求。现有方案大多通过预定义策略压缩历史帧来维护内存，但不同待生成视频片段需要参考不同的历史线索，固定策略难以满足这一需求。为此，我们提出MemFlow解决方案：在生成新片段前，系统会依据该片段的文本提示动态检索最相关的历史帧来更新内存库。这种设计能确保即使后续帧出现新事件或场景切换，叙事仍保持连贯性。此外在生成过程中，注意力层仅激活内存库中与每个查询最相关的标记，从而有效保障生成效率。MemFlow通过这种方式实现了卓越的长上下文一致性，其计算负担几乎可忽略不计（相比无内存基线仅降低7.9%速度），并保持了对所有支持KV缓存的流式视频生成模型的兼容性。 |
| TimeLens：基于多模态大语言模型的视频时序定位新思路 | Jun Zhang | [PDF](https://arxiv.org/pdf/2512.14698v1) | 本文并未提出全新方法，而是为视频时序定位这一视频理解核心能力建立了一个简洁、渐进但至关重要的基准。尽管多模态大语言模型在各类视频理解任务中表现卓越，但针对视频时序定位的优化方案仍待深入探索。本研究提出TimeLens，从数据质量与算法设计两个核心维度系统探究构建具备强大视频时序定位能力的多模态大语言模型。我们首先揭示现有视频时序定位基准数据集存在的严重质量问题，进而推出TimeLens-Bench——该数据集基于三个主流基准进行精细化重标注，并遵循严格的质量标准。分析表明，相较于传统基准，模型评估排名出现显著变化，证实了既往评估标准的不可靠性。同时，我们通过自动化重标注流程处理噪声训练数据，构建了大规模高质量训练数据集TimeLens-100K。

基于数据基础，我们深入探索算法设计原则，获得一系列具有实践价值的洞见与高效可行的方案：包括采用交错文本编码的时间表征方法、以可验证奖励强化学习作为训练范式，以及精心设计的强化学习训练方案。这些研究成果最终凝聚为TimeLens模型系列——该系列多模态大语言模型在开源模型中实现了最先进的视频时序定位性能，甚至超越了GPT-5与Gemini-2.5-Flash等专有模型。所有代码、数据与模型均将开源以促进后续研究。 |
| 球形水蛭量化：视觉标记化与生成的新方法 | Yue Zhao | [PDF](https://arxiv.org/pdf/2512.14697v1) | 非参数化量化因其参数高效性及对大码本的良好可扩展性而备受关注。本文通过格编码的视角，提出了不同非参数化量化方法的统一框架。格码的几何特性揭示了在训练自编码器时，对于某些现有免查表量化变体（如BSQ）需要引入辅助损失项的必要性。在此基础上，我们探索了若干可能的候选方案，包括随机格、广义斐波那契格以及最密球堆积格。研究发现，基于Leech格的量化方法（命名为球面Leech量化，$Λ_{24}$-SQ）凭借其在超球面上的高度对称性与均匀分布特性，既能简化训练流程，又能改善重建与压缩的权衡关系。在图像标记化与压缩任务中，该方法在所有评估指标上均优于当前最佳基准BSQ，同时消耗更少的比特数。这种改进优势同样延伸至最先进的自回归图像生成框架中。 |
| CRISP：基于平面场景基元的单目视频接触引导真实到仿真转换 | Zihan Wang | [PDF](https://arxiv.org/pdf/2512.14696v1) | 我们提出CRISP方法，该方法能够从单目视频中重建可模拟的人体运动与场景几何。现有的人体-场景联合重建研究主要依赖数据驱动的先验知识，并通过无物理约束的联合优化实现，或重建出带有伪影的噪声几何，导致涉及场景交互的运动追踪策略失效。相比之下，我们的核心思路是通过对场景点云进行平面基元拟合，构建凸面、干净且可直接用于仿真的几何结构——这通过一个基于深度、法向量和光流的简单聚类流程实现。为重建交互过程中可能被遮挡的场景几何，我们引入人体-场景接触建模技术（例如利用人体姿态重建被遮挡的椅面）。最后，我们通过强化学习驱动人形控制器，确保人体与场景重建结果符合物理规律。在人体中心化视频基准测试（EMDB、PROX）中，本方法将运动追踪失败率从55.2%降至6.9%，同时强化学习仿真吞吐量提升43%。我们进一步在真实场景视频（包括随手拍摄视频、网络视频乃至Sora生成视频）中验证了该方法，证明CRISP能够大规模生成符合物理规律的人体运动与交互环境，有力推动了机器人及AR/VR领域的实景仿真应用发展。 |
| 通用推理模型 | Zitian Gao | [PDF](https://arxiv.org/pdf/2512.14693v1) | 通用变换器（UTs）已在ARC-AGI和数独等复杂推理任务中得到广泛应用，但其性能提升的具体来源仍未得到充分探究。本研究系统分析了通用变换器的变体，发现其在ARC-AGI上的改进主要源于Transformer的循环归纳偏置和强非线性组件，而非复杂的架构设计。基于这一发现，我们提出通用推理模型（URM），通过引入短卷积和截断反向传播机制增强通用变换器。该方法显著提升了推理性能，在ARC-AGI 1上达到53.8%的pass@1最高水平，在ARC-AGI 2上实现16.0%的pass@1最佳表现。代码已开源：https://github.com/zitian-gao/URM。 |
| 原生与紧凑结构化潜在空间在三维生成中的应用 | Jianfeng Xiang | [PDF](https://arxiv.org/pdf/2512.14692v1) | 三维生成建模领域的最新进展显著提升了生成的真实感，但现有表征方式仍制约着该领域发展——这些方法难以捕捉具有复杂拓扑结构和精细外观特征的数字资产。本文提出一种从原生三维数据中学习结构化潜在表征的创新方法以应对这一挑战。其核心是名为O-Voxel的新型稀疏体素结构，这种全维度体素表征能同时编码几何与外观信息。O-Voxel能够稳健建模任意拓扑形态，包括开放型、非流形及全封闭曲面，同时捕获超越纹理色彩的完整表面属性，如基于物理的渲染参数。基于O-Voxel，我们设计了具有高空间压缩率和紧凑潜在空间的稀疏压缩变分自编码器。通过整合多元公共三维资产数据集，我们训练了包含40亿参数的大规模流匹配模型用于三维生成。尽管模型规模庞大，推理过程仍保持高效性。与此同时，我们生成资产的几何精度与材质质量远超现有模型。我们相信该方法为三维生成建模领域带来了重大突破。 |
| MMGR：多模态生成式推理 | Zefan Cai | [PDF](https://arxiv.org/pdf/2512.14691v1) | 视频基础模型能够生成视觉逼真且时序连贯的内容，但其作为世界模拟器的可靠性取决于是否能够捕捉物理、逻辑与空间约束。现有评估指标（如弗雷歇视频距离）侧重感知质量，却忽略了推理层面的缺陷，包括对因果关系、物理规律及全局一致性的违背。我们提出多模态生成式推理评估基准，这是一个基于五大推理能力构建的规范化评估框架：物理推理、逻辑推理、三维空间推理、二维空间推理以及时序推理。该基准在三大领域对生成式推理进行系统性评估：抽象推理、具身导航以及物理常识理解。通过细粒度评估指标，该基准要求视频与图像生成在整体上均达到正确性。我们对主流视频模型与图像模型进行了基准测试，结果显示各领域均存在显著的性能差距。模型在物理常识任务中表现尚可，但在抽象推理任务上表现欠佳，在具身场景中的长程空间规划也存在明显不足。我们的分析揭示了当前模型的关键局限：过度依赖感知数据、全局状态一致性薄弱，以及优化目标偏向视觉合理性而非因果正确性。该基准为生成式世界模型提供了统一的诊断工具，并指明了构建具备推理能力的生成模型的发展路径。 |
| 芯片：通过后见扰动实现人形机器人控制的自适应顺应性 | Sirui Chen | [PDF](https://arxiv.org/pdf/2512.14689v1) | 人形机器人领域的最新进展已解锁了敏捷的运动技能，包括后空翻、奔跑和爬行。然而，人形机器人执行强力操控任务——如移动物体、擦拭和推车——仍具挑战性。我们提出通过视觉扰动实现自适应柔顺性的人形控制方法（CHIP），该即插即用模块能够在保持对动态参考动作敏捷跟踪的同时，实现可控的末端执行器刚度。CHIP易于实施，既无需数据增强，也无需额外奖励调优。研究表明，采用CHIP训练的通用运动跟踪控制器能够执行多种需要不同末端执行器柔顺性的强力操控任务，例如多机器人协作、擦拭、箱体搬运和开门。 |
| 《口语对话摘要：面向口语对话摘要的情感丰富对话数据集》 | Yen-Ju Lu | [PDF](https://arxiv.org/pdf/2512.14687v1) | 近期的音频语言模型已能处理长对话。然而，由于缺乏关联语音、摘要与副语言特征的数据，情感感知或口语对话摘要的研究受到限制。我们推出Spoken DialogSum——首个将原始对话音频与事实摘要、情感增强型摘要，以及说话人年龄、性别和情感等语句级标签对齐的语料库。该数据集通过两个阶段构建：首先，利用大语言模型对DialogSum文本脚本进行改写，加入类似Switchboard语料库中的填充词与反馈词，并为每句对话标注情感、音高和语速特征；随后，通过富有表现力的文本转语音引擎，根据标注脚本合成与副语言标签对齐的语音。Spoken DialogSum包含13,460段情感类型丰富的对话，每段均配有事实摘要与情感聚焦型摘要。数据集已公开于https://fatfat-emosum.github.io/EmoDialog-Sum-Audio-Samples/。基线实验表明，相较于级联式ASR-LLM系统，音频大语言模型将情感摘要的ROUGE-L指标提升了28%，印证了端到端语音建模的价值。 |
| 随机一阶方法的偏差-方差权衡：从有界方差到无限均值 | Chuan He | [PDF](https://arxiv.org/pdf/2512.14686v1) | 随机优化是现代机器学习的基石。近期研究将随机一阶方法（SFOMs）的研究范围从轻尾噪声扩展至实践中常见重尾噪声场景，其中梯度裁剪技术成为控制重尾梯度的关键手段。大量理论进展进一步表明，SFOMs的预言机复杂度取决于噪声的尾指数$α$。然而，现有复杂度结果通常仅覆盖$α\in (1,2]$的情形（即噪声具有有限均值的区间），且当$α$趋近于1时复杂度边界趋于无穷。本文系统研究了尾指数$α\in(0,2]$的广义噪声情形，涵盖从有界方差噪声到无限均值噪声的完整区间，其中后者在现有研究中鲜有涉及。通过对梯度裁剪中偏差-方差权衡的创新性分析，我们证明当噪声尾部分布对称性受控时，裁剪SFOMs能在任意尾指数$α\in (0,2]$的重尾噪声环境下获得更优的复杂度保证。该偏差-方差权衡分析不仅为裁剪SFOMs建立了跨全尾指数范围的统一复杂度理论框架，其简洁的分析方法还可与经典轻尾噪声分析相结合，从而构建重尾噪声下的预言机复杂度保证体系。最终，数值实验验证了我们的理论发现。 |
