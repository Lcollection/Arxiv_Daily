# arxiv 2025-11-29

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 重探不同难度水平的泛化能力：并非易事 | Yeganeh Kordi | [PDF](https://arxiv.org/pdf/2511.21692v1) | 我们研究大型语言模型（LLMs）在不同任务难度间的泛化能力，这是影响数据筛选与评估有效性的关键问题。现有研究对“使用简单数据还是困难数据进行训练能获得更好结果”以及“这种增益体现在简单还是困难测试数据上”等问题尚未达成共识。为解决这一问题，我们通过模型、数据集和细粒度样本难度分组三个维度，对LLMs的泛化能力展开系统性评估。我们基于数千种不同LLMs的输出结果，结合教育测试领域成熟的难度度量指标——项目反应理论（IRT），对六个数据集中的样本进行难度分级。与先前研究不同，我们的难度评级完全由多种LLMs的能力决定，排除了人类对难度的主观判断。通过更客观、大规模、细粒度的分析，我们发现跨难度泛化能力往往存在局限：无论是使用简单数据还是困难数据进行训练，都无法在全部难度范围内实现一致提升。这些结果表明，在LLMs的训练和评估数据中保持难度多样性至关重要，任何在难度维度上走捷径的做法都具有风险。 |
| 画布到图像：基于多模态控制的组合式图像生成 | Yusuf Dalva | [PDF](https://arxiv.org/pdf/2511.21691v1) | 尽管现代扩散模型在生成高质量多样化图像方面表现出色，但在实现高保真度的组合式与多模态控制方面仍存在困难——特别是当用户需要同时指定文本提示、主体参照、空间排布、姿态约束和布局标注时。我们提出"画布到图像"统一框架，将这些异构控制要素整合至单一画布界面，使用户能够生成精准反映创作意图的图像。其核心创新在于将多样控制信号编码为复合画布图像，使模型能够直接进行视觉空间联合推理。我们进一步构建了多任务数据集，提出多任务画布训练策略，通过统一学习范式优化扩散模型对异构控制信号的理解与整合能力。这种联合训练使模型能够跨越多重控制模态进行推理，而非依赖任务特定启发式方法，并在推理阶段展现出优秀的多元控制泛化能力。大量实验表明，在多人组合、姿态控制合成、布局约束生成及多元控制生成等挑战性测试中，Canvas-to-Image在身份保持与控制遵循度方面显著优于现有前沿方法。 |
| TraceGen：三维轨迹空间中的世界建模实现跨形态视频学习

（解析：1. "TraceGen"作为专有名词保留不译；2. "World Modeling"译为"世界建模"符合计算机视觉领域术语规范；3. "3D Trace Space"译为"三维轨迹空间"准确体现三维运动轨迹的数学空间概念；4. "Cross-Embodiment"译为"跨形态"精准表达不同物理实体形态的涵义；5. 采用"实现...学习"的动宾结构保持学术论文标题的简洁性与动态感） | Seungjae Lee | [PDF](https://arxiv.org/pdf/2511.21690v1) | 仅通过少量演示就能在新平台和新场景中学习新机器人任务仍具挑战性。尽管人类和其他机器人的示范视频资源丰富，但本体结构、相机参数和环境差异阻碍了其直接应用。我们通过引入统一的符号化表征——场景级轨迹的紧凑三维"轨迹空间"，解决了小数据量问题，该表征支持跨本体、跨环境和跨任务视频的学习。我们提出TraceGen世界模型，该模型在轨迹空间而非像素空间预测未来运动，在保留操作所需几何结构的同时抽象掉外观特征。为实现大规模训练，我们开发了TraceForge数据流水线，将异构的人类与机器人视频转化为统一的三维轨迹，构建包含12.3万条视频和180万个观察-轨迹-语言三元组的数据集。基于该数据集的预训练产生了可迁移的三维运动先验模型，仅需五段目标机器人视频即可实现高效适应：在四项任务中达到80%成功率，同时推理速度比基于视频的顶尖世界模型快50-600倍。在更具挑战性的场景中，仅使用手机拍摄的五段未标定人类演示视频，该模型在真实机器人上仍能达到67.5%的成功率，彰显了TraceGen在不依赖物体检测器或繁重像素空间生成的情况下实现跨本体适应的能力。 |
| 工具交响乐：通过高效模型与工具编排提升智能水平 | Hongjin Su | [PDF](https://arxiv.org/pdf/2511.21689v1) | 大型语言模型是强大的通用系统，但在解决诸如"人类终极考试"（HLE）这类深度复杂问题时，仍面临概念性挑战与高昂计算成本。我们证明，通过小型调度器管理其他模型及多样化工具，既能突破智能水平上限，又能提升复杂智能体任务的解决效率。本文提出ToolOrchestra——一种训练小型调度器协调智能工具的方法。该方法创新性地采用强化学习框架，融合结果导向、效率优先及用户偏知的奖励机制。基于此训练的Orchestrator模型（80亿参数）在保证更高精度的同时，较以往工具使用智能体显著降低成本，并能根据用户偏好匹配查询任务的最适工具。在HLE测试中，Orchestrator以37.1%的得分超越GPT-5（35.1%），效率提升2.5倍。在tau2-Bench与FRAMES基准测试中，该模型以约30%的成本实现对GPT-5的显著超越。深入分析表明，Orchestrator在多项指标下实现了性能与成本的最佳平衡，并对未见工具展现强大泛化能力。这些成果验证了轻量级调度模型组合多样化工具的方法，相比现有方案兼具更高效率与更强效能，为构建实用可扩展的工具增强推理系统开辟了新路径。 |
| G$^2$VLM：基于几何基础的视觉语言模型——融合统一三维重建与空间推理能力

（注：译文通过"几何基础"对应"Geometry Grounded"的学术内涵，"融合统一"体现"Unified"的技术特性，完整保留专业术语"三维重建"与"空间推理"，并通过破折号构建符合中文论文标题的递进式结构） | Wenbo Hu | [PDF](https://arxiv.org/pdf/2511.21688v1) | 视觉语言模型（VLMs）在空间智能方面仍缺乏鲁棒性，在空间理解与推理任务中表现欠佳。我们认为这一缺陷源于缺乏能够从二维图像重建三维空间的视觉几何学习过程。本文提出G$^2$VLM——一个基于几何基础的视觉语言模型，该模型融合了空间智能的两个核心维度：三维空间重建与空间语义理解。G$^2$VLM原生利用学习得到的三维视觉几何特征，既能直接预测三维属性，又可通过上下文学习与交叉推理增强空间推理任务。我们的统一架构在空间理解方面具有高度扩展性：既能利用海量多视角图像和视频数据进行训练，又能获得通常仅能通过难以采集的标注数据才能构建的三维视觉先验优势。实验结果表明，G$^2$VLM在两项任务中均表现卓越，其三维重建效果可比肩最先进的前馈式三维重建模型，在空间理解与推理任务中取得更优或具有竞争力的结果。通过将强语义的VLM与底层三维视觉任务相融合，我们希望G$^2$VLM能成为该领域的强基准，并为三维场景编辑等未来应用开启更多可能性。 |
| 矩阵：点对点多智能体合成数据生成框架 | Dong Wang | [PDF](https://arxiv.org/pdf/2511.21686v1) | 合成数据对于训练大语言模型已愈发重要，尤其在真实数据稀缺、成本高昂或涉及隐私的场景下。此类生成任务通常需要协调的多智能体工作流，由专业化智能体协同生成质量更高、多样性更强且结构更丰富的数据。然而，现有多智能体合成框架往往依赖中心化编排器导致可扩展性瓶颈，或为特定领域硬编码而缺乏灵活性。我们提出\textbf{Matrix}——一种去中心化框架，将控制流与数据流统一表征为通过分布式队列传递的序列化消息。这种点对点设计消除了中心编排器，每个任务通过轻量级智能体独立推进，而计算密集型操作（如LLM推理或容器化环境）则由分布式服务处理。基于Ray构建的Matrix可扩展至数万个并发智能体工作流，其模块化可配置设计能轻松适配各类数据生成流程。我们在多智能体协作对话、基于网页的推理数据提取、客服场景工具使用轨迹生成等多样化合成场景中评估Matrix。在所有案例中，Matrix在相同硬件资源下实现了$2$--$15$倍的数据生成吞吐量提升，且未牺牲输出质量。 |
| 无像素视觉：基于相机轨迹的感知 | Zihui Xue | [PDF](https://arxiv.org/pdf/2511.21681v1) | 能否不观看视频像素，仅通过相机运动轨迹——即其在空间中划过的路径——来感知视频内容？本文首次系统性地探究这个看似不可能的问题。为此，我们提出对比学习框架来训练CamFormer：一个将相机位姿轨迹映射到联合嵌入空间的专用编码器，使其与自然语言表征对齐。研究发现，与表面上的简单性相反，相机轨迹实则是揭示视频内容的信息富集信号。换言之，“如何移动”确实能揭示“正在做什么”（第一人称视角）或“观察什么”（第三人称视角）。我们在跨模态对齐、分类与时序分析等多样化下游任务中，验证了所学CamFormer嵌入向量的通用性。值得注意的是，我们的表征对不同相机位姿估计方法（包括高精度多传感器方案与标准纯RGB估计器）均保持稳健性。本研究确立了相机轨迹作为一种轻量化、强健且通用的视频内容感知模态。 |
| 具有成长与精炼多模态语义记忆的能动学习者

（解析说明：
1. "Agentic Learner"译为"能动学习者"，体现学习者具有自主行动和决策能力
2. "Grow-and-Refine"采用"成长与精炼"的译法，准确传达动态发展与持续优化的双重含义
3. "Multimodal Semantic Memory"译为"多模态语义记忆"，保持计算机与认知科学领域的专业术语规范
4. 整体采用偏正结构，通过"具有...的"连接成分，符合中文科技文献的表述习惯） | Weihao Bo | [PDF](https://arxiv.org/pdf/2511.21678v1) | 多模态大语言模型在独立查询中展现出强大的推理能力，但其运作始终从零开始——每个问题都独立求解，且常重复相同错误。现有基于记忆增强的智能体主要存储过往轨迹以供复用，然而基于轨迹的记忆存在简略偏差，会逐渐丢失关键领域知识。更严重的是，即使在真正的多模态问题解决场景中，此类系统仅记录单模态的行为轨迹，未能保留视觉注意力与逻辑推理如何协同促成解决方案。这与人类认知存在根本性错位：语义记忆兼具多模态与整合特性，通过协调而独立的表征流同时保存视觉与抽象知识。

为此我们提出ViLoMem——一种双流记忆框架，构建基于图式的紧凑记忆。该框架分别编码视觉分心模式与逻辑推理错误，使多模态大语言模型能够从成功与失败经验中学习。遵循生长-精炼原则，系统持续积累并更新多模态语义知识：在保持稳定、可泛化策略的同时避免灾难性遗忘。在六大多模态基准测试中，ViLoMem持续提升pass@1准确率，并显著减少重复的视觉与逻辑错误。消融实验证实了具有显式分心-幻觉分离的双流记忆的必要性，彰显了错误感知多模态记忆在终身学习与跨域智能体学习中的价值。我们的项目页面将发布于：https://weihao-bo.github.io/ViLoMeo-page。 |
| 基于演化模型的干扰下实验研究 | Sadegh Shirani | [PDF](https://arxiv.org/pdf/2511.21675v1) | 网络系统中的因果效应估计是数据驱动决策的核心问题。在此类场景中，对单个单元实施的干预可能产生溢出效应，而在复杂的物理或社会系统中，驱动这些干扰结构的交互路径大多不可观测。我们认为，要识别群体层面的因果效应，无需还原精确的网络结构；相反，只要刻画这些交互如何影响结果演化即可。基于此原理，我们研究一种基于演化的方法：通过观察多轮实验中干预措施如何引致结果变化，从而弥补缺失的网络信息。借助暴露映射视角，我们给出结果的经验分布遵循低维递归方程的公理化描述，并确定此类演化映射存在所需的最小结构条件。这构成了双重差分法的分布形态对应物——该方法不假设个体单元具有平行路径，而是利用不同处理情境间的平行演化模式来估计反事实轨迹。关键洞见在于：随机化处理除消除潜在混杂因素外，更通过隐式采样隐藏的干扰通道，使异质性溢出效应的一致学习成为可能。我们提出因果消息传递作为该方法在稠密网络中的具体实现，并将其拓展至更普遍的干扰结构（包括少数单元主导多数溢出效应的影响者网络）。最后我们讨论了该方法的局限性，指出强烈的时间趋势或内生性干扰可能破坏识别效果。 |
| 大型稀疏网络中的事件驱动资格传播：生物现实性塑造的效率

（该翻译在保持专业术语准确性的基础上，采用符合中文计算机科学/神经科学领域论文标题的表述习惯：
1. "Event-driven"译为"事件驱动"（计算机领域标准译法）
2. "Eligibility propagation"译为"资格传播"（神经科学中STDP学习规则术语）
3. "Biological realism"译为"生物现实性"（计算神经科学常用表述）
4. 通过冒号分隔主副标题，符合中文学术标题规范
5. "efficiency shaped by"动态译为"塑造的效率"，既保持被动语态的专业感又符合中文表达） | Agnes Korcsak-Gorzo | [PDF](https://arxiv.org/pdf/2511.21674v1) | 尽管技术已取得显著进步，人工智能系统仍可从生物原理中获益，例如循环连接结构与高能效机制。受大脑运作机制启发，我们提出了一种具有生物合理性的资格传播学习规则拓展方案，适用于脉冲循环神经网络。通过将时间驱动更新机制转化为事件驱动模式，我们将该学习规则整合至大规模脉冲神经网络仿真平台，并验证其在神经形态MNIST等任务中的适用性。我们通过引入持续动态权重更新、严格局部连接和稀疏连接等典型生物特征来扩展该模型。研究结果表明，基于生物学的约束条件可为设计计算高效的人工智能算法提供指导，在保持学习性能的同时实现百万级神经元的可扩展性。这项工作搭建了机器学习与计算神经科学之间的桥梁，不仅推动可持续生物启发式人工智能系统的发展，同时深化了我们对类脑学习机制的理解。 |
