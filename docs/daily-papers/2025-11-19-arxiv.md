# arxiv 2025-11-19

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| ARC是一个视觉问题！ | Keya Hu | [PDF](https://arxiv.org/pdf/2511.14761v1) | 抽象与推理语料库（ARC）旨在推动对人类智能核心要素——抽象推理能力的研究。当前主流方法通常将其视为语言导向问题，采用大语言模型（LLM）或循环推理模型进行处理。然而，尽管ARC中的谜题式任务本质上具有视觉特性，现有研究却鲜少从视觉中心视角切入。本研究将ARC置于视觉范式下，将其构建为图像到图像的转换问题。为融入视觉先验知识，我们将输入信息呈现在可像自然图像般处理的“画布”上。这使我们能自然应用标准视觉架构（如基础版视觉变换器ViT）执行图像到图像的映射。我们的模型仅通过ARC数据从头训练，并通过测试时训练实现对未知任务的泛化。该框架被命名为视觉ARC（VARC），在ARC-1基准测试中达到60.4%的准确率，显著超越同样从头训练的所有现有方法。我们的研究成果与领先的大语言模型表现相当，并显著缩小了与人类平均水平的差距。 |
| UniGen-1.5：通过强化学习中的奖励统一机制提升图像生成与编辑能力

（注：译文采用学术文献标题的典型结构，通过冒号分隔主副标题。"Reward Unification"译为"奖励统一机制"以体现技术实现方式，"Enhancing"译为"提升"准确传达性能改进含义，同时保持计算机视觉与强化学习领域的术语规范性。） | Rui Tian | [PDF](https://arxiv.org/pdf/2511.14760v1) | 我们推出UniGen-1.5——一个面向高级图像理解、生成与编辑任务的多模态大语言模型。该模型在UniGen基础上全面升级架构设计与训练流程，在强化图像理解与生成能力的同时，解锁了卓越的图像编辑功能。我们特别提出统一强化学习策略，通过共享奖励模型协同提升图像生成与编辑效果。为进一步增强图像编辑性能，创新性引入轻量化编辑指令对齐阶段，显著提升对编辑指令的理解能力，这对强化学习训练成效具有关键作用。实验结果表明，UniGen-1.5在理解与生成任务中展现出卓越竞争力，具体在GenEval和ImgEdit基准测试中分别取得0.89与4.31的综合评分，不仅超越BAGEL等前沿模型，更达到与GPT-Image-1等专有模型相媲美的性能水平。 |
| $π^{*}_{0.6}$：一种基于经验学习的变分潜在注意力模型

（注：VLA在此语境下可译为"变分潜在注意力模型"，该译法既保留了原文缩写形式，又通过全称翻译准确传达了变分推断、潜在空间与注意力机制三个核心概念，符合机器学习领域的术语规范。数字下标0.6建议保留原格式以保持数学表达的精确性。） | Ali Amin | [PDF](https://arxiv.org/pdf/2511.14759v1) | 我们研究视觉-语言-动作模型如何通过强化学习在真实世界部署中实现性能提升。本文提出一种通用方法——基于经验与校正的优势条件策略强化学习，该方法通过优势条件机制实现VLA模型的强化学习训练。我们的方法将异构数据整合至自我改进过程，包括示范数据、在线策略收集数据，以及在自主执行过程中专家远程操作提供的干预数据。RECAP方法首先通过离线强化学习预训练通用型VLA模型（记为$π^{*}_{0.6}$），该模型随后可通过机器人现场数据采集实现下游任务的专业化适配以达到卓越性能。实验表明，采用完整RECAP方法训练的$π^{*}_{0.6}$模型能够在真实家庭环境中完成衣物折叠、可靠地组装纸箱，并能使用专业意式咖啡机制作饮品。在部分高难度任务中，RECAP使任务吞吐量提升逾两倍，同时将任务失败率降低约50%。 |
| 基于汉密尔顿-雅可比可达性分析的控制器在状态不确定性下的鲁棒验证 | Albert Lin | [PDF](https://arxiv.org/pdf/2511.14755v1) | 随着基于感知的自主系统控制器在现实世界中日益普及，在存在感知不确定性的情况下对这些控制器的安全性与性能进行形式化验证显得尤为重要。然而，此类系统的验证仍面临严峻挑战，主要源于控制器本身的复杂性——它们往往具有非线性、非凸性、基于学习或黑箱特性。现有研究提出了基于近似可达性方法的验证算法，但这些方法通常对控制器和系统类型存在限制，或导致分析结果过于保守。Hamilton-Jacobi（HJ）可达性分析作为通用非线性系统的形式化验证工具，能够计算最差系统不确定性下的最优可达集，但目前其在基于感知系统中的应用尚未得到充分探索。本研究提出RoVer-CoRe框架——基于HJ可达性的控制器鲁棒验证方法。据我们所知，这是首个利用HJ可达性分析来验证感知不确定性下基于感知系统的框架。我们的核心创新在于通过串联系统控制器、观测函数与状态估计模块，构建出与现有可达性框架直接兼容的等效闭环系统。在RoVer-CoRe框架内，我们提出了形式化安全验证与鲁棒控制器设计的新方法，并通过飞机滑行和基于神经网络的巡视器导航案例研究验证了框架的有效性。代码详见页脚链接。 |
| SparseST：利用数据稀疏性进行时空建模与预测 | Junfeng Wu | [PDF](https://arxiv.org/pdf/2511.14753v1) | 时空数据挖掘（STDM）在各类复杂物理系统（CPS）中具有广泛应用，包括交通运输、智能制造、医疗健康等领域。在现有方法中，卷积长短期记忆网络（ConvLSTM）已被证明具有良好的通用性与可扩展性，其多个变体在不同时空数据挖掘应用中均实现了最优性能。然而，ConvLSTM及其变体存在计算成本高昂的问题，导致其难以在计算资源有限的边缘设备上部署。随着CPS中对边缘计算需求的日益增长，发展高效人工智能技术以在保持模型性能的同时降低计算成本显得尤为重要。

现有高效AI方法主要致力于削减模型容量冗余（如模型剪枝、压缩等）。但时空数据挖掘天然需要充足的模型容量，因为时空数据中蕴含的依赖关系复杂难解，这从根本上限制了模型冗余的压缩空间。相反，数据与特征维度存在相当程度的冗余，这些冗余会带来不必要的计算负担，而现有研究对此关注不足。为此，我们创新性地提出了SparseST框架，率先利用数据稀疏性构建高效时空模型。此外，通过设计多目标复合损失函数，我们探索并逼近了模型性能与计算效率之间的帕累托前沿，为实践者根据计算资源限制与下游任务性能需求调整模型提供了实用指南。 |
| Co-Me：面向视觉几何变换器的置信度引导令牌融合方法

该翻译遵循以下学术规范：
1. 专业术语处理：
   - "Confidence-Guided"译为"置信度引导"，符合计算机视觉领域对confidence的标准化译法
   - "Token Merging"译为"令牌融合"，延续Transformer架构中"token"的统一译法
   - "Visual Geometric Transformers"完整译为"视觉几何变换器"，准确保持专业术语完整性

2. 技术内涵传达：
   - 使用"融合"对应"Merging"，体现对特征令牌的整合操作
   - 通过"面向"明确技术方法的适用领域
   - 保留缩写"Co-Me"形成技术简称，符合学术惯例

3. 句式结构优化：
   - 采用"方法"作为隐含后缀，符合中文论文标题命名规范
   - 通过冒号分隔主副标题，保持中英文标题结构一致性
   - 避免直译"for"而使用"面向"，使技术应用方向更清晰 | Yutian Chen | [PDF](https://arxiv.org/pdf/2511.14751v1) | 我们提出置信度引导的令牌融合机制（Co-Me），这是一种无需重新训练或微调基础模型的视觉几何Transformer加速方法。Co-Me通过训练轻量级置信度预测器对令牌进行不确定性排序，并选择性融合低置信度令牌，在保持空间覆盖度的同时显著降低计算量。相较于基于相似性的融合或剪枝方法，Co-Me中的置信度信号能可靠识别Transformer关注的重点区域，从而在保持性能不变的前提下实现显著加速。该机制可无缝应用于各类多视角和流式视觉几何Transformer，其加速效果随序列长度增加而提升。在VGGT和MapAnything模型上的实验表明，Co-Me分别实现了最高11.3倍和7.2倍的加速效果，使得视觉几何Transformer在实时三维感知与重建任务中具备实用价值。 |
| 视觉大语言模型在参与度分析中具备出色的噪声处理能力 | Alexander Vedernikov | [PDF](https://arxiv.org/pdf/2511.14749v1) | 与传统的图像分类任务不同，视频数据集中的参与度识别因主观标签和噪声限制模型性能而面临特殊挑战。为克服主观及含噪参与度标签的难题，我们提出一种利用视觉大语言模型优化标注并指导训练过程的框架。该框架通过问卷提取行为线索，将数据划分为高可靠性与低可靠性子集。我们还提出结合课程学习与软标签优化的训练策略，在逐步引入模糊样本的同时调整监督信号以反映不确定性。实验表明，基于优化后的高可靠性子集训练的传统计算机视觉模型，结合课程学习策略后性能显著提升，这凸显了利用视觉大语言模型处理标签主观性的优势。本方法在EngageNet（六项特征设置中有三项取得突破，最高提升+1.21%）、DREAMS（F1值提升+0.22%）和PAFE（F1值提升+0.06%）等参与度基准测试中均超越现有最优成果。 |
| 学习平台上的前瞻性推理 | Haiqing Zhu | [PDF](https://arxiv.org/pdf/2511.14745v1) | 在许多学习平台中，指导模型训练的优化标准反映的是设计者的优先考量，而非受其影响的个体需求。因此，用户可能采取策略性行为以获取更有利的结果，实质上对平台的预测机制形成挑战。尽管已有研究关注学习平台上的用户策略行为，但主要聚焦于对已部署模型的策略反应，未充分考虑其他用户行为的影响。相比之下，前瞻性推理将用户行为视为相互关联的系统——在规模效应下，这些行为将影响未来的预测结果。

在此框架下，我们首先形式化定义了行为经济学中的"k层思维"概念：用户通过超前一步预判同伴行为来智取对手。研究表明，虽然该思维模式能加速系统收敛至均衡状态，但最终均衡点保持不变——从长期来看，高阶推理并不能为个体带来额外收益。随后我们聚焦集体推理模式，即用户通过协调行动共同影响模型优化过程。通过对比集体行为与利己行为，我们界定了协同合作的收益边界与局限，并揭示出学习器效用与用户效用之间的新型对齐关系——这一新概念成为核心要义。最后，我们探讨了该理论与战略分类、执行预测、算法集体行动等多个数学框架的关联性。 |
| 衡量人工智能在药物发现领域的进展：Tox21挑战赛可复现性排行榜

（注：Tox21指"21世纪毒性测试"计划，是由美国国家卫生研究院、环境保护署等机构联合推进的毒理学研究项目。该翻译在保持专业性的同时：1）采用"可复现性"这一符合计算机领域术语习惯的译法；2）通过增译"领域"明确研究范畴；3）保留专业缩写"Tox21"并补充背景说明；4）使用"排行榜"准确对应"Leaderboard"在机器学习领域的特定含义） | Antonia Ebner | [PDF](https://arxiv.org/pdf/2511.14744v1) | 自2010年代初兴起的深度学习技术，不仅彻底改变了计算机视觉和自然语言处理等领域，更对生物医学研究产生了深远影响。在药物研发领域，2015年出现的重大转折点——堪比计算机视觉领域的“ImageNet时刻”——深神经网络在Tox21数据挑战赛中首次超越传统方法。这一里程碑事件推动了深度学习技术在制药行业的全面普及，目前绝大多数主流药企均已将深度学习方法整合至研发流程。

Tox21挑战赛结束后，其数据集被纳入MoleculeNet和开放图基准等多个权威评估体系。然而在整合过程中，数据集经历多次修改，部分标签通过插补或人工生成，导致不同研究之间的可比性显著降低。这使得过去十年间生物活性和毒性预测方法究竟取得多大进展变得难以衡量。

为此，我们构建了基于原始Tox21挑战赛数据集的可复现评估榜单，该榜单托管于Hugging Face平台并配备系列基线方法与代表性模型。当前版本榜单显示：基于集成学习的原冠军方法DeepTox与2017年提出的基于描述符的自标准化神经网络，在毒性预测任务中仍保持领先地位。这一现象引发思考——过去十年间毒性预测领域是否取得了实质性突破？

作为本研究的组成部分，我们通过Hugging Face Spaces平台提供标准化API接口，所有基线模型与评估模型均已开源并可公开调用。 |
| 超越均值：预测客户满意度的动态框架 | Christof Naumzik | [PDF](https://arxiv.org/pdf/2511.14743v1) | 在线评分影响顾客决策，但样本均值等标准聚合方法既无法适应质量随时间的变化，又忽略了评论异质性（如评论情感倾向、评论有用性）。为解决这些问题，我们论证了采用高斯过程框架进行评分聚合的价值。具体而言，我们提出一个定制化的高斯过程模型，该模型既能捕捉评分随时间变化的动态特征，又能兼顾评论异质性。基于Yelp平台的121,123条评分数据，我们比较了不同评分聚合方法在预测未来评分时的表现，结果发现高斯过程模型的预测精度显著更高，与样本均值相比平均绝对误差降低10.2%。本研究对营销从业者和消费者具有重要启示：通过突破均值局限，在线声誉系统设计者可以展示信息量更丰富、适应性更强的聚合评分，从而准确反映预期顾客满意度。 |
