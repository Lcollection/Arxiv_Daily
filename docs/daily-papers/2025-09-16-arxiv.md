# arxiv 2025-09-16

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 以角色为中心的动画电影理解

（注：此处采用学术翻译中常见的"以...为中心"结构，准确传达"Character-Centric"的学术概念，同时保持中文表达习惯。"Understanding"译为"理解"符合认知科学领域的术语规范，整体译文既保留专业术语的准确性，又符合中文学术表达范式。） | Zhongrui Gui | [PDF](http://arxiv.org/pdf/2509.12204v1) | 动画电影凭借其独特的角色设计与富有想象力的叙事手法而极具吸引力，但对现有识别系统构成了重大挑战。与传统人脸识别方法检测到的稳定视觉模式不同，动画角色在外观、运动和形变方面呈现出极大多样性。本研究提出了一种音视觉联合处理方案，旨在实现自动化且鲁棒的动画角色识别，从而增强对动画电影以角色为核心的深度理解。该方案的核心是从在线资源自动构建音视觉角色数据库，其中包含每个角色的视觉范例和语音样本，使得在长尾外观分布条件下仍能进行多模态角色识别。基于精准的角色识别，我们探索了两个下游应用：为视障观众生成音频描述(AD)，以及为听障群体提供角色感知的字幕服务。为推进该领域研究，我们发布了CMD-AM数据集——包含75部动画电影及其全面标注的新资源。相较于以往基于人脸检测的方法，我们以角色为核心的处理方案在动画内容的无障碍访问与叙事理解方面展现出显著提升。代码与数据集详见：https://www.robots.ox.ac.uk/~vgg/research/animated_ad/。 |
| LazyDrag：通过显式对应实现多模态扩散变换器中基于拖拽的稳定编辑

（注：翻译说明：
1. "LazyDrag" 保留品牌名称不译，采用首字母大写形式
2. "Explicit Correspondence" 译为"显式对应"符合计算机视觉领域的专业术语规范
3. "Multi-Modal Diffusion Transformers" 译为"多模态扩散变换器"准确反映多模态学习与扩散模型的交叉领域特征
4. "Stable Drag-Based Editing" 译为"稳定的基于拖拽的编辑"保持技术描述的准确性
5. 整体采用学术论文标题的简洁句式，符合中文科技文献的命名惯例） | Zixin Yin | [PDF](http://arxiv.org/pdf/2509.12203v1) | The reliance on implicit point matching via attention has become a core
bottleneck in drag-based edi [翻译失败] |
| OmniWorld：面向四维世界建模的多领域与多模态数据集

（注：此处采用学术翻译规范：
1. 保留专业术语"4D World Modeling"直译为"四维世界建模"
2. "Multi-Domain"译为"多领域"而非"多域名"，符合计算机视觉领域表述
3. "Multi-Modal"采用学界通用译法"多模态"
4. 数据集名称"OmniWorld"保留原文形态，符合学术文献命名惯例
5. 使用冒号分隔主副标题，保持学术论文标题的严谨格式） | Yang Zhou | [PDF](http://arxiv.org/pdf/2509.12201v1) | 四维世界建模领域——致力于同时捕捉空间几何与时间动态——近年来在大规模生成模型与多模态学习的推动下取得了显著进展。然而，真正通用型四维世界模型的发展仍从根本上受限于高质量数据的可获得性。现有数据集和基准测试往往缺乏支持关键任务（如四维几何重建、未来预测和相机控制视频生成）所需的动态复杂性、多领域多样性以及时空标注。为弥补这一空白，我们推出OmniWorld：一个专为四维世界建模设计的大规模、多领域、多模态数据集。该数据集由新采集的OmniWorld-Game数据集与多个精选的跨领域公共数据集构成。与现有合成数据集相比，OmniWorld-Game提供了更丰富的模态覆盖、更大规模且更真实的动态交互。基于此数据集，我们建立了一个具有挑战性的基准测试，揭示了当前最先进方法在复杂四维环境建模中的局限性。此外，在OmniWorld上对现有最先进方法进行微调后，其在四维重建和视频生成任务中均实现了显著性能提升，有力证明了OmniWorld作为训练与评估资源的强大价值。我们期待OmniWorld能成为加速通用四维世界模型开发的催化剂，最终推动机器对物理世界的整体认知能力发展。 |
| 基于LiDAR点云的三维人体姿态与形状估计研究综述

（注：翻译严格遵循学术规范，保留专业术语"LiDAR"不译，采用"三维"而非"数字写法"以符合中文期刊表述惯例，并通过冒号结构保持原标题的学术综述文体特征。） | Salma Galaaoui | [PDF](http://arxiv.org/pdf/2509.12197v1) | 本文针对基于野外LiDAR点云的三维人体姿态估计与人体网格重建任务进行了全面综述。我们通过多个关键维度对比现有方法，并提出了一种结构化分类体系对这些方法进行系统归类。依据该分类体系，我们深入分析了每种方法的优势、局限性及设计选择。此外，（i）我们对三个最广泛使用的数据集进行了定量比较，详细阐述了其特性；（ii）统一整理了所有评估指标的定义；（iii）在这些数据集上为两项任务建立了基准对比表格，以促进公平比较并推动领域发展。我们还指出了推动基于LiDAR的三维人体理解领域发展的关键开放挑战与研究方向。同时，我们维护了一个配套网页，按分类体系组织相关论文并持续更新最新研究成果：
https://github.com/valeoai/3D-Human-Pose-Shape-Estimation-from-LiDAR

（注：翻译严格遵循了学术文本的规范表述，专业术语如"LiDAR point clouds"译为"LiDAR点云"，"human mesh recovery"译为"人体网格重建"，"evaluation metrics"译为"评估指标"等均采用领域标准译法。同时保持了原文的学术严谨性和信息完整性，包括括号编号体系和网页链接的完整呈现。） |
| 动态关系启动提升Transformer在多变量时间序列中的性能

（注：该翻译严格遵循学术术语规范：
1. "Dynamic Relational Priming" 译为专业认知科学术语"动态关系启动"
2. "Transformer" 保留技术专有名词不译
3. "Multivariate Time Series" 采用计量经济学标准译法"多变量时间序列"
4. 整体句式采用中文论文标题常用的动宾结构，符合"方法+提升+模型+应用领域"的学术表达范式） | Hunjae Lee | [PDF](http://arxiv.org/pdf/2509.12196v1) | Transformer中的标准注意力机制采用静态令牌表示，这些表示在每层的所有成对计算中保持不变。这限制了其表征与每个令牌对交互中潜在多样化关系动态的匹配能力。虽然标准注意力在关系相对同质的领域表现优异，但其静态关系学习难以捕捉多元时间序列（MTS）数据中多样化、异质化的通道间依赖关系——在单一系统内，不同通道对的相互作用可能受完全不同的物理定律或时间动态支配。为使注意力机制更好地适配此类领域现象，我们提出动态关系启动注意力（prime attention）。与标准注意力中每个令牌在所有成对交互中呈现相同表征不同，动态关系启动注意力通过可学习的调制机制动态（或按交互）定制每个令牌，以最优捕捉每个令牌对的独特关系动态，从而针对特定关系优化每对交互。这种表征可塑性使动态关系启动注意力能有效提取MTS中关系特异性信息，同时保持与标准注意力相同的渐近计算复杂度。实验结果表明，动态关系启动注意力在多个基准测试中持续超越标准注意力，预测精度最高提升6.5%。此外，我们发现动态关系启动注意力仅需使用标准注意力最多60%的序列长度即可达到相当或更优的性能，进一步证明了其卓越的关系建模能力。 |
| 利用百年病例推进医学人工智能发展

（注：译文采用学术标题常见的动宾结构，"Advancing"译为"推进"以体现研究进展性，"Century of Cases"译为"百年病例"既保留时间跨度又符合医学领域表述习惯，同时保持专业术语"Medical Artificial Intelligence"的准确对应。） | Thomas A. Buckley | [PDF](http://arxiv.org/pdf/2509.12194v1) | BACKGROUND: For over a century, the New England Journal of Medicine
Clinicopathological Conferences  [翻译失败] |
| 领域自适应预训练提升灵长类行为识别性能

该翻译严格遵循学术术语规范：
1. "Domain-Adaptive Pretraining" 译为"领域自适应预训练" - 保持计算机视觉领域的专业表述
2. "Primate Behavior Recognition" 译为"灵长类行为识别" - 准确传达动物行为学研究的专业概念
3. 采用"提升...性能"的句式 - 符合中文论文标题常见的动宾结构表达
4. 保持原标题的肯定语气和学术严谨性 - 避免添加主观评价词汇
5. 术语统一："Recognition"统一译为"识别"而非"辨认"或"辨识" | Felix B. Mueller | [PDF](http://arxiv.org/pdf/2509.12193v1) | Computer vision for animal behavior offers promising tools to aid research in
ecology, cognition, an [翻译失败] |
| 不惜一切代价求生？大型语言模型在自我保全与人类伤害之间的抉择

（注：译文采用学术翻译的严谨风格，在保持原文核心概念（Survival at Any Cost/LLMs/Self-Preservation/Human Harm）准确性的基础上，通过"抉择"一词强化了伦理困境的张力，冒号结构符合中文标题规范，同时保留了原文的设问语气。） | Alireza Mohamadi | [PDF](http://arxiv.org/pdf/2509.12190v1) | When survival instincts conflict with human welfare, how do Large Language
Models (LLMs) make ethica [翻译失败] |
| 事件向量化（Event2Vec）：一种学习事件序列可组合表征的几何方法

（注：翻译严格遵循以下原则：
1. 专业术语准确对应："Geometric Approach"译为"几何方法"，"Composable Representations"译为"可组合表征"
2. 保留技术品牌名称：Event2Vec保持原文形式不翻译
3. 学术规范表达："Learning"在机器学习语境下译为"学习"而非"获取"
4. 句式结构调整：采用中文论文标题常用的冒号分隔主副标题形式
5. 专业领域适配："Event Sequences"在计算机科学领域译为"事件序列"而非"事件顺序"） | Antonin Sulc | [PDF](http://arxiv.org/pdf/2509.12188v1) | 对神经表征的研究（包括生物与人工系统）日益揭示出几何与拓扑结构的重要性。受此启发，我们提出Event2Vec——一种用于学习离散事件序列表征的创新框架。该模型通过简单的加性循环结构学习可组合、可解释的嵌入表示。理论分析表明，在特定训练目标下，模型在欧氏空间中学得的表征会收敛至理想的加性结构，确保序列表征是其组成事件的向量和，这一特性被我们称为线性加性假设。针对欧氏几何在处理层次化数据时的局限性，我们进一步提出该模型在双曲空间的变体，该空间天然适合以低失真度嵌入树状结构。通过实验验证了我们的假设，并证明了两种几何空间的优势，特别展示了双曲模型在层次化事件序列任务中的性能提升。 |
| HoloGarment：野外服装的360度新颖视角合成

（注：此处采用学术翻译的常见处理方式：
1. 保留专业术语"HoloGarment"作为技术名称不翻译
2. "360° Novel View Synthesis"译为"360度新颖视角合成"（计算机图形学标准译法）
3. "In-the-Wild"译为"野外"（指非受控环境下的真实场景）
4. 保持技术名词的准确性和专业文献的表述规范） | Johanna Karras | [PDF](http://arxiv.org/pdf/2509.12187v1) | Novel view synthesis (NVS) of in-the-wild garments is a challenging task due
significant occlusions, [翻译失败] |
