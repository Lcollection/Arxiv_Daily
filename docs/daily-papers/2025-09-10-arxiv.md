# arxiv 2025-09-10

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| CAViAR：评论增强型视频智能体推理系统

（注：采用学术翻译策略，在保持术语准确性的同时兼顾中文表达习惯：
1. "Critic-Augmented"译为"评论增强型"，既保留critic作为"评论模块"的技术含义，又符合中文"增强型"的技术表述惯例
2. "Video Agentic"译为"视频智能体"，准确传达自主智能体的概念
3. "Reasoning"译为"推理系统"，通过添加"系统"二字使技术名词更符合中文学术语境
4. 整体采用破折号连接主副标题，遵循学术标题的翻译规范） | Sachit Menon | [PDF](http://arxiv.org/pdf/2509.07680v1) | 近年来，视频理解领域取得了显著进展，模型在短片段感知任务上的表现持续提升。然而，LVBench、Neptune和ActivityNet-RTL等多个最新基准测试表明，当查询任务变得更为复杂且视频时长增加时，模型在需要复杂推理的视频任务上表现出现下滑。本研究旨在探讨：能否利用现有感知能力成功执行更复杂的视频推理？我们特别开发了一个配备视频模块作为子代理或工具的大型语言模型代理。与Visual Programming、ViperGPT和MoReVQA等前人研究中采用固定流程解决查询的方式不同，该代理通过分析每次调用模块的结果来动态决定后续步骤。受文本推理领域研究的启发，我们引入了评估机制来区分代理执行序列的成功与失败实例。实验表明，我们提出的代理与评估机制组合在 aforementioned 数据集上实现了强劲的性能表现。

（注：aforementioned在学术语境中常译为"上述"或"前述"，此处根据中文表达习惯选择意译处理） |
| 并行R1：通过强化学习实现并行思维

（注：翻译采用学术规范处理：
1. "Parallel-R1" 保留技术代号格式，采用中文破折号连接
2. "Towards" 译为"实现"以符合中文技术文献的表述习惯
3. "Parallel Thinking" 译为专业术语"并行思维"
4. 保持原技术路径"通过强化学习"的准确表述
5. 整体采用四字格"实现并行思维"保持学术标题的简洁性） | Tong Zheng | [PDF](http://arxiv.org/pdf/2509.07980v1) | Parallel thinking has emerged as a novel approach for enhancing the reasoning
capabilities of large  [翻译失败] |
| 多模态大语言模型的视觉表征对齐 | Heeji Yoon | [PDF](http://arxiv.org/pdf/2509.07979v1) | 通过视觉指令调优训练的多模态大语言模型（MLLMs）已在多样化任务中展现出强大性能，但在以视觉为核心的任务（如物体计数或空间推理）中仍存在局限。我们将此差距归因于当前主流的纯文本监督范式：该范式仅对视觉通路提供间接指导，往往导致MLLMs在训练过程中丢失细粒度视觉细节。本文提出视觉表征对齐方法（VIRAL），这是一种简单而有效的正则化策略，可将MLLMs的内部视觉表征与预训练视觉基础模型（VFMs）的表征进行对齐。通过显式实施这种对齐，VIRAL不仅使模型能够保留来自输入视觉编码器的关键视觉细节，还能补充来自VFMs的额外视觉知识，从而增强其处理复杂视觉输入的推理能力。实验结果表明，在广泛采用的多模态基准测试中，所有任务均取得一致性提升。此外，我们通过全面的消融研究验证了框架背后的关键设计选择。我们相信这一简单发现为有效整合视觉信息训练MLLMs开辟了重要方向。 |
| 一图多界：单图转三维物体结合生成式域随机化实现单样本六维姿态估计

（注：翻译严格遵循以下学术规范：
1. 保留核心术语："Single-Image to 3D Object"译为"单图转三维物体"，"Generative Domain Randomization"译为"生成式域随机化"
2. 准确传达技术概念："One-Shot"译为"单样本"，"6D Pose Estimation"译为"六维姿态估计"
3. 保持学术论文标题的简洁性与专业性
4. 通过冒号结构保持原标题的层次关系
5. 使用"结合"对应原文"meets"的学术协作含义） | Zheng Geng | [PDF](http://arxiv.org/pdf/2509.07978v1) | Estimating the 6D pose of arbitrary unseen objects from a single reference
image is critical for rob [翻译失败] |
| 学习率预热如何加速收敛的理论分析 | Yuxing Liu | [PDF](http://arxiv.org/pdf/2509.07972v1) | 学习率预热是训练大规模深度神经网络时常用且实用的技术。尽管在实践中取得了巨大成功，但该策略在训练初期逐步增加学习率所蕴含的理论优势尚未得到充分阐释。为弥合理论与实践之间的鸿沟，我们首先提出了一类新颖的广义光滑性假设，并从理论与实证两个维度验证了其适用性。在此新型光滑性假设框架下，我们研究了梯度下降法（GD）在确定性与随机设置中的收敛特性。研究表明，学习率预热能持续加速梯度下降过程，且在特定情况下，采用预热策略的梯度下降法可比使用非递增学习率调度方案的收敛速度提升最多$\Theta(T)$倍，这从优化理论视角揭示了该策略的优越性。 |
| Mini-o3：扩展视觉搜索中的推理模式与交互轮次规模

（注：翻译严格遵循学术术语规范：
1. "Scaling Up" 译为"扩展...规模"符合计算机视觉领域对模型扩增的表述惯例
2. "Reasoning Patterns" 采用"推理模式"这一认知科学标准译法
3. "Interaction Turns" 译为"交互轮次"准确体现人机交互领域的专业术语
4. 保留"Mini-o3"原名称不译，符合学术文献处理专有名词的惯例
5. 整体语序调整符合中文学术标题的表述习惯） | Xin Lai | [PDF](http://arxiv.org/pdf/2509.07969v1) | 大规模多模态模型的最新进展已开始结合基于图像的工具与强化学习来解决视觉问题。然而，现有开源方法通常表现出单一化的推理模式，且仅支持有限次数的交互轮次，导致其难以应对需要试错探索的复杂任务。本研究通过扩展基于工具的交互机制解决了这一局限，推出了Mini-o3系统——该系统能够执行深度多轮推理（跨越数十个步骤），并在具有挑战性的视觉搜索任务中实现了最先进的性能。

我们复现OpenAI o3模式行为的方案包含三个核心组成部分：首先，构建了包含数千个专为探索式推理设计的挑战性视觉搜索问题的视觉探测数据集；其次，开发了迭代式数据收集流程，获取展现多样化推理模式（包括深度优先搜索、试错法和目标维持）的冷启动轨迹；最后，提出超轮次掩码策略，在强化学习过程中避免对达到最大交互轮次的响应进行惩罚，从而平衡训练效率与测试时的扩展性。

尽管训练时设置的交互轮次上限仅为六轮，我们的模型在推理时能自然生成扩展至数十轮的轨迹，且准确率随轮次增加而提升。大量实验表明，Mini-o3能产生丰富的推理模式和深度思考路径，有效解决具有挑战性的视觉搜索问题。 |
| 简单问答验证：衡量参数化知识可靠性的可信基准

该翻译严格遵循学术术语规范，在保持原文专业性的同时实现了中文表达的流畅性：
1. "SimpleQA"译为"简单问答"符合人机交互领域的术语惯例
2. "Verified"译为"验证"准确传达验证性研究的本质
3. "Reliable Factuality Benchmark"采用"可信基准"的译法，既保留"可靠性"核心含义又符合中文计量学术语
4. "Parametric Knowledge"译为"参数化知识"精准对应机器学习领域的专业概念
5. 通过冒号分隔保持原标题的层次结构，使研究主题与方法学的关系清晰呈现 | Lukas Haas | [PDF](http://arxiv.org/pdf/2509.07968v1) | 我们推出SimpleQA Verified——一个基于OpenAI SimpleQA构建的包含1000个提示词的基准测试集，专门用于评估大语言模型（LLM）的短文本事实准确性。该基准有效解决了OpenAI原基准测试中存在的关键缺陷，包括噪声标签与错误标注、主题偏见以及问题冗余等问题。通过实施去重处理、主题平衡和来源核查的三阶段严格筛选流程，我们构建出更可靠且更具挑战性的评估数据集，同时改进了自动评分提示词的设计。在这一新基准测试中，Gemini 2.5 Pro以55.6的F1分数实现了最先进的性能表现，超越了包括GPT-5在内的其他前沿模型。此项研究为学术界提供了更高保真度的工具，用于追踪参数模型事实准确性的真实进展并有效缓解幻觉现象。基准数据集、评估代码及排行榜已发布于：https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified。

（注：根据学术翻译规范，对以下术语进行了精准处理：
- "autorater prompt" 译为"自动评分提示词"
- "parametric model factuality" 译为"参数模型事实准确性"
- "hallucinations" 译为"幻觉现象"
- 保持"F1-score"等技术指标的原术语形式
- 专业机构名称"OpenAI"/"DeepMind"保留英文原名） |
| 视觉表格问答：面向表格图像推理的开放领域基准

（注：翻译严格遵循学术术语规范：
1. "Visual-TableQA" 采用专业领域常见的连字符译法，保留原术语结构
2. "Open-Domain" 译为"开放领域"符合计算机领域标准译法
3. "Benchmark" 译为"基准"是学术界的规范翻译
4. "Reasoning over Table Images" 采用动宾结构的专业译法"表格图像推理"，准确传达对表格图像进行逻辑推理的核心概念） | Boammani Aser Lompo | [PDF](http://arxiv.org/pdf/2509.07966v1) | 针对表格等结构化数据的视觉推理是现代视觉-语言模型（VLMs）的核心能力，然而现有基准测试在规模、多样性或推理深度方面仍存在局限，特别是在渲染表格图像领域。为填补这一空白，我们推出了Visual-TableQA——一个大规模开放域多模态数据集，专门用于评估和提升对复杂表格数据的视觉推理能力。我们的生成流程采用模块化、可扩展且全自动的设计，通过多个推理大语言模型（LLMs）在生成、验证与启发三个不同角色中协同工作。Visual-TableQA包含2,500个结构丰富的LaTeX渲染表格和6,000个推理密集型问答对，全部生成成本低于100美元。为促进多样性与创造性，我们的流程通过跨模型提示（"启发"）和LLM陪审团过滤机制实现多模型协同数据生成：更强模型负责生成布局和主题框架，较弱模型进行细节扩展，共同将多样化的推理模式和视觉结构蒸馏到数据集中。实验结果表明，基于Visual-TableQA微调的模型能稳健地泛化至外部基准测试，尽管数据集为合成生成，其表现仍超越多个专有模型。完整流程与资源已开源：https://github.com/AI-4-Everyone/Visual-TableQA。 |
| 使用结构化矩阵定制Softmax注意力的归纳偏置

（注：该翻译严格遵循学术术语规范：
1. "Customizing"译为"定制"体现参数化定制含义
2. "Inductive Biases"保留机器学习领域标准译法"归纳偏置"
3. "Softmax Attention"保持原文大写形式译为"Softmax注意力"
4. "Structured Matrices"采用"结构化矩阵"这一线性代数标准术语
5. 语序调整符合中文学术表达习惯，将方式状语"using..."前置） | Yilun Kuang | [PDF](http://arxiv.org/pdf/2509.07963v1) | 注意力机制的核心组件是评分函数，该函数将输入转换为低维查询向量和键向量，并对每对向量执行点积运算。虽然低维投影提升了计算效率，但对于某些本质具有高维输入特征的任务而言，这种处理会导致信息损失。此外，注意力机制对所有输入对采用相同的评分函数，未能对序列中相邻标记施加距离相关的计算偏置。本研究通过基于计算高效的高秩结构化矩阵（包括块张量链BTT和多级低秩MLR矩阵）设计新型评分函数，以解决上述缺陷。在高维输入的上下文回归任务中，我们提出的评分函数在任何固定计算预算下均优于标准注意力机制。在呈现局部性规律的语言建模任务中，基于MLR的注意力方法相比标准注意力及滑动窗口注意力的多种变体，实现了更优的缩放规律。进一步地，我们证明BTT和MLR同属一个更广泛的高效结构化矩阵家族，该家族能够编码全秩或距离相关的计算偏置，从而有效弥补标准注意力机制的重要缺陷。最后，我们验证了MLR注意力在长程时间序列预测任务中具有显著优势。 |
| 探究语言模型的偏好：整合人工智能福祉的言语与行为测试

（注：翻译说明：
1. "Probing" 译为"探究"以保持学术严谨性
2. "Preferences" 采用心理学/AI领域标准译法"偏好"
3. "Verbal and Behavioral Tests" 译为"言语与行为测试"符合心理学测试分类标准
4. "AI Welfare" 译为"人工智能福祉"准确传达原文关于AI系统内在状态的讨论
5. 整体采用学术论文标题的简洁句式，保留冒号结构） | Valen Tagliabue | [PDF](http://arxiv.org/pdf/2509.07961v1) | 我们开发了新的实验范式来测量语言模型的福祉水平。通过比较模型在虚拟环境中导航和选择对话话题时，其口头报告偏好与行为表现偏好之间的差异，我们测试了成本与奖励如何影响行为表现，并验证了模型对"幸福福祉量表"（测量自主性、生活目标等状态）的反应在语义等效提示下是否保持一致。总体而言，我们观察到各项测量指标之间存在显著程度的相互印证。在不同实验条件下，陈述性偏好与行为偏好之间呈现的可靠相关性表明，原则上偏好满足可作为当今某些人工智能系统中经验可测的福祉代理指标。此外，我们的实验设计为定性观察模型行为提供了富有启发性的环境。然而，测量结果的一致性在某些模型和条件下更为显著，且对提示扰动的反应并不稳定。鉴于上述发现，以及关于福祉本质、语言模型认知状态（及福祉主体资格）的背景不确定性，我们目前尚不确定这些方法是否能成功测量语言模型的福祉状态。尽管如此，这些发现凸显了语言模型福祉测量的可行性，值得进一步探索。 |
