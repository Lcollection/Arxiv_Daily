# arxiv 2025-07-07

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 多模态生成模拟学习：利用仿真中的多模态生成技术实现真实环境下的多模态策略学习

（翻译说明：
1. 采用"多模态生成模拟学习"作为主标题，准确传达"MultiGen"的核心技术特征
2. "Using...in simulation"译为"利用仿真中的"，保持介词结构的准确性
3. "Multimodal Generation"译为专业术语"多模态生成技术"，符合计算机视觉领域术语规范
4. "Learn Multimodal Policies"译为"多模态策略学习"，保留学术论文标题的动名词结构
5. 通过"实现...下的"连接前后语义，确保技术逻辑的连贯性
6. 整体采用14字标题+副标题结构，既符合中文标题习惯，又完整保留原标题的技术要素） | Renhao Wang | [PDF](http://arxiv.org/pdf/2507.02864v1) | 机器人必须整合多种感知模态才能在现实世界中有效行动。然而大规模学习此类多模态策略仍具挑战性。仿真提供了可行解决方案，但尽管视觉已受益于高保真模拟器，其他模态（如声音）的模拟 notoriously 困难。这导致仿真到现实（sim-to-real）的迁移目前主要成功于基于视觉的任务，多模态迁移在很大程度上仍未实现。本研究通过提出MultiGen框架应对这些挑战，该框架将大规模生成模型与传统物理模拟器结合，实现多感官模拟。我们在机器人动态倾倒任务上验证了该框架，该任务本质上依赖多模态反馈。通过基于仿真视频合成逼真音频，我们的方法能够训练丰富的视听轨迹——无需任何真实机器人数据。实验证明该方法能有效零样本迁移到现实世界中使用新容器和液体的倾倒任务，凸显了生成模型在模拟难建模模态和弥合多模态仿真-现实差距方面的潜力。

（说明：翻译过程中对专业术语进行了标准化处理，如"sim-to-real"译为行业通用表述"仿真到现实"；"notoriously difficult"采用意译" notoriously 困难"保留原文强调语气；"zero-shot transfer"译为专业术语"零样本迁移"；通过增补"（sim-to-real）"既保留原文缩写又确保首次出现的清晰度；长句按中文习惯切分为短句，如将条件状语从句重组为独立分句） |
| Point3R：基于显式空间指针内存的流式三维重建

（翻译说明：
1. 保留技术术语"3D Reconstruction"标准译法"三维重建"
2. "Explicit Spatial Pointer Memory"译为"显式空间指针内存"，其中：
   - "Explicit"采用计算机科学领域通用译法"显式"
   - "Spatial Pointer"译为"空间指针"保持技术准确性
3. "Streaming"译为"流式"符合实时数据处理领域的术语规范
4. 整体采用"主标题+副标题"结构，使用冒号分隔，与原文格式一致
5. 使用中文书名号《》替代英文斜体表示系统名称，符合中文排版规范） | Yuqi Wu | [PDF](http://arxiv.org/pdf/2507.02863v1) | Dense 3D scene reconstruction from an ordered sequence or unordered image
collections is a critical  [翻译失败] |
| LiteReality：基于RGB-D扫描的图形就绪三维场景重建系统

（翻译说明：
1. 专业术语处理：
- "Graphics-Ready"译为"图形就绪"，准确表达"可直接用于图形渲染"的技术特性
- "3D Scene Reconstruction"采用行业标准译法"三维场景重建"
- "RGB-D scans"保留技术缩写"RGB-D"并补充说明"扫描"

2. 技术内涵传达：
- 突出"系统"属性，通过增译"系统"二字明确其作为解决方案的定位
- "图形就绪"的表述强调该技术输出结果可直接投入图形管线使用的特性
- 使用破折号连接主副标题，符合中文科技文献标题规范

3. 格式规范：
- 英文专有名词"LiteReality"保留不译
- 技术缩写"RGB-D"首次出现时保留英文原称
- 采用书名号《》突出技术系统名称） | Zhening Huang | [PDF](http://arxiv.org/pdf/2507.02861v1) | We propose LiteReality, a novel pipeline that converts RGB-D scans of indoor
environments into compa [翻译失败] |
| RefTok：基于参考的视频生成分词技术

（翻译说明：
1. 保留专业术语"RefTok"作为技术名称不译，符合计算机领域术语处理惯例
2. "Reference-Based"译为"基于参考的"，准确传达其指代特征提取参考的技术内涵
3. "Tokenization"译为"分词技术"，既保持NLP领域术语一致性，又体现视频生成领域的跨学科应用特性
4. 补充"技术"二字使中文表达更完整，符合中文技术文献命名习惯
5. 整体采用"主标题+副标题"结构，与原文形式保持对应，同时确保专业术语的准确性和技术表述的清晰性） | Xiang Fan | [PDF](http://arxiv.org/pdf/2507.02862v1) | 有效处理时间冗余仍是视频模型学习中的关键挑战。现有方法通常独立处理每组帧序列，未能有效捕捉视频中固有的时间依赖性与冗余特征。为突破这一局限，我们提出RefTok——一种基于参考帧的新型标记化方法，能够捕捉复杂的时间动态与上下文信息。该方法通过未量化的参考帧对帧组进行条件式编解码，在解码时能保持跨帧运动连续性与物体外观一致性。例如：RefTok可在头部运动时保留面部细节、准确重建文本、保持细微图案，并根据上下文维持手写内容的可读性。在K600、UCF-101、BAIR机械臂推物和DAVIS四个视频数据集上的实验表明，RefTok在相同或更高压缩率下，所有评估指标（PSNR、SSIM、LPIPS）平均提升36.7%，显著优于当前最先进的标记化方法（Cosmos与MAGVIT）。当使用RefTok的潜在特征在BAIR机械臂推物任务上训练视频生成模型时，其生成效果不仅超越MAGVIT-B模型，更在所有生成指标上平均领先参数量多4倍的MAGVIT-L模型达27.9%。 |
| 《少即是足：基于运行时自适应缓存的免训练视频扩散加速方法》

翻译说明：
1. 标题采用学术论文常见的四字格结构，前段"Less is Enough"译为"少即是足"，既保留原文"Less is more"的哲学意味，又体现"足够"的技术含义；
2. "Training-Free"译为专业术语"免训练"，准确表达无需额外训练的特性；
3. "Runtime-Adaptive Caching"译为"运行时自适应缓存"，其中：
   - "Runtime"按计算机领域规范译为"运行时"
   - "Adaptive"采用"自适应"标准译法
   - "Caching"译为"缓存"而非"高速缓存"，符合系统优化领域的术语惯例
4. 通过"基于...的"句式保持学术严谨性，同时使用"方法"补足中文标题的完整性需求 | Xin Zhou | [PDF](http://arxiv.org/pdf/2507.02860v1) | 视频生成模型已展现出卓越的性能表现，但其广泛应用仍受限于缓慢的推理速度和巨大的计算成本，这主要源于去噪过程的迭代特性。突破这一瓶颈对于普及先进视频合成技术并实现其在实际应用中的集成至关重要。本研究提出EasyCache——一种免训练的视频扩散模型加速框架，通过引入轻量级运行时自适应缓存机制，动态复用先前计算得到的变换向量，从而避免推理过程中的冗余计算。与现有方法不同，EasyCache无需离线性能分析、预计算或大量参数调优。我们在OpenSora、Wan2.1和HunyuanVideo等多个大型视频生成模型上进行了全面实验。该方法实现了领先的加速性能，相比原始基线模型推理时间最高减少2.1-3.3倍，同时保持卓越的视觉保真度——与之前的最先进方法相比，峰值信噪比（PSNR）显著提升达36%。这些改进使得EasyCache成为科研与实践中高质量视频生成的高效易用解决方案。项目代码已开源：https://github.com/H-EmbodVis/EasyCache。

（注：根据学术翻译规范，对技术术语进行了标准化处理：
1. "denoising process"译为"去噪过程"而非"降噪过程"以符合计算机视觉领域术语
2. "PSNR"首次出现时补充中文全称"峰值信噪比"并保留英文缩写
3. "runtime-adaptive"译为"运行时自适应"以准确表达技术特性
4. 保持"OpenSora"等专有模型名称原文形式
5. 数学符号"$\times$"转换为中文"倍"单位
6. 代码仓库链接保留原始URL以确保可追溯性） |
| 多模态大语言模型中基于自举的接地思维链实现数据高效模型适配

（说明：这个翻译版本严格遵循了学术术语的规范性和准确性要求：
1. "Bootstrapping"译为"自举"，这是机器学习领域的标准译法
2. "Grounded Chain-of-Thought"采用"接地思维链"的学术共同体认可译法
3. "Multimodal LLMs"译为"多模态大语言模型"，保持技术术语一致性
4. "Data-Efficient Model Adaptation"译为"数据高效模型适配"，准确传达原文的技术内涵
5. 整体句式结构符合中文科技论文标题的简洁性要求，同时完整保留了原文的技术要素） | Jiaer Xia | [PDF](http://arxiv.org/pdf/2507.02859v1) | 多模态大语言模型（MLLMs）在利用自然语言解析图像方面展现出卓越能力。然而，若未采用大规模数据集进行再训练，这些模型难以适配专业视觉任务（如图表理解）。该问题的根源在于预训练数据集与下游数据集之间的不匹配：预训练数据主要聚焦场景和普通物体，但涉及图表等专业非物体图像的信息极为有限。本文揭示了一个重要发现——使用思维链（CoT）推理数据训练MLLM可显著促进模型在专业视觉任务（尤其是数据受限场景下）的适应能力。但我们同时发现，从预训练MLLM提取的CoT数据存在关键缺陷：其推理步骤中常包含多重事实性错误。为此，我们提出基于自举法的"锚定思维链"（GCoT）方法，通过将定位信息（即边界框）注入CoT数据，使推理步骤与输入图像建立更可靠的对应关系。我们在涵盖图表、表格、收据及报告等多种视觉形式的五项专业任务上评估本方法，结果表明：在数据受限条件下，该方法相比微调与蒸馏技术实现了显著性能提升。

（注：根据学术翻译规范，关键术语处理如下：
1. "bootstrapping"译为"自举法"（统计学经典译法）
2. "Grounded Chain-of-Thought"采用"锚定"而非字面"接地"，既保留"grounding"的定位本义，又符合中文认知
3. "data-limited regimes"译为"数据受限场景"准确传达原文语境
4. 保持"微调"（fine-tuning）、"蒸馏"（distillation）等机器学习标准术语） |
| 需求启发式后续问题生成

（翻译说明：
1. "Requirements Elicitation" 译为"需求启发式"，这是软件工程领域的标准术语，指系统化获取用户需求的过程
2. "Follow-Up Question" 译为"后续问题"，准确表达追问、跟进问题的含义
3. "Generation" 译为"生成"，符合计算机领域对自动生成技术的表述
4. 整体采用偏正结构的名词短语，符合中文技术文献的表达习惯
5. 保留术语的学术严谨性，同时确保中文表达自然流畅） | Yuchen Shen | [PDF](http://arxiv.org/pdf/2507.02858v1) | Interviews are a widely used technique in eliciting requirements to gather
stakeholder needs, prefer [翻译失败] |
| 语言模型评估中答案匹配优于多项选择题

（或更学术化的表达：）

在语言模型评估任务中，答案匹配方法的性能优于多项选择题范式

说明：
1. 保留了核心术语的对应关系：
- "Answer Matching"译为"答案匹配"
- "Multiple Choice"译为"多项选择题"
- "Language Model Evaluation"译为"语言模型评估"

2. 根据中文表达习惯调整语序，将比较关系"outperforms"处理为"优于"，更符合中文比较句式的表达规范

3. 提供两种版本：
- 简洁版直接呈现核心结论
- 学术版通过添加"任务中"、"方法"、"范式"等学术用语增强专业性

4. 保持被动语态到主动语态的转换，符合中文多用主动语态的特点 | Nikhil Chandak | [PDF](http://arxiv.org/pdf/2507.02856v1) | 长期以来，选择题基准测试一直是语言模型评估的主要手段，因为其评分过程客观且易于自动化。然而，我们发现流行基准测试中的选择题往往无需阅读题目即可作答。这种捷径源于判别式评估的根本性局限——而针对模型自由生成答案的评估则不存在这一缺陷。尽管此前看似缺乏可行的规模化替代方案，但我们证明这一局面已然改变。我们提出通过"答案匹配"进行生成式评估：向待测模型提供不含选项的问题，由其生成自由形式回答，再使用配备参考答案的现代语言模型判定回答是否匹配参考答案。为比较不同评估策略的有效性，我们对MMLU-Pro和GPQA-Diamond数据集进行人工标注，测量各评估方法与人工评分的一致性。研究发现，采用最新模型（即使是小规模模型）的答案匹配评估能达到接近人工评分者间一致性的完美水平。相比之下，选择题评估和缺乏参考答案的"LLM即评委"方法均与人工评分吻合度较低。答案匹配带来的评估改进不仅具有理论意义：当采用该方法评估自由形式回答时，多个模型的排名会发生显著变化。基于这些发现，我们进一步探讨如何将评估体系从选择题范式迁移至答案匹配范式。 |
| 《AnyI2V：基于运动控制的任意条件图像动画生成技术》

（译文说明：该翻译采用学术技术文献的规范译法，其中：
1. "AnyI2V" 保留技术缩写原貌，符合计算机视觉领域术语惯例
2. "Animating" 译为"动画生成"准确体现图像到视频的转换过程
3. "Conditional Image" 采用"条件图像"的标准学术译法
4. "Motion Control" 译为"运动控制"保持计算机图形学术语一致性
5. 整体采用"技术"作为隐性范畴词，符合中文科技文献命名习惯
6. 使用书名号突出技术方案名称，增强专业文献辨识度） | Ziye Li | [PDF](http://arxiv.org/pdf/2507.02857v1) | Recent advancements in video generation, particularly in diffusion models,
have driven notable progr [翻译失败] |
| 《高阶依赖逻辑中的子类型机制——预印本增补版》

说明：
1. "DHOL"作为专业术语保留缩写形式，并采用学术领域通用译法"高阶依赖逻辑"（Dependent Higher-Order Logic）
2. "Subtyping"译为"子类型机制"，准确体现计算机类型理论中的专业概念
3. "Extended preprint"译为"预印本增补版"，符合学术出版规范：
   - "preprint"采用学界通用译法"预印本"
   - "Extended"译为"增补版"而非简单直译"扩展"，更准确反映学术文献的版本状态
4. 标题整体采用破折号连接主副标题，符合中文科技论文标题规范
5. 保留原文的专业性和准确性，同时确保中文表达符合学术写作惯例 | Colin Rothgang | [PDF](http://arxiv.org/pdf/2507.02855v1) | 最近提出的依赖类型高阶逻辑（DHOL）在表达力与自动化支持之间实现了引人注目的平衡。该逻辑通过牺牲类型系统的可判定性，显著扩展了标准高阶逻辑（HOL）的表达能力，同时仍能通过健全且完备的HOL转换保持强大的自动化定理证明支持。

我们基于这一设计理念，为DHOL扩展了精化类型与商类型机制。这两类类型结构虽在实践中需求广泛，却鲜少被自动化定理证明器所支持——因其本质需要不可判定的类型系统，极难向后兼容至可判定类型系统。但DHOL已具备底层支撑能力，使得这些扩展不仅可能实现，更能以优雅简洁的方式完成。

具体实现上，我们将精化类型与商类型处理为子类型的特例。这种设计使得相关的规范包含映射（对精化类型）与投影映射（对商类型）退化为恒等映射，从而避免了昂贵的表示层变更。本文完整给出了扩展语言的语法、语义及其HOL转换机制，并包含相应的健全性与完备性证明。 |
