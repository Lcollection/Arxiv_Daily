# arxiv 2025-10-06

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| LEAML：面向多模态大语言模型的分布外视觉任务标签高效适配方法

（注：该翻译采用学术文献标题的经典译法：
1. 保留英文缩写"LEAML"保持术语一致性
2. "Label-Efficient"译为"标签高效"准确传达核心方法论
3. "Out-of-Distribution Visual Tasks"译为"分布外视觉任务"符合机器学习领域术语规范
4. 使用"适配方法"对应"Adaptation"体现模型迁移学习的动态过程
5. 通过"面向..."的句式清晰建立多模态大语言模型与研究主体的逻辑关系） | Ci-Siang Lin | [PDF](http://arxiv.org/pdf/2510.03232v1) | 多模态大语言模型（MLLM）在通用视觉基准测试中表现出色，但在医疗影像等专业领域的分布外（OOD）任务中表现欠佳——这些领域标注数据稀缺且成本高昂。我们提出LEAML框架，通过利用少量标注的视觉问答样本与大量未标注图像，实现标签高效的自适应。该方法通过标题蒸馏正则化的问答生成器，为未标注数据生成领域相关的伪问答对。关键创新在于选择性更新仅与问答任务最相关的神经元，使问答生成器在蒸馏过程中高效获取领域知识。在胃肠内镜和运动视觉问答上的实验表明，在最小监督条件下LEAML持续优于标准微调方法，凸显了该框架的有效性。 |
| 奖励模型不过是披着风衣的指标

（注：该翻译采用意译手法，通过"披着风衣"的隐喻既保留了原文"Trench Coat"的意象，又准确传达了"看似复杂实则本质简单"的学术观点。"Metrics"译为"指标"符合机器学习领域的术语规范，"Reward Models"作为专业术语保持直译为"奖励模型"。整个译文在保证学术准确性的同时，通过中文特有的修辞手法实现了原文的修辞效果。） | Sebastian Gehrmann | [PDF](http://arxiv.org/pdf/2510.03231v1) | 在大语言模型后训练过程中，强化学习的出现引发了人们对奖励模型的广泛关注。奖励模型通过评估采样输出的质量来生成训练信号，而这一职能与监测AI模型性能的评估指标高度重合。我们发现这两个研究领域目前基本处于割裂状态，导致术语冗余和问题重复出现。共有的挑战包括：对伪相关性的敏感性、下游奖励破解的影响、提升数据质量的方法以及元评估的实施路径。本立场文件认为，加强领域协作将有助于解决这些问题。为此，我们通过具体案例展示了评估指标在特定任务上优于奖励模型的表现，并对两个领域进行了系统综述。基于此综述，我们指出在偏好诱导方法、规避伪相关性与奖励破解、以及考虑校准的元评估等多个研究方向，加强领域融合将有效提升奖励模型与评估指标的性能表现。 |
| 通过显式位置到坐标映射提升图形用户界面定位能力 | Suyuchen Wang | [PDF](http://arxiv.org/pdf/2510.03230v1) | GUI接地任务（即将自然语言指令映射到像素坐标）对自主智能体至关重要，但当前视觉语言模型仍难以有效解决。其核心瓶颈在于可靠的区块到像素映射机制——当模型外推至训练时未见的高分辨率显示界面时，这种映射关系就会失效。现有方法直接从视觉特征生成文本标记形式的坐标，迫使模型隐式推断复杂的位置-像素映射关系，导致在新分辨率下准确度下降且故障频发。我们通过两项互补的创新解决这一问题：首先，RULER标记作为显式坐标标记，使模型能像地图网格线般参照定位，通过坐标调整而非从零生成；其次，交错多维旋转位置编码通过确保宽度与维度表征的均衡性，改善了标准位置编码方案的不对称问题。在ScreenSpot、ScreenSpot-V2和ScreenSpot-Pro数据集上的实验表明，该方法持续提升接地准确度，尤其在高分辨率界面实现最大幅度改进。通过提供显式空间引导而非依赖隐式学习，我们的方法实现了跨分辨率跨平台的更可靠GUI自动化。 |
| MIXER：面向纹理识别的混合超球面随机嵌入神经网络

（解析说明：
1. 保留首字母缩略词"MIXER"不译，维持技术术语的原始标识性
2. "Mixed Hyperspherical Random Embedding"采用"混合超球面随机嵌入"的译法：
   - Hyperspherical对应"超球面"，是几何学习领域的标准术语
   - Random Embedding译为"随机嵌入"，符合表示学习领域的命名规范
3. 神经网络类型说明后置，通过"面向...的"连接应用领域
4. "Texture Recognition"译为"纹理识别"，符合计算机视觉领域术语标准
5. 整体采用技术文献标题的简洁译法，保持学术表达的精确性） | Ricardo T. Fares | [PDF](http://arxiv.org/pdf/2510.03228v1) | 用于表征学习的随机神经网络在纹理识别任务中持续取得显著成果，有效结合了传统技术与基于学习方法的双重优势。然而现有方法主要聚焦于改进跨信息预测机制，尚未对整体随机网络架构带来重大突破。本文提出Mixer——一种用于纹理表征学习的新型随机神经网络。该方法的核心理念在于利用超球面随机嵌入与双分支学习模块相结合，同步捕获通道内与通道间的关联特性，并通过新构建的优化问题进一步增强纹理表征的丰富性。实验结果表明，该方法在多个具有不同特征与挑战的纯纹理基准数据集上均展现出令人瞩目的性能。源代码将于论文发表时同步公开。 |
| 通过潜在集成随机共振实现对抗攻击的测试时防御 | Dong Lao | [PDF](http://arxiv.org/pdf/2510.03224v1) | 我们提出一种针对对抗攻击的测试时防御机制：通过难以察觉的图像扰动来显著改变模型预测结果。与现有依赖特征过滤或平滑的方法不同——这类方法可能导致信息损失——我们提出“以噪治噪”策略，利用随机共振现象在最小化信息损失的同时增强模型鲁棒性。该方法通过对输入图像施加微小平移扰动，对齐变换后的特征嵌入，在映射回原始参考图像前进行特征聚合。整个过程可表示为封闭形式的数学公式，无需引入额外网络模块或针对特定攻击类型进行微调，即可部署于多种现有网络架构。该方法完全无需训练、与网络架构无关且适用于各类攻击。实验结果表明，在图像分类任务中实现了最先进的鲁棒性表现，并首次为稠密预测任务（包括立体匹配与光流估计）建立了通用测试时防御方案，彰显了方法的通用性与实用性。具体而言，在多种对抗攻击下，相较于干净（未扰动）样本的性能基准，我们的方法在图像分类任务中恢复了高达68.1%的准确率损失，在立体匹配任务中恢复71.9%，在光流估计任务中恢复29.2%。 |
| 自锚定：基于逐步注意力对齐的大语言模型推理方法 | Hongxiang Zhang | [PDF](http://arxiv.org/pdf/2510.03223v1) | 为解决大语言模型在复杂推理任务中的挑战，基于提示的方法提供了一种轻量级的替代方案，无需微调与强化学习。然而随着推理链的延伸，关键的中间步骤与原始提示往往湮没在上下文中，导致注意力分散并引发错误。本文提出Self-Anchor创新框架，通过利用推理过程的内在结构来引导大语言模型的注意力机制。该框架将推理轨迹解构为结构化方案，自动将模型注意力对齐至最相关的推理步骤，使模型在生成过程中始终保持焦点。实验表明，Self-Anchor在六项基准测试中均优于当前最先进的提示方法。值得注意的是，该方法显著缩小了“非推理”模型与专用推理模型之间的性能差距，有望使大多数大语言模型无需重新训练即可处理复杂推理任务。 |
| 在可验证奖励的强化学习中，低概率标记持续驱动探索

（注：该翻译采用学术文献常用表达方式，通过以下处理确保专业性：
1. 保留"低概率标记"作为强化学习领域术语"Low-probability Tokens"的标准译法
2. "Sustain Exploration"译为"持续驱动探索"体现持续性动态过程
3. "Verifiable Reward"采用"可验证奖励"准确对应可验证性技术特征
4. 整体句式采用中文论文标题常见的"在...中"结构，符合学术表达规范） | Guanhua Huang | [PDF](http://arxiv.org/pdf/2510.03222v1) | 具有可验证奖励的强化学习（RLVR）虽能推动大语言模型在复杂推理任务中的发展，但其扩展性常受训练瓶颈制约——当策略熵坍缩时性能趋于停滞，这标志着探索能力的丧失。现有方法通常通过维持高策略熵来解决该问题，然而对有效探索调控机制的研究仍显不足。我们的分析表明，盲目关注熵值可能放大无关词元并破坏训练稳定性。本文深入探究RLVR中的探索动态，发现关键问题在于：具有价值的低概率探索性词元会逐渐被淘汰，我们将其命名为**推理火花**。研究发现，尽管预训练模型中富含这类火花，但在RLVR过程中会因过度惩罚而系统性湮灭，导致探索能力退化。为此，我们提出低概率正则化方法（Lp-Reg），其核心机制是通过启发式代理分布对策略进行正则化。该代理分布通过滤除预设噪声词元并对剩余候选集重归一化构建，最终形成噪声更少的分布——其中推理火花的概率被显著放大，进而作为KL散度约束下的柔性正则目标，保护这些珍贵词元免遭淘汰。实验表明，Lp-Reg能实现约1,000步的稳定同策略训练，而基线熵控制方法在此区间已失效。这种持续探索能力带来了突破性性能：在五项数学基准测试中达到60.17%的平均准确率，较现有方法提升2.66%。代码已开源：https://github.com/CarlanLark/Lp-Reg。 |
| 《弃权与验证：一种降低智能程序修复噪声的双大语言模型策略》 | José Cambronero | [PDF](http://arxiv.org/pdf/2510.03217v1) | 自主式自动程序修复（APR）系统正日益致力于解决工业环境中复杂的仓库级缺陷，但最终由智能体生成的补丁仍需经过人工审核才能提交，以确保其真正修复缺陷。向开发人员展示低质量补丁会产生显著干扰，既浪费宝贵的开发时间，又削弱对自动化代码修改的信任。我们提出两种基于大语言模型的互补策略来降低此类干扰：缺陷弃置策略与补丁验证策略。缺陷弃置策略可排除自主式APR系统难以修复的缺陷，补丁验证策略则能筛除不符合修复要求的补丁。我们在谷歌代码库的三组缺陷集及其内部自主式APR系统生成的候选补丁上评估了这两种策略。针对174个人工上报的缺陷集，通过策略筛除不合格缺陷及补丁轨迹后，成功率分别最高提升13个百分点和15个百分点，联合应用时最高可提升39个百分点。对于空指针异常和检测器报告（含机器生成缺陷报告）的缺陷类型，补丁验证策略同样提升了平均单样本成功率。这种双策略方法为自主式APR系统实现可靠的工业级部署提供了可行路径。 |
| Wave-GMS：面向医学图像分割的轻量化多尺度生成模型

（解析说明：
1. 保留核心模型名称"Wave-GMS"不翻译，维持学术术语的准确性
2. "Lightweight"译为"轻量化"符合计算机领域术语规范
3. "Multi-Scale Generative Model"采用"多尺度生成模型"的标准译法
4. 专业领域标注"医学图像分割"明确应用范围
5. 整体采用"定语前置"的中文学术标题惯用结构，保持简洁严谨） | Talha Ahmed | [PDF](http://arxiv.org/pdf/2510.03216v1) | 为实现人工智能工具在医院及医疗机构的公平部署，我们需要具备高性能且能在有限显存GPU上实现大批次训练的深度分割网络。本研究提出Wave-GMS——一种轻量高效的医学图像分割多尺度生成模型。该模型具有显著减少的可训练参数量，无需加载高内存消耗的预训练视觉基础模型，并支持在有限显存GPU上进行大批次训练。我们在四个公开数据集（BUS、BUSI、Kvasir-Instrument和HAM10000）上开展大量实验，证明Wave-GMS仅需约260万可训练参数即可实现最先进的分割性能，并具有卓越的跨领域泛化能力。代码已发布于https://github.com/ATPLab-LUMS/Wave-GMS。 |
| 缓存间直连：大型语言模型间的直接语义通信 | Tianyu Fu | [PDF](http://arxiv.org/pdf/2510.03215v1) | 多大型语言模型系统通过整合不同大语言模型的互补优势，实现了单一模型无法达到的性能与效率提升。现有设计中，LLM之间通过文本进行通信，这迫使内部表征必须转换为输出词元序列。该过程不仅会损失丰富的语义信息，还会产生逐词元生成的延迟。基于这些局限性，我们提出核心问题：LLM能否实现超越文本的通信？预研实验表明，在保持缓存大小不变的情况下，增强KV-Cache的语义表征可提升响应质量，这验证了KV-Cache作为模型间通信媒介的有效性。为此，我们提出缓存间直接通信（C2C）新范式，实现LLM间的直接语义传递。C2C通过神经网络将源模型的KV-Cache投影并融合至目标模型的KV-Cache，从而完成直接语义传输。可学习的门控机制会筛选出能受益于缓存通信的目标模型层。相较于文本通信，C2C既能充分利用双模型的深度专业化语义，又避免了显式中间文本生成。实验表明：C2C相较单一模型平均准确率提升8.5-10.5%；较文本通信范式平均准确率进一步提高约3.0-5.0%，同时延迟平均加速2.0倍。代码已开源：https://github.com/thu-nics/C2C。 |
