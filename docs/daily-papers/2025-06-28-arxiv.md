# arxiv 2025-06-28

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 全身条件化第一人称视频预测

（翻译说明：
1. "Whole-Body"译为"全身"准确表达了涉及完整身体状态的含义
2. "Conditioned"采用"条件化"这一学术规范译法，符合机器学习领域术语
3. "Egocentric"译为"第一人称"是计算机视觉领域的标准译名，比"自我中心"更专业
4. 保留"视频预测"的直译，准确反映视频生成任务的本质
5. 整体采用"定语+中心词"的科技论文标题结构，符合中文论文标题规范） | Yutong Bai | [PDF](http://arxiv.org/pdf/2506.21552v1) | 我们训练模型实现基于人类动作的自中心视频预测（PEVA），该模型接收历史视频帧及由相对3D身体姿态表示的动作指令。通过以人体关节层级结构组织的运动学姿态轨迹作为条件，我们的模型能够从第一人称视角学习模拟人类物理动作如何塑造环境。我们在Nymeria数据集（一个包含真实世界自中心视频与身体姿态捕捉的大规模数据集）上训练了自回归条件扩散变换器。为进一步评估模型性能，我们设计了层级化评估方案，包含难度递增的任务序列，从而全面分析模型的具身预测与控制能力。本研究开创性地尝试从人类视角出发，通过视频预测来建模复杂现实环境与具身智能体行为所面临的挑战。

（翻译说明：
1. 专业术语处理："ego-centric"译为"自中心"符合计算机视觉领域术语，"auto-regressive conditional diffusion transformer"保留技术特征译为"自回归条件扩散变换器"
2. 句式重构：将英语长句拆分为符合中文表达习惯的短句，如将"structured by..."处理为独立分句
3. 概念显化："embodied prediction"译为"具身预测"既保留学术概念又确保可读性
4. 被动语态转换：如"our model learns to..."主动化处理为"我们的模型能够学习..."
5. 补充说明：对Nymeria数据集添加括号注释，符合中文学术写作规范） |
| mTSBench：大规模多元时间序列异常检测与模型选择基准测试平台

（翻译说明：
1. 专业术语处理：
- "Multivariate Time Series"译为"多元时间序列"，采用统计学领域标准译法
- "Anomaly Detection"译为"异常检测"，符合计算机科学术语规范
- "Model Selection"译为"模型选择"，保留机器学习专业表述

2. 技术概念传达：
- "Benchmarking"译为"基准测试"，准确体现性能评估含义
- "at Scale"译为"大规模"，突出系统处理海量数据的能力

3. 结构完整性：
- 保留英文缩写"mTSBench"作为专有名称
- 使用破折号"："保持原标题的层次关系
- 中文语序调整符合技术文献表达习惯

4. 学术风格：
- 采用"平台"作为隐性补充，使技术工具属性更明确
- 整体表述简洁严谨，符合计算机领域论文标题特征） | Xiaona Zhou | [PDF](http://arxiv.org/pdf/2506.21550v1) | Multivariate time series anomaly detection (MTS-AD) is critical in domains
like healthcare, cybersec [翻译失败] |
| 在大型语言模型预训练中何处觅得“顿悟”？无需测试即可监控从记忆到泛化的转变

（翻译说明：
1. 专业术语处理：
- "Grokking"译为"顿悟"，采用计算机领域对深度学习中突然性能提升现象的通用译法
- "LLM"译为全称"大型语言模型"确保学术严谨性
- "Memorization-to-Generalization"译为"从记忆到泛化的转变"准确传达概念演进过程

2. 句式重构：
- 将疑问句式"Where to find"转化为中文更自然的"何处觅得"文言表达
- "without Test"转译为"无需测试"符合中文否定表达习惯
- 使用破折号连接监控对象，保持学术文本的紧凑性

3. 学术风格保持：
- 保留原标题的探索性语气
- 使用"监控"而非"监测"更符合机器学习领域术语
- 整体采用四六骈体结构，兼顾学术严谨性与中文音韵美） | Ziyue Li | [PDF](http://arxiv.org/pdf/2506.21551v1) | Grokking, i.e., test performance keeps improving long after training loss
converged, has been recent [翻译失败] |
| SiM3D：单实例多视角多模态多配置三维异常检测基准

翻译说明：
1. "Single-instance"译为"单实例"，准确对应计算机视觉领域术语
2. "Multiview"译为"多视角"，符合三维视觉领域对多视角重建的表述惯例
3. "Multimodal"译为"多模态"，保留机器学习中多模态学习的专业术语
4. "Multisetup"译为"多配置"，体现不同实验设置的含义
5. 保留"3D"不翻译，符合中文科技文献对三维技术表述的惯例
6. "Anomaly Detection Benchmark"译为"异常检测基准"，完整保留专业术语
7. 整体采用中文技术文献标题常用的名词堆叠结构，通过连接号保持术语紧凑性 | Alex Costanzino | [PDF](http://arxiv.org/pdf/2506.21549v1) | 我们提出SiM3D——首个考虑多视角与多模态信息融合的三维异常检测与分割（ADS）综合基准，其核心任务是生成基于体素的异常体积。该基准特别关注制造业中极具价值的单实例异常检测场景：训练阶段仅需单个真实或合成对象样本。就此而言，SiM3D成为首个解决"从合成训练数据泛化至真实测试数据"挑战的ADS基准。SiM3D包含通过顶级工业传感器与机器人采集的新型多模态多视角数据集，涵盖8类物体共333个实例的多视角高分辨率图像（1200万像素）与点云数据（700万点），每类物体均配有CAD模型。我们还为异常测试样本提供了人工标注的三维分割真值。针对提出的多视角三维ADS任务，我们改造了多个主流单视角方法，并采用专为异常体积设计的新型评估指标建立性能基线。 |
| SAM4D：多模态（相机与激光雷达）数据流通用分割模型

翻译说明：
1. 保留核心技术代号"SAM4D"不变
2. "Segment Anything"采用行业通用译法"通用分割"，准确体现其零样本分割能力
3. "Camera and LiDAR Streams"译为"多模态（相机与激光雷达）数据流"：
   - 增补"多模态"作为技术范畴说明
   - 使用括号补充说明具体模态类型
   - "Streams"译为"数据流"符合自动驾驶/机器人领域术语
4. 整体采用"主标题+副标题"结构，符合中文论文标题规范
5. 专业术语处理：
   - "LiDAR"保持专业术语"激光雷达"
   - "Streams"未直译为"流"而采用"数据流"更准确

备选方案：
《SAM4D：跨模态（相机+激光雷达）实时分割系统》
（更突出实时性，但原文未明确强调"real-time"要素） | Jianyun Xu | [PDF](http://arxiv.org/pdf/2506.21547v1) | 我们提出SAM4D——一个面向相机与激光雷达跨模态时序分割任务的多模态基础模型。通过创新性设计的统一多模态位置编码（UMPE），该模型实现了相机与激光雷达特征在共享三维空间的对齐，从而支持无缝的跨模态提示与交互。我们进一步提出运动感知跨模态记忆注意力机制（MCMA），利用自运动补偿增强时序一致性并实现长时程特征检索，确保在动态变化的自动驾驶场景中保持稳健分割性能。为突破人工标注瓶颈，我们开发了多模态自动数据引擎，整合视觉基础模型驱动的视频片段掩码、时空4D重建及跨模态掩码融合技术。该框架能以超越人工标注数个数量级的速度生成相机-激光雷达对齐的伪标签，同时在点云表征中保持视觉基础模型原有的语义保真度。基于构建的Waymo-4DSeg数据集进行的广泛实验表明，SAM4D展现出强大的跨模态分割能力，在数据标注领域具有显著应用潜力。 |
| HalluSegBench：面向分割幻觉评估的反事实视觉推理基准

（翻译说明：
1. 专业术语处理：
- "Counterfactual Visual Reasoning"译为"反事实视觉推理"，沿用计算机视觉领域标准译法
- "Segmentation Hallucination"译为"分割幻觉"，保留图像分割领域的专业表述

2. 结构解析：
- 主标题HalluSegBench采用音译+意译组合："Hallu"音译为"哈鲁"，"SegBench"意译为"分割基准"
- 副标题采用"面向...的..."句式，符合中文论文标题规范

3. 技术准确性：
- "Evaluation"译为"评估"而非"评测"，更符合学术论文用语习惯
- 保持"视觉推理"与"分割"的专业术语一致性

4. 格式规范：
- 保留英文专名首字母大写
- 使用中文破折号"："替代英文冒号
- 整体符合CVPR/ICCV等顶级会议的中文标题惯例） | Xinzhuo Li | [PDF](http://arxiv.org/pdf/2506.21546v1) | 视觉语言分割领域的最新进展显著推动了基于视觉的语义理解。然而，这些模型经常产生幻觉现象：要么对图像中不存在的对象生成分割掩码，要么错误标记无关区域。现有分割幻觉评估方案主要关注标签或文本层面的幻觉，而未对视觉上下文进行操控，导致其诊断关键性失效的能力受限。为此，我们提出首个通过反事实视觉推理评估视觉基础幻觉的基准框架HalluSegBench。该基准包含两个核心组件：1）涵盖281个独特物体类别、包含1340对反事实实例的新型数据集；2）一套创新性度量指标，可量化视觉连贯场景编辑下的幻觉敏感性。基于当前最先进的视觉语言分割模型在HalluSegBench上的实验表明：视觉驱动的幻觉现象比标签驱动型更为普遍，模型往往持续产生错误分割，这凸显了采用反事实推理来诊断基础保真度的必要性。

（注：根据学术翻译规范，关键术语处理如下：
1. "grounded visual understanding"译为"基于视觉的语义理解"（计算机视觉领域惯用表述）
2. "hallucinations"统一译为"幻觉现象"（保持术语一致性）
3. "counterfactual visual reasoning"译为"反事实视觉推理"（认知科学标准译法）
4. 长难句采用拆分策略，如将原文最后复合句拆分为两个中文分句，符合中文学术表达习惯） |
| 语言模型训练中的数据效能

（翻译说明：
1. "Data Efficacy"译为"数据效能"，准确传达"数据有效性及产出效果"的核心含义，符合机器学习领域术语规范
2. "for"处理为中文修饰关系助词"的"，符合学术标题的简洁性要求
3. "Language Model Training"采用直译"语言模型训练"，保留专业术语的准确性
4. 整体采用名词短语结构，与原文语法结构保持一致，同时符合中文标题表达习惯
5. 未添加冗余动词，保持学术标题的凝练特征） | Yalun Dai | [PDF](http://arxiv.org/pdf/2506.21545v1) | 数据是语言模型（LM）训练的基础要素。近期研究聚焦于数据效率领域，旨在通过选择最小或最优训练数据子集来实现性能最大化，其中数据过滤、采样与选择技术发挥着关键作用。作为补充，我们提出"数据效能"概念，强调通过优化训练数据组织方式来提升模型性能，该领域目前研究相对不足。本研究提出通用范式DELT，将数据效能纳入语言模型训练考量，突显训练数据组织方式的重要性。DELT包含三大核心组件：数据评分、数据选择与数据排序。在数据评分方面，我们创新性地设计了可学习性-质量双维评分（LQS），从梯度一致性的角度综合评估每个数据样本的可学习性与质量；在数据排序环节，提出折叠排序法（FO）以解决模型遗忘与数据分布偏差等问题。系统化实验验证了数据效能在语言模型训练中的价值，主要发现包括：首先，在不增加数据规模与模型参数量的前提下，DELT各组件实例均能不同程度提升模型性能；其次，采用LQS评分与FO排序的组合方案能实现最显著的性能提升；最后，通过数据选择可实现数据效能与数据效率的协同优化。这些发现表明，数据效能是语言模型训练中极具潜力的基础研究方向。 |
| DeOcc-1-to-3：基于自监督多视角扩散的单图像三维去遮挡技术

（翻译说明：
1. 专业术语处理：
- "De-Occlusion"译为"去遮挡"，符合计算机视觉领域术语规范
- "Self-Supervised"译为"自监督"，保持机器学习领域的标准译法
- "Multi-View Diffusion"译为"多视角扩散"，准确传达多视角图像生成与扩散模型的技术内涵

2. 技术表述优化：
- 采用"三维"而非直译"3D"，更符合中文科技文献表述习惯
- "via"译为"基于"而非简单对应"通过"，突出技术方法的创新性
- 保留"DeOcc-1-to-3"原始编号，维持技术方案的标识性

3. 句式结构调整：
- 将英文后置修饰语转换为中文前置定语
- 使用破折号替代原标题中的冒号，更符合中文标题排版规范
- 保持学术文本的简洁性，避免冗余表述） | Yansong Qu | [PDF](http://arxiv.org/pdf/2506.21544v1) | Reconstructing 3D objects from a single image is a long-standing challenge,
especially under real-wo [翻译失败] |
| StruMamba3D：探索结构化Mamba架构在点云自监督表征学习中的应用

（翻译说明：
1. 专业术语处理："Structural Mamba"译为"结构化Mamba架构"，既保留"Mamba"这一专用模型名称，又通过"架构"明确其技术属性
2. 技术概念转换："self-supervised"采用计算机视觉领域通用译法"自监督"
3. 学科规范："point cloud representation learning"译为"点云表征学习"，符合三维视觉领域术语标准（注：大陆学界常用"表征"而非台湾地区惯用的"表徵"）
4. 结构优化：通过冒号分层呈现主副标题关系，保留原标题的学术论文命名风格
5. 动词处理："Exploring"译为"探索"准确传达研究性质，比"研究"更符合预印本论文的探索性特征） | Chuxin Wang | [PDF](http://arxiv.org/pdf/2506.21541v1) | 近期，基于Mamba架构的方法通过利用状态空间模型（SSM）高效的情境建模能力和线性复杂度，在点云表征学习领域展现出卓越性能。然而，这些方法仍存在两个制约SSM潜力发挥的关键问题：SSM处理过程中破坏三维点云的邻接关系，以及在下游任务输入长度增加时无法保持长序列记忆。为此，我们提出了一种自监督点云表征学习新范式StruMamba3D，其优势体现在：首先，我们设计了空间状态代理机制以保持点云间的空间依赖关系；其次，通过状态级更新策略增强SSM，并融合轻量级卷积促进空间状态交互，实现高效结构建模；第三，采用序列长度自适应策略降低预训练Mamba模型对输入长度的敏感性。在四项下游任务中的实验结果表明，本方法具有显著性能优势。特别地，在不使用投票策略的情况下，我们的方法在ModelNet40数据集上达到95.1%的准确率，在ScanObjectNN最具挑战性的数据划分上取得92.75%的准确率，均达到当前最优水平（SOTA）。 |
| WorldVLA：迈向自回归动作世界模型

（翻译说明：
1. 完整保留专业术语"WorldVLA"作为专有名词不翻译
2. "Autoregressive"译为技术领域标准译法"自回归"
3. "Action World Model"采用意译结合的方式处理为"动作世界模型"，既保留"World Model"作为AI领域术语的固定译法，又通过"动作"准确传达"Action"的特定含义
4. "Towards"译为"迈向"以体现研究的前沿性和发展性特征
5. 整体采用学术论文标题的简洁风格，符合中文科技文献命名规范） | Jun Cen | [PDF](http://arxiv.org/pdf/2506.21539v1) | We present WorldVLA, an autoregressive action world model that unifies action
and image understandin [翻译失败] |
