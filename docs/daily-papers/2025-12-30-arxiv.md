# arxiv 2025-12-30

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| Stream-DiffVSR：基于自回归扩散的低延迟可流式视频超分辨率技术 | Hau-Shiang Shiu | [PDF](https://arxiv.org/pdf/2512.23709v1) | 基于扩散模型的视频超分辨率方法虽能实现出色的感知质量，但由于依赖未来帧和昂贵的多步去噪过程，在延迟敏感场景中仍不实用。我们提出Stream-DiffVSR——一种因果条件扩散框架，专为高效在线视频超分辨率设计。该方法严格基于历史帧进行处理，融合了四项核心技术：采用四步蒸馏去噪器实现快速推理；通过自回归时序引导模块在潜在去噪过程中注入运动对齐线索；配备轻量级时序感知解码器与时序处理模块以增强细节和时序连贯性。在RTX4090 GPU上，Stream-DiffVSR处理720p帧仅需0.328秒，性能显著超越现有扩散模型方法。与当前在线SOTA方法TMP相比，在提升感知质量（LPIPS指标优化0.095）的同时，将延迟降低超过130倍。该方法实现了扩散模型视频超分辨率领域的最低延迟记录，将初始延迟从4600秒以上缩短至0.328秒，成为首个适用于低延迟在线部署的扩散模型超分辨率方案。项目主页：https://jamichss.github.io/stream-diffvsr-project-page/ |
| 利用评分标准奖励机制训练人工智能协同科学家 | Shashwat Goel | [PDF](https://arxiv.org/pdf/2512.23707v1) | AI协研科学家正逐渐成为协助人类研究者实现科研目标的重要工具。这类AI协研系统的核心能力在于：在给定研究目标与约束条件后，能够自主生成完整的研究方案。这些方案既可为研究者提供头脑风暴的素材，也可经进一步优化后直接投入实践。然而，当前语言模型在生成完全符合约束条件与隐性要求的研究方案方面仍面临挑战。

本研究探索如何利用海量现有科研文献训练语言模型，以生成更优质的研究方案。我们通过跨领域论文自动提取研究目标及目标特异性评估标准，构建了可扩展的多样化训练语料库。随后采用基于自我评分的强化学习方法，训练研究方案生成模型：训练过程中由初始策略的冻结副本担任评分器，评估标准形成的生成-验证差异使模型能在无需人工监督的情况下持续优化。

为验证该方法，我们组织专家对机器学习领域的研究目标进行了长达225小时的人工评估。结果显示：针对70%的研究目标，专家更青睐经微调的Qwen3-30B-A3B模型生成的方案；84%的自动提取目标特异性评估标准获得专家认可。为检验泛化能力，我们将该方法扩展至医学论文及arXiv预印本的研究目标，并采用前沿模型陪审团进行评估。微调后的模型实现了12-22%的相对性能提升，展现出显著的跨领域泛化能力——即使在医学研究这类难以获得执行反馈的领域同样有效。

这些发现共同证明，这种可扩展的自动化训练方法具有提升通用AI协研科学家能力的潜力，标志着该领域向前迈出了重要一步。 |
| 扩散模型洞悉透明度：利用视频扩散模型实现透明物体的深度与法线估计 | Shaocong Xu | [PDF](https://arxiv.org/pdf/2512.23705v1) | 透明物体对于感知系统而言一直以难以处理而著称：折射、反射和透射现象破坏了立体视觉、飞行时间法以及纯判别式单目深度估计的基本假设，导致深度估计出现空洞和时间上的不稳定。我们的核心发现是：现代视频扩散模型已经能够合成逼真的透明现象，这表明它们已内化了光学规律。为此，我们构建了TransPhy3D——一个包含透明/反射场景的合成视频数据集：通过Blender/Cycles渲染生成的11,000个序列。场景由精心筛选的类别丰富的静态资源与形状丰富的程序化资源组合而成，并搭配玻璃/塑料/金属材质。我们采用基于物理的光线追踪和OptiX降噪技术，同步渲染RGB图像、深度图与法线图。

基于大型视频扩散模型，我们通过轻量级LoRA适配器学习从视频到深度（及法线）的转换器。训练过程中，我们在DiT主干网络中拼接RGB与（含噪声的）深度潜在特征，并在TransPhy3D及现有逐帧合成数据集上进行协同训练，从而实现对任意长度输入视频的时间一致性预测。最终得到的模型DKT，在涉及透明物体的真实与合成视频基准测试中实现了零样本状态最优性能：包括ClearPose、DREDS（已知类别/新类别）以及TransPhy3D测试集。相较于强大的图像/视频基线方法，DKT在精度和时间一致性上均有提升，其法线估计变体在ClearPose上取得了最佳视频法线估计结果。紧凑的13亿参数版本运行速度约为每帧0.17秒。

将DKT集成到抓取系统中，其深度估计显著提升了在半透明、反射和漫反射表面上的抓取成功率，优于现有估计器。这些成果共同印证了一个更广泛的论断："扩散模型理解透明度"。生成式视频先验可以被高效、无标签地转化为鲁棒且时间一致性的感知能力，为应对现实世界中具有挑战性的操控任务提供了新途径。 |
| 在多轮对话中引导行为 | Jing Huang | [PDF](https://arxiv.org/pdf/2512.23701v1) | 在对话环境中识别大型语言模型（LLM）的特定且通常复杂的行为，对其评估至关重要。近期研究提出了新颖技术，旨在寻找能够诱导目标模型产生特定行为的自然语言提示，但这些研究主要集中于单轮对话场景。本文聚焦于多轮对话背景下的行为诱导研究。我们首先提出一个分析框架，将现有方法根据其与目标模型的交互方式分为三类：仅依赖先验知识的方法、基于离线交互的方法，以及通过在线交互学习的方法。随后，我们提出在线方法的广义多轮对话形式化框架，统一了单轮与多轮行为诱导的研究范式。我们通过自动生成多轮测试用例对三类方法进行全面评估，并通过分析查询预算（即与目标模型的交互次数）与成功率（即成功诱导行为的输入发现率）之间的权衡关系，深入探究这些方法的效率。研究发现，在三个测试任务中，现有多轮对话基准采用的静态方法仅能发现极少甚至无法发现失效案例，而在线方法仅需数千次查询即可实现平均45%/19%/77%的成功率。本研究不仅揭示了行为诱导方法在多轮对话评估中的创新应用价值，更强调了学术界向动态基准测试体系转型的必要性。 |
| 离线强化学习中V学习的贝尔曼校准 | Lars van der Laan | [PDF](https://arxiv.org/pdf/2512.23694v1) | 我们提出迭代贝尔曼校准，这是一种简单、模型无关且后处理的方法，用于在无限时域马尔可夫决策过程中校准离策略价值预测。贝尔曼校准要求具有相似预测长期回报的状态，在目标策略下表现出与贝尔曼方程一致的单步回报。我们通过将拟合的贝尔曼目标重复回归到模型的预测上，将经典的直方图校准和等渗校准方法适配到动态、反事实的设置中，并使用双重稳健伪结果来处理离策略数据。这产生了一种一维拟合价值迭代方案，可应用于任何价值估计器。我们的分析在弱假设下为校准和预测提供了有限样本保证，并且关键的是，无需贝尔曼完备性或可实现性假设。 |
| 基于文本细粒度人工反馈对大型语言模型进行微调 | Sky CH-Wang | [PDF](https://arxiv.org/pdf/2512.23693v1) | 我们提出了一种基于反馈驱动改进链的偏好监督微调方法及相应数据集。给定模型生成的响应，标注者通过标记"喜欢"与"不喜欢"的文本片段并提供具体评价依据，从而提供细粒度反馈。基础模型随后根据反馈从左至右重写被标注为不喜欢的片段，形成渐进式改进序列。我们通过链式结构中每个相邻步骤构建直接对齐的偏好配对，使模型能够从局部化、目标明确的编辑中学习。实验表明，该方法在性能上超越了基于标准A/B偏好排序或完整对比重写的直接对齐方法，证明这种结构化、基于修订的监督机制能实现更高效、更有效的偏好调优。 |
| PROFASR-BENCH：高风险专业语音场景下上下文条件化自动语音识别基准测试平台 | Deepak Babu Piskala | [PDF](https://arxiv.org/pdf/2512.23686v1) | 专业场景下的自动语音识别面临现有基准测试未能充分体现的挑战：密集领域术语、正式语体变体以及对关键实体错误的近零容忍度。我们推出ProfASR-Bench——一个面向金融、医疗、法律和技术等高风险应用场景的专业对话评估套件。每个示例均将自然语言提示（领域线索和/或说话者画像）与富含实体的目标话语配对，实现对语境条件化识别的受控测量。该语料库支持传统ASR指标，同时配备实体感知评分及按口音与性别划分的切片化报告机制。

通过使用Whisper（编码器-解码器ASR）和Qwen-Omni（音频语言模型）两大代表性模型家族，在无上下文、画像提示、领域+画像提示、理想提示及对抗提示五种对照条件下进行测试，我们发现稳定规律：即便采用理想提示，轻量级文本上下文对平均词错误率（WER）的改善微乎其微；对抗性提示亦无法稳定降低系统性能。我们将此现象定义为上下文利用差距：当前系统虽具备提示功能，却未能充分利用易得的辅助信息。

ProfASR-Bench提供标准化的上下文阶梯框架、包含置信区间的实体与切片感知报告系统，以及可复现的跨模型家族融合策略比较测试平台。

数据集：https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench  
代码库：https://github.com/prdeepakbabu/ProfASR-Bench |
| 基于大语言模型的学术评审中的多语言隐藏提示注入攻击 | Panagiotis Theocharopoulos | [PDF](https://arxiv.org/pdf/2512.23684v1) | 大型语言模型（LLM）正越来越多地被考虑应用于高影响力工作流程，包括学术同行评审。然而，LLM容易受到文档级隐藏提示注入攻击的影响。在本研究中，我们构建了一个包含约500篇被ICML收录的真实学术论文的数据集，并评估了在这些文档中嵌入隐藏对抗性提示的效果。每篇论文均被注入了四种不同语言但语义相同的指令，并使用LLM进行评审。研究发现，英语、日语和中文的提示注入会导致评审分数及录用/拒绝决定发生显著变化，而阿拉伯语注入则几乎不产生影响。这些结果凸显了基于LLM的评审系统对文档级提示注入的脆弱性，并揭示了不同语言间脆弱性的显著差异。 |
| 网络世界模型 | Jichen Feng | [PDF](https://arxiv.org/pdf/2512.23676v1) | 语言智能体日益需要在能够行动、记忆和学习的持久化世界中运行。现有方法呈现两极分化：传统网络框架通过数据库支持提供可靠但固定的上下文环境，而完全生成式世界模型虽追求无限环境却以牺牲可控性与工程实践性为代价。本研究提出网络世界模型（WWM），在两者间建立平衡——通过常规网络代码实现世界状态与"物理规则"以确保逻辑一致性，同时依托结构化潜在状态，由大语言模型生成上下文、叙事框架与高层决策。我们基于真实网络技术栈构建了系列WWM系统，包括：基于真实地理的无限旅行图景、虚构星系探索系统、网络级百科全书与叙事世界，以及模拟与游戏化环境。通过跨系统实践，我们总结出WWM的核心设计原则：分离代码定义规则与模型驱动想象，将潜在状态表征为类型化网络接口，运用确定性生成实现无限但有结构的探索。研究表明，网络技术栈本身可作为世界模型的可扩展基础架构，为构建可控且开放的环境提供新范式。项目主页：https://github.com/Princeton-AI2-Lab/Web-World-Models。 |
| 面向长上下文的端到端测试时训练 | Arnuv Tandon | [PDF](https://arxiv.org/pdf/2512.23675v1) | 我们将长上下文语言建模视为持续学习问题而非架构设计问题。在此框架下，我们仅采用标准架构——配备滑动窗口注意力的Transformer模型。然而，该模型在测试阶段会通过给定上下文的下一个词元预测持续学习，将其读取的上下文信息压缩至权重参数中。此外，我们通过在训练阶段实施元学习，优化了模型在测试时学习的初始化状态。总体而言，我们的方法作为测试时训练的一种形式，在测试阶段（通过下一个词元预测）和训练阶段（通过元学习）均实现了端到端的处理流程，这与先前方法形成鲜明对比。

我们开展了大量实验，重点关注模型的扩展特性。具体而言，对于使用1640亿词元训练的30亿参数模型，我们的方法（TTT-E2E）在上下文长度扩展方面展现出与全注意力Transformer相同的特性，而其他模型（如Mamba 2和门控DeltaNet）则不具备这种特性。但类似于循环神经网络，TTT-E2E的推理延迟不受上下文长度影响，在处理128K上下文时比全注意力机制快2.7倍。相关代码已开源发布。 |
