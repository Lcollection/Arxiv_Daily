# arxiv 2025-10-18

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 耦合扩散采样实现免训练的多视角图像编辑 | Hadi Alzayer | [PDF](http://arxiv.org/pdf/2510.14981v1) | 我们提出一种推理时扩散采样方法，利用预训练的二维图像编辑模型实现多视角一致性图像编辑。这类模型能够独立为三维场景或物体的多视角图像集合生成高质量单帧编辑效果，但无法保持跨视角一致性。现有方案通常通过对显式三维表示进行优化来解决该问题，但存在优化流程冗长且在稀疏视角设置下不稳定的缺陷。我们通过约束生成的二维图像序列遵循预训练多视角图像分布，提出了一种隐式三维正则化方法。该方法通过耦合扩散采样实现——这是一种简单的扩散采样技术，可同时从多视角图像分布和二维编辑图像分布中采样两条轨迹，并利用耦合项强制生成图像间的多视角一致性。我们在三个不同的多视角图像编辑任务上验证了该框架的有效性与普适性，证明了其可适配多种模型架构的适用性，并凸显了其作为多视角一致性编辑通用解决方案的潜力。 |
| 从像素到词汇——迈向规模化原生视觉语言基元 | Haiwen Diao | [PDF](http://arxiv.org/pdf/2510.14979v1) | 原生视觉语言模型（VLMs）的体系已逐渐成为传统模块化VLMs的有力竞争者，这一发展由不断演进的模型架构与训练范式所推动。然而，仍有两大悬而未决的问题阻碍其广泛探索与推广：（一）原生VLMs与模块化模型的根本差异何在？这些限制因素能在多大程度上被突破？（二）如何降低原生VLMs的研究门槛，实现技术民主化，从而加速该领域发展？本文旨在厘清这些挑战，并提出构建原生VLMs的指导原则。具体而言，优质的原生VLM基础架构应满足：（i）在共享语义空间中实现像素与文本表征的高效对齐；（ii）无缝融合传统独立视觉与语言模块的优势；（iii）内在地具备支持统一视觉语言编码、对齐与推理的跨模态特性。基于此，我们推出NEO——一个从第一性原理构建的全新原生VLM系列。该模型在多样现实场景中可与顶尖模块化模型抗衡，仅需3.9亿图文样本即可从零高效习得视觉感知能力，并通过我们精心设计的基础架构缓解稠密单体模型内部的视觉-语言冲突。我们将NEO定位为可扩展强大多模态模型的基石，配套提供丰富的可复用组件库，以构建高性价比、易扩展的技术生态。代码与模型已开源：https://github.com/EvolvingLMMs-Lab/NEO。 |
| 组合式机器的能动性设计 | Wenqian Zhang | [PDF](http://arxiv.org/pdf/2510.14980v1) | 复杂机器的设计既是人类智慧的标志，也是工程实践的基石。随着大语言模型（LLMs）的最新进展，我们提出疑问：它们是否也能学会创造？我们通过组合式机器设计这一视角来探讨该问题——该任务要求通过标准化组件组装机器，使其在模拟物理环境中满足运动或操控等功能需求。为支持这项研究，我们推出了BesiegeField测试平台。该平台基于机器建造游戏《Besiege》构建，支持基于零部件的建造、物理模拟和奖励驱动评估。通过BesiegeField，我们对具备智能体工作流程的尖端大语言模型进行基准测试，识别出成功所需的关键能力，包括空间推理、策略性组装和指令遵循。鉴于当前开源模型存在不足，我们探索了强化学习（RL）作为改进路径：通过构建冷启动数据集、开展RL微调实验，揭示了语言、机器设计与物理推理交叉领域面临的开放性挑战。 |
| 训练无需图像编辑对的图像编辑模型 | Nupur Kumari | [PDF](http://arxiv.org/pdf/2510.14978v1) | 近期图像编辑模型在遵循自然语言编辑指令方面取得了显著成果，但这些成果依赖于使用大规模输入-目标配对数据集进行监督微调。这构成了关键瓶颈，因为此类自然生成的配对数据难以大规模整理。现有解决方案通过利用预训练模型的零样本能力生成合成训练数据，但这种方法会将预训练模型的伪影传递并放大至最终训练模型。本研究提出了一种全新的训练范式，完全摆脱对配对数据的依赖。该方法通过训练过程中展开多步扩散模型，并利用视觉语言模型（VLM）的反馈信号直接优化模型参数。针对每个输入图像和编辑指令，VLM会评估编辑结果是否遵循指令并保留未修改内容，从而为端到端优化提供直接梯度。为确保视觉保真度，我们引入分布匹配损失（DMD），将生成图像约束在预训练模型学习到的图像流形内。我们在标准基准测试上评估了该方法，并进行了详尽的消融实验。在无需任何配对数据的情况下，本方法在少步生成设置下的表现与基于大量监督配对数据训练的各类图像编辑扩散模型相当。当使用相同VLM作为奖励模型时，我们的方法也超越了基于强化学习的技术（如Flow-GRPO）。 |
| Ponimator：展开交互姿态以实现多样化人-人互动动画

（注：该翻译在保持专业术语准确性的基础上，采用"展开交互姿态"对应"unfolding interactive pose"的动态概念，"多样化"对应"versatile"的适配性内涵，通过"人-人互动动画"准确传达"human-human interaction animation"的学术范畴，整体符合计算机图形学与动画领域的专业表达规范。） | Shaowei Liu | [PDF](http://arxiv.org/pdf/2510.14976v1) | 近距离人际交互姿态能够传递丰富的互动动态情境信息。基于此类姿态，人类可凭借对行为模式的强先验认知，直观推断互动情境并预测可能的过往与未来动态。受此启发，我们提出Ponimator框架——一种以近距离交互姿态为锚点的通用交互动画生成方案。我们的训练数据源自动作捕捉交互数据集中的紧密接触双人姿态及其时序上下文。通过运用交互姿态先验，Ponimator采用两个条件扩散模型：(1) 姿态动画器利用时序先验从交互姿态生成动态运动序列；(2) 姿态生成器运用空间先验，在交互姿态缺失时根据单帧姿态、文本描述或二者组合合成交互姿态。该框架集成支持基于图像的交互动画、反应动画及文本到交互合成等多重任务，实现将高质量动作捕捉数据中的交互知识向开放场景迁移。跨数据集与多应用的实证研究验证了姿态先验的普适性，以及我们框架的有效性与鲁棒性。 |
| Terra：基于点潜在空间的可探索原生三维世界模型

（注：Terra作为专有名词保留原文，通过冒号后的解释性翻译完整呈现技术特性："Explorable"译为"可探索"强调交互性，"Native 3D World Model"译为"原生三维世界模型"保持技术准确性，"Point Latents"采用计算机图形学常用译法"点潜在空间"） | Yuanhui Huang | [PDF](http://arxiv.org/pdf/2510.14977v1) | 世界模型因能对现实世界进行综合建模而日益受到关注。然而，现有方法大多仍以像素对齐表示作为世界演化的基础，忽视了物理世界固有的三维特性。这种局限可能削弱世界模型的三维一致性并降低建模效率。本文提出Terra——一个原生三维世界模型，通过内蕴三维潜在空间实现可探索环境的表征与生成。具体而言，我们设计了一种创新的点云-高斯变分自编码器（P2G-VAE），可将三维输入编码为潜在点表征，继而解码为三维高斯基元以联合建模几何结构与外观属性。随后提出稀疏点流匹配网络（SPFlow），通过同步去噪潜在点的空间位置与特征来实现潜在点表征的生成。Terra凭借原生三维表征与架构确保精确的多视角一致性，仅需单次生成过程即可支持任意视点的灵活渲染。此外，该模型通过在点潜在空间中进行渐进式生成，实现了可探索的世界建模。我们在ScanNet v2的复杂室内场景数据集上开展大量实验，结果表明Terra在保持高三维一致性的前提下，于重建与生成任务中均达到最先进性能。 |
| 与任何人：迈向可控且身份一致性的图像生成

（解析：该标题翻译需兼顾学术严谨性与中文表达习惯。核心术语处理如下：
1. "WithAnyone"译为"与任何人"，保留原短语的开放性社交语义
2. "Controllable"采用计算机视觉领域标准译法"可控"
3. "ID Consistent"译为"身份一致性"，符合数字身份识别技术的专业表述
4. 动态介词"Towards"译为"迈向"，准确传达研究的前瞻性特征
5. 整体采用主副标题结构，破折号衔接符合中文论文标题规范） | Hengyuan Xu | [PDF](http://arxiv.org/pdf/2510.14975v1) | 身份一致性生成已成为文本到图像研究的重要方向，近期模型在生成与参考身份对齐的图像方面取得显著进展。然而，由于缺乏包含同一人物多张图像的大规模配对数据集，现有方法大多采用基于重建的训练范式。这种训练方式容易引发我们称之为"复制-粘贴"的失效模式——模型直接复制参考人脸，而非在姿态、表情或光照等自然变化中保持身份一致性。这种过度相似性会削弱生成结果的可控性，限制模型的表达能力。为解决这些问题，我们（1）构建了面向多人物场景的大规模配对数据集MultiID-2M，为每个身份提供多样化参考；（2）提出量化评估基准，同时衡量复制-粘贴伪影及身份保真度与多样性的平衡；（3）设计具有对比身份损失的新训练范式，利用配对数据实现保真度与多样性的均衡。这些创新最终形成基于扩散模型的WithAnyone系统，在保持高身份相似度的同时有效缓解复制-粘贴问题。大量定性与定量实验表明，WithAnyone显著减少复制-粘贴伪影，提升姿态和表情的可控性，并保持优异的感知质量。用户研究进一步验证本方法在实现高身份保真度的同时，能够完成富有表现力的可控生成。 |
| pi-Flow：基于策略的模仿蒸馏少步生成方法

（解析说明：
1. "Policy-Based"译为"基于策略的"，符合强化学习领域术语规范
2. "Few-Step Generation"采用"少步生成"的译法，既保持原意又符合中文表达习惯
3. "Imitation Distillation"译为"模仿蒸馏"，准确对应模仿学习与知识蒸馏的技术概念
4. 整体采用"方法"作为隐性后缀，符合中文论文标题命名惯例
5. 保持原标题的技术层次递进关系：方法论（pi-Flow）→ 实现机制（基于策略）→ 核心特征（少步）→ 技术路径（模仿蒸馏）） | Hansheng Chen | [PDF](http://arxiv.org/pdf/2510.14974v1) | 基于少步扩散或流的生成模型通常会将预测速度的教师模型蒸馏为能够预测去噪数据捷径的学生模型。这种形式不匹配导致了复杂的蒸馏流程，往往面临质量与多样性的权衡问题。为此，我们提出基于策略的流模型（$\pi$-Flow）。该模型通过修改学生流模型的输出层，使其在单个时间步预测无需网络计算的操作策略。该策略可在后续子步长中生成动态流速度，其计算开销可忽略不计，从而无需额外网络评估即可在这些子步长上实现快速精确的常微分方程积分。

为使策略的常微分方程轨迹与教师模型对齐，我们提出了一种新颖的模仿蒸馏方法：通过标准的$\ell_2$流匹配损失，使策略生成的速度在自身轨迹上与教师模型保持一致。通过直接模仿教师模型的行为，$\pi$-Flow实现了稳定可扩展的训练，并规避了质量-多样性权衡问题。在ImageNet 256$^2$数据集上，其单步评估FID指标达到2.85，优于同架构DiT的MeanFlow模型。在FLUX.1-12B和Qwen-Image-20B模型上的4步评估实验中，$\pi$-Flow在保持教师级生成质量的同时，相比现有最优少步方法实现了显著更优的多样性表现。 |
| 注意力机制是扩散大语言模型中KV缓存的全部所需 | Quan Nguyen-Tri | [PDF](http://arxiv.org/pdf/2510.14973v1) | This work studies how to adaptively recompute key-value (KV) caches for
diffusion large language mod [翻译失败] |
| TokDrift：当大语言模型以子词表达而代码以语法运行 | Yinxi Li | [PDF](http://arxiv.org/pdf/2510.14972v1) | 用于代码处理的大型语言模型依赖子词分词器（例如字节对编码），这类分词器通过混合自然语言文本与程序语言代码训练获得，但其运作机制基于统计学规律而非语法规则。这导致语义完全相同的代码片段会因表面特征（如空格差异或标识符命名）而产生不同的分词结果。为量化这种错位带来的影响，我们提出TokDrift框架，该框架通过应用保持语义不变的改写规则，生成仅存在分词差异的代码变体。在涵盖参数规模超300亿的九款代码大模型中实验发现，即使微小的格式改动也会引发模型行为的显著偏移。分层分析表明，该问题源于早期嵌入层中子词切分未能准确捕捉语法标记边界。本研究揭示了对齐失准的分词机制是影响代码理解与生成可靠性的潜在障碍，指出未来代码大模型需要发展语法感知的分词方案。 |
