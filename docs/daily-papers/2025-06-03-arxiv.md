# arxiv 2025-06-03

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 《开放验证码世界：基于网络的多模态大语言模型智能体测试与基准评估综合平台》

翻译说明：
1. "Open CaptchaWorld" 采用音意结合译法，保留"开放"的直译，将"CaptchaWorld"译为"验证码世界"既保持专业术语准确性又体现平台特性
2. "Comprehensive"译为"综合"准确传达平台功能的完备性
3. "Web-based"译为"基于网络"符合计算机领域术语规范
4. "Testing and Benchmarking"采用"测试与基准评估"的并列结构，其中"Benchmarking"译为"基准评估"是学术界的标准译法
5. "Multimodal LLM Agents"译为"多模态大语言模型智能体"：
   - "Multimodal"译为"多模态"是人工智能领域的固定术语
   - "LLM"采用全称翻译"大语言模型"（Large Language Model）
   - "Agents"译为"智能体"是人工智能领域的专业译法

该翻译严格遵循学术翻译的准确性、专业性和一致性原则，所有术语均采用计算机科学和人工智能领域的标准中文表述。 | Yaxin Luo | [PDF](http://arxiv.org/pdf/2505.24878v1) | 验证码（CAPTCHA）一直是网络智能体在实际应用中的关键瓶颈，常常阻碍其完成端到端的自动化任务。尽管现代多模态大语言模型（MLLM）智能体在静态感知任务中展现出卓越性能，但其处理验证码这类需要交互式多步推理挑战的能力尚未得到充分验证。为填补这一空白，我们推出Open CaptchaWorld——首个基于网页的基准测试平台，专门通过多样化动态验证题来评估MLLM智能体的视觉推理与交互能力。该基准涵盖20类现代验证码变体共计225道题目，并采用我们提出的新评估指标"验证码推理深度"进行标注，该指标量化了解决每道题目所需的认知与操作步骤数。实验结果表明：人类测试者始终维持接近完美的准确率（93.3%），而当前最先进的MLLM智能体（以Browser-Use Openai-o3为最佳）成功率最高仅达40.0%，远低于人类水平。这凸显Open CaptchaWorld作为诊断现有多模态智能体局限性的重要基准，将为开发更强大的多模态推理系统提供指引。代码与数据集详见此https链接。 |
| AdaHuman：基于组合式多视角扩散的可动画精细三维人体生成

（翻译说明：
1. 保留技术术语"Animatable"专业译法"可动画"，指模型具备动画控制能力
2. "Detailed 3D Human Generation"采用计算机图形学领域标准译法"精细三维人体生成"
3. "Compositional Multiview Diffusion"译为"组合式多视角扩散"，其中：
   - "Compositional"体现模块化组合技术特征
   - "Multiview"采用计算机视觉领域通用译法"多视角"
4. 整体句式结构调整为中文技术论文标题常用的"技术手段+核心成果"结构
5. 冒号使用符合中文标题规范，与英文原标题保持排版一致性） | Yangyi Huang | [PDF](http://arxiv.org/pdf/2505.24877v1) | 现有图像到3D虚拟人生成方法难以创建适用于实际应用的高细节、可动画化虚拟人。我们提出AdaHuman创新框架，能够从单张真实场景图像生成高保真可动画3D虚拟人。该框架包含两项核心技术突破：（1）姿态条件式3D关节扩散模型，可在每个扩散步骤同步生成任意姿态下一致的多视角图像及对应3D高斯溅射（3DGS）重建；（2）组合式3DGS优化模块，通过图像到图像精细化增强局部身体部位细节，并采用创新的裁剪感知相机光线图实现无缝整合，最终生成协调统一的高精度3D虚拟人。该框架能生成具有最小自遮挡的高真实度标准A姿态虚拟人，支持任意输入动作的骨骼绑定与动画驱动。在公开基准测试和真实场景图像上的大量实验表明，AdaHuman在虚拟人重建与姿态重置任务上显著优于现有最优方法。相关代码与模型将开源供研究使用。 |
| Agent-X：以视觉为中心的智能体任务中深度多模态推理能力评估

（翻译说明：
1. 保留原项目名称"Agent-X"作为专有名词不译，符合学术文献命名惯例
2. "Vision-Centric"译为"以视觉为中心的"，准确传达视觉模态在任务中的核心地位
3. "Agentic Tasks"译为"智能体任务"，采用人工智能领域对"Agent"的标准译法
4. "Deep Multimodal Reasoning"译为"深度多模态推理"，完整保留"深度"的技术含义和"多模态"的专业表述
5. 整体采用"副标题"结构，用冒号分隔主副标题，符合中文论文标题规范
6. 添加"能力"二字使中文表达更完整，同时不改变原意） | Tajamul Ashraf | [PDF](http://arxiv.org/pdf/2505.24876v1) | Deep reasoning is fundamental for solving complex tasks, especially in
vision-centric scenarios that [翻译失败] |
| ReasonGen-R1：通过监督微调（SFT）与强化学习（RL）实现自回归图像生成模型的思维链（CoT）技术

（翻译说明：
1. 专业术语处理：
- "Autoregressive Image generation models"译为"自回归图像生成模型"，保留机器学习领域术语规范
- "SFT"采用中文全称"监督微调"并保留英文缩写，符合学术文献惯例
- "RL"译为"强化学习"，采用人工智能领域通用译法
- "CoT"译为"思维链"，遵循2022年后国内学界对"Chain-of-Thought"的标准译法

2. 技术内涵传达：
- 通过增补"技术"二字明确方法论属性
- 使用"实现"准确表达"through"的技术路径含义
- 保持"自回归"这一核心模型特性的专业表述

3. 结构规范：
- 主副标题结构完整保留
- 专业缩写首次出现时标注全称
- 术语翻译与arXiv最新论文中文版本保持一致） | Yu Zhang | [PDF](http://arxiv.org/pdf/2505.24875v1) | Although chain-of-thought reasoning and reinforcement learning (RL) have
driven breakthroughs in NLP [翻译失败] |
| 通向可泛化神经符号学习的道路应由基础模型铺就

（翻译说明：
1. 专业术语处理：
- "Generalizable"译为"可泛化"，符合机器学习领域术语规范
- "Neuro-Symbolic Learning"保留专业表述译为"神经符号学习"
- "Foundation Models"采用学界共识译法"基础模型"

2. 句式结构：
- 英文被动语态转换为中文主动表达"应由...铺就"
- 隐喻修辞"Paved with"忠实再现为"铺就"，保留原文意象

3. 学术风格：
- 使用"应"体现学术建议语气
- 保持标题的简洁性与学术严谨性

4. 创新点保留：
- "Generalizable"前置强调，突出研究重点
- 神经符号学习与基础模型的组合关系通过"由...铺就"准确传达） | Adam Stein | [PDF](http://arxiv.org/pdf/2505.24874v1) | 为应对复杂推理任务中神经网络训练面临的挑战，同时兼顾可解释性、可靠性和效率优势，神经符号学习应运而生。传统神经符号学习方法通过结合符号程序来训练神经模型，但其显著局限性导致仅能处理简单问题。另一方面，纯神经基础模型如今通过提示而非训练即可达到最先进性能，但其可靠性存疑且缺乏可解释性。通过为基础模型补充符号程序（我们称之为"神经符号提示"），为复杂推理任务提供了新的解决路径。这引发了一个核心问题：在基础模型时代，神经符号学习中的专项模型训练究竟应扮演何种角色？为探究该问题，我们揭示了传统神经符号学习在算力、数据和程序三个维度导致泛化问题的缺陷。本立场论文论证指出：基础模型能够实现可泛化的神经符号解决方案，既可达成神经符号学习的原始目标，又能规避从零训练带来的弊端。 |
| MiniMax-Remover：抑制不良噪声助力视频目标移除

（翻译说明：
1. 采用"抑制"对应"Taming"，既保留驯服的本义，又体现技术场景中对噪声的控制
2. "不良噪声"比直译"坏噪声"更符合中文工程术语习惯
3 "助力"比"帮助"更能体现技术方案的赋能特性
4. 保留算法名称MiniMax-Remover的原始形态符合学术惯例
5. 通过冒号分隔主副标题，遵循中文论文标题格式规范
6. "视频目标移除"准确对应Video Object Removal的专业概念） | Bojia Zi | [PDF](http://arxiv.org/pdf/2505.24873v1) | Recent advances in video diffusion models have driven rapid progress in video
editing techniques. Ho [翻译失败] |
| 代理思考者（ProxyThinker）：基于小型视觉推理器的测试时引导

翻译说明：
1. "ProxyThinker"采用音意结合的译法，保留"Proxy"（代理）的核心含义，同时通过"思考者"体现"Thinker"的智能特性
2. "Test-Time Guidance"译为"测试时引导"，准确传达模型在推理阶段（而非训练阶段）进行指导的技术特征
3. "Small Visual Reasoners"译为"小型视觉推理器"，其中：
   - "Small"译为"小型"而非字面的"小"，更符合中文技术文献表述习惯
   - "Visual Reasoners"译为"视觉推理器"准确表达其作为视觉领域专用推理组件的技术定位
4. 整体采用学术论文标题的简洁风格，通过冒号分隔主副标题，符合中文科技文献标题规范
5. 保留专业术语的一致性，与计算机视觉领域常用译法保持统一 | Zilin Xiao | [PDF](http://arxiv.org/pdf/2505.24872v1) | Recent advancements in reinforcement learning with verifiable rewards have
pushed the boundaries of  [翻译失败] |
| MoDoMoDo：面向多模态大语言模型强化学习的多领域数据混合方法  

（翻译说明：  
1. "Multi-Domain Data Mixtures" 译为"多领域数据混合"，其中：  
   - "Multi-Domain"采用计算机领域通用译法"多领域"  
   - "Mixtures"译为"混合"而非"混合物"，更符合机器学习数据处理的语境  
2. "Multimodal LLM" 保留专业术语一致性，译为"多模态大语言模型"  
3. "Reinforcement Learning" 采用人工智能领域标准译名"强化学习"  
4. 标题结构处理为"方法名称+技术说明"的中文学术标题惯用格式  
5. 冒号后增加"面向"字以明确技术方案的适用对象，符合中文技术文献表述规范） | Yiqing Liang | [PDF](http://arxiv.org/pdf/2505.24871v1) | 可验证奖励强化学习（RLVR）近期已成为大语言模型（LLM）后训练的重要范式，在具有结构化可验证答案的任务中实现了最先进的性能。将RLVR应用于多模态大语言模型（MLLM）虽蕴含重大机遇，但由于视觉语言任务具有更广泛的异构特性——需要精细的视觉、逻辑与空间推理能力——其应用面临显著复杂性。基于多数据集开展RLVR训练虽可能提升MLLM性能，但不同数据集交互产生的目标冲突会带来优化挑战，这凸显了构建最优数据集混合策略以增强泛化与推理能力的必要性。本文提出系统化的多模态LLM-RLVR后训练框架，包含严格的数据混合问题形式化定义与基准实现：首先（1）通过构建包含多样化可验证视觉语言问题的数据集，开发支持多领域在线RL学习与差异化可验证奖励的多模态RLVR框架；其次（2）提出能通过数据混合分布预测RL微调效果、进而优化最佳混合比例的学习策略。全面实验表明，结合混合预测策略的多领域RLVR训练可显著提升MLLM的通用推理能力：相比均匀数据混合后训练模型，我们的最优混合策略使分布外基准准确率平均提升5.24%；相较微调前基线模型，累计提升幅度达20.74%。 |
| GenSpace：空间感知图像生成基准测试

翻译说明：
1. "GenSpace"作为专有技术名词保留不译，符合学术术语翻译惯例
2. "Benchmarking"译为"基准测试"，准确体现其作为评估标准的含义
3. "Spatially-Aware"译为"空间感知"，精准传达对空间关系/位置感知的技术特征
4. 整体采用"名词+副标题"的学术标题结构，符合中文科技论文标题规范
5. 使用冒号替代原标题中的空格分隔，更符合中文标点使用习惯

该翻译在保持学术严谨性的同时，确保了技术概念的准确传递，且符合中文表达习惯。 | Zehan Wang | [PDF](http://arxiv.org/pdf/2505.24870v1) | 人类能够凭借直觉在三维空间中构图布景进行摄影创作。然而，当基于文本或图像提示生成画面时，先进的人工智能图像生成器是否具备同等的三维空间认知能力来进行场景规划？我们提出GenSpace——一个全新的基准测试与评估框架，用于系统评估当前图像生成模型的空间感知能力。研究发现，使用通用视觉语言模型（VLM）的标准评估方法往往难以捕捉细微的空间错误。为此，我们设计了一套专业化评估方案及度量标准：通过整合多个视觉基础模型重建三维场景几何结构，从而提供更精确且符合人类感知的空间保真度评价指标。实验结果表明，尽管AI模型能生成视觉吸引力强的图像并遵循一般性指令，但在物体位置、空间关系和尺寸比例等具体三维细节处理上仍存在明显缺陷。我们归纳出现有最先进图像生成模型在空间认知方面的三大核心局限：1）物体透视理解能力 2）自我中心-他者中心视角转换能力 3）度量尺度遵循能力，这些发现为提升图像生成的空间智能指明了改进方向。 |
| SiLVR：一种基于语言的简易视频推理框架

（翻译说明：
1. 保留首字母缩略词"SiLVR"作为专有名词不译，符合学术术语惯例
2. "Simple"译为"简易"而非简单，更符合技术框架的命名规范
3. "Language-based"采用"基于语言的"标准学术翻译
4. "Video Reasoning Framework"译为"视频推理框架"，其中：
   - "Reasoning"译为"推理"而非"论证"，符合计算机视觉领域术语
   - 补充量词"一种"使中文更规范
5. 整体采用"名词+解释性定语"的中文技术命名结构，保持学术严谨性） | Ce Zhang | [PDF](http://arxiv.org/pdf/2505.24869v1) | Recent advances in test-time optimization have led to remarkable reasoning
capabilities in Large Lan [翻译失败] |
