# arxiv 2025-12-01

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 视频推理强化：在多模态语言模型中实现一致且基于事实的推理 | Muhammad Maaz | [PDF](https://arxiv.org/pdf/2511.23478v1) | 对动态视觉内容进行推理仍然是多模态大语言模型面临的核心挑战。近期出现的思维模型虽能生成显式推理轨迹以提升可解释性，但其推理过程往往看似合理，实则存在逻辑不一致或视觉证据支撑薄弱的问题。我们通过两项诊断指标对这些问题进行界定与量化：思维答案一致性（TAC）用于衡量推理过程与答案的契合度，视频注意力分数（VAS）则用于评估推理过程对视觉线索与文本线索的依赖程度。通过对11个视频推理基准测试的分析发现，当前模型严重依赖语言先验而非视觉内容。为解决这一问题，我们提出一种强化学习方法，可同步提升时序精度与推理一致性。该方法将时间戳感知的监督微调与基于新型时序对齐奖励（TAR）的组相对策略优化（GRPO）相结合，通过双阶段后训练机制推动时序对齐且因果连贯的视频推理。最终构建的Video R2模型在多项基准测试中均实现了TAC、VAS与准确率的全面提升，证明时序对齐与推理一致性的改进能够带来更精准、更可信的视频理解。我们的代码、数据集及模型将全面开源。 |
| 视频操作链：通过操作链实现交互式视频推理 | Hanoona Rasheed | [PDF](https://arxiv.org/pdf/2511.23477v1) | 近期多模态大语言模型（MLLMs）在视频理解领域取得进展，但多数模型仍停留在“思考视频”阶段——即视频编码完成后，推理过程完全在文本域展开，将视觉输入视为静态背景。这种被动范式形成了语义瓶颈：模型无法回放视频、调整关注焦点或验证证据，导致在需要细粒度时空理解的任务中仅能进行浅层视觉推理。本研究提出交互式视频推理新范式，将视频转化为主动认知工作空间，使模型能够“伴随视频思考”。我们开发的Video CoM模型通过操作链（CoM）进行推理，执行迭代式视觉动作以收集和精炼证据。为支持该机制，我们构建了包含18K指令调优数据的Video CoM Instruct数据集，专门针对多步骤操作推理任务。除监督学习外，我们进一步通过强化学习优化操作策略，采用具备推理感知能力的组相对策略优化（GRPO）方法。与先前仅依赖稀疏答案奖励的研究不同，本方法引入步骤级推理奖励机制，引导模型进行基于证据且逻辑一致的推理。Video CoM在九项视频推理基准测试中表现优异，相较于当前最优模型平均性能提升3.6%，而训练数据仅需25K SFT样本和3K GRPO视频样本，远少于同类大规模模型所需数据量。消融实验表明，推理感知奖励机制能同步提升准确性与可解释性。代码已开源：https://github.com/mbzuai-oryx/Video-CoM |
| 实践出真知：通过多轮交互在大型语言模型中构建高效的世界模型推理 | Bao Shu | [PDF](https://arxiv.org/pdf/2511.23476v1) | 发展稳健的世界模型推理能力对于大型语言模型（LLM）智能体在复杂环境中进行规划与交互至关重要。尽管多轮交互能通过真实反馈提供对环境动态的优越理解，但现有方法往往强加僵化的推理流程，限制了模型的主动学习能力，最终阻碍高效的世界模型推理。为解决这些问题，我们探索通过高效交互与主动推理实现世界模型内化（WMAct）。该方法将模型从结构化推理中解放出来，使其能够通过实践直接塑造思维方式，并通过两项关键机制实现高效能的世界模型推理：（1）奖励重标定机制，根据行动效能调整结果奖励，以激励减少冗余并实现有目的的交互；（2）交互频率退火策略，逐步降低允许的最大交互轮次，迫使模型浓缩学习过程、内化环境动态，而非过度依赖环境线索。我们在推箱子、迷宫和出租车任务上的实验表明，WMAct能够实现高效的世界模型推理，仅需单轮交互即可解决以往需多轮交互的任务，并展现出对复杂环境的强迁移能力，在一系列推理基准测试中显著提升性能。 |
| AnyTalker：通过交互式精炼实现多人对话视频生成的可扩展性 | Zhizhou Zhong | [PDF](https://arxiv.org/pdf/2511.23475v1) | 近期，多人视频生成技术开始受到广泛关注。尽管已有初步研究探索了音频驱动的多人对话视频生成，但由于多样化多人数据采集成本高昂，以及难以实现多身份间连贯的交互驱动，这些方法仍面临诸多挑战。为解决这些问题，我们提出了AnyTalker——一个具备可扩展多流处理架构的多人视频生成框架。具体而言，我们通过一种新颖的身份感知注意力机制对扩散变换器的注意力模块进行扩展，该机制可迭代处理身份-音频对，从而实现可驱动身份数量的任意扩展。此外，训练多人生成模型需要海量多人数据。我们提出的训练流程仅依赖单人视频学习多人说话模式，并仅需少量真实多人视频片段即可优化交互表现。我们还构建了专用评估指标与数据集，用于衡量生成多人视频的自然度与交互性。大量实验表明，AnyTalker在唇部同步、视觉质量与自然交互性方面表现卓越，在数据成本与身份可扩展性之间实现了良好平衡。 |
| ThetaEvolve：开放问题上的测试时学习 | Yiping Wang | [PDF](https://arxiv.org/pdf/2511.23473v1) | 大规模语言模型（LLM）的最新进展推动了数学发现领域的突破，以AlphaEvolve系统为代表——该系统通过演化程序来改进开放问题的边界，但其采用闭源架构。然而，该系统依赖前沿LLM集成实现新边界，且作为纯推理系统无法内化演化策略。我们提出ThetaEvolve开源框架，通过简化和扩展AlphaEvolve，在测试阶段高效扩展上下文学习与强化学习（RL）规模，使模型能够持续从改进开放优化问题的经验中学习。ThetaEvolve具备以下特性：采用单一LLM架构、配备增强探索能力的大型程序数据库、支持高吞吐量的批量采样、引入抑制输出停滞的惰性惩罚机制，以及可选的奖励塑形功能以提供稳定训练信号等。ThetaEvolve是首个使小型开源模型（如DeepSeek-R1-0528-Qwen3-8B）能在AlphaEvolve提及的开放问题（圆堆积与首项自相关不等式）上取得最新最优边界的演化框架。此外，通过在两个模型和四项开放任务中的实验，我们发现测试阶段结合RL的ThetaEvolve持续超越纯推理基线模型，且模型确实掌握了演化能力——经RL训练的检查点在已训练目标任务及其他未见任务上均表现出更快的进展速度和更优的最终性能。代码已公开发布：https://github.com/ypwang61/ThetaEvolve |
| 视觉生成调优 | Jiahao Guo | [PDF](https://arxiv.org/pdf/2511.23469v1) | 大型视觉语言模型（VLMs）通过大规模预训练有效弥合了模态鸿沟，获得了与语言对齐的复杂视觉表征。然而，这些为多模态理解任务优化的表征是否蕴含视觉生成的内在潜力，目前仍未得到充分探索。本文提出视觉生成调优（VGT）这一创新范式，旨在激发任意视觉语言模型中潜在的视觉生成能力。通过对预训练充分的VLMs进行高效视觉生成调优，我们显著降低了对齐成本，并加速了连续空间中自回归建模的收敛速度（提速20倍）。具体而言，我们摒弃了为扩散变换器设计的纠缠式像素级变分自编码器，通过将预训练VLMs的语义编码器与像素解码器的潜在表征对齐，构建了VGT自编码器。在图像重建任务中，我们在28倍压缩比下实现了26.67 PSNR和0.50 rFID，性能超越专用变分自编码器；在视觉生成任务中，我们在自回归模型中取得了最先进的成果——GenEval得分0.77，DPG-Bench得分78.73。此外，所提出的VGT展现出显著的扩展潜力，能够灵活赋能任何为多模态理解训练的VLMs，使其具备视觉生成能力，这为探索下一代统一多模态基础模型开辟了新路径。模型与代码已开源：https://github.com/hustvl/VGT。 |
| 小世界：评估孤立环境中世界模型的动态理解能力 | Xinyi Li | [PDF](https://arxiv.org/pdf/2511.23465v1) | 当前世界模型缺乏统一且可控的系统性评估环境，难以判断其是否真正掌握了环境动态的底层规律。本研究针对这一开放性问题，提出了小型世界基准测试平台——该测试平台旨在通过独立且精确可控的动态环境评估世界模型能力，无需依赖人工设计的奖励信号。基于该基准，我们在完全可观测状态空间中对循环状态空间模型、Transformer、扩散模型及神经常微分方程等代表性架构进行了全面实验，考察了它们在六个不同领域中的表现。实验结果揭示了这些模型捕捉环境结构的有效性，以及其预测能力在长序列推演中的衰减规律，既凸显了当前建模范式的优势与局限，也为表征学习与动态建模的未来改进方向提供了重要启示。 |
| 进步的代价：算法效率与人工智能推理成本下降 | Hans Gundlach | [PDF](https://arxiv.org/pdf/2511.23455v1) | 近年来，语言模型在高级基准测试中取得了巨大进展，但这一进展很大程度上依赖于使用成本更高的模型。因此，基准测试可能扭曲了单位成本下实际能力发展的真实图景。为纠正这一问题，我们整合了Artificial Analysis与Epoch AI的数据，构建了迄今为止规模最大的当前及历史基准测试价格数据集。研究发现，在知识、推理、数学和软件工程等前沿模型的基准测试中，达到特定性能水平所需成本正以每年约5至10倍的速度显著下降。这种人工智能推理成本的降低源于经济因素、硬件效率提升以及算法效率改进的综合作用。通过单独分析开源模型以控制竞争效应，并剔除硬件价格下降的影响，我们估算出算法效率的年提升率约为3倍。最后，我们建议评估机构在衡量人工智能实际影响时，应将基准测试成本作为核心指标予以公布和考量。 |
| 面向类别级物体检测的以物体为中心的数据合成 | Vikhyat Agarwal | [PDF](https://arxiv.org/pdf/2511.23450v1) | 深度学习在目标检测领域已能可靠识别图像中的特定物体类别。然而，若要将模型的检测能力扩展至新物体类别，通常需要大量带标注的训练数据，这些数据的获取成本高昂且耗时，尤其对于现有数据集中代表性不足的长尾类别而言更是如此。本文提出以物体为中心的数据场景——当可用数据以物体中心形式（多视角图像或3D模型）存在且数量有限时，系统评估了四种不同数据合成方法在该场景下对新物体类别进行目标检测模型微调的性能。这些方法基于简单图像处理技术、三维渲染和图像扩散模型，利用物体中心数据合成具有不同上下文连贯性与复杂度的逼真杂乱图像。我们评估了这些方法如何帮助模型在真实数据中实现类别级泛化，并在此数据受限的实验场景中展现出显著的性能提升。 |
| 基于物理信息的神经网络在热物理性质反演中的应用 | Ali Waseem | [PDF](https://arxiv.org/pdf/2511.23449v1) | 逆热问题是指根据观测或已知的热扩散行为来估算材料的热物理性质。逆热问题具有广泛的应用，其中一个关键应用在于量化建筑立面改造如何降低热传递系数——这是建筑能效的关键决定因素。然而，利用现场采集的非侵入式数据解决逆热问题容易因环境变化或与理论假设条件的偏差而产生误差。因此，当前测量导热系数的方法要么具有侵入性，要么需要长时间观测，或者对环境和实验条件敏感。本文提出一种基于物理信息神经网络（PINN）的迭代框架，通过一组热成像图估算墙体导热系数k；该框架交替进行两个步骤：首先在固定k值下使用PINN估算正向热问题，然后通过比较热成像图与PINN预测的表面温度来优化k值，重复此过程直至估算的k值收敛。利用气象站采集的环境数据以及有限体积法软件模拟生成的数据，在墙体黎明时温度分布接近稳态的条件下，我们准确预测了不同环境条件和数据采集采样时间下的k值。尽管违反稳态假设会影响k值估算的准确性，但我们提出的框架最大平均绝对误差（MAE）仅为4.0851。我们的工作证明了基于PINN的方法能够在现实条件下可靠地现场估算材料特性，无需长时间的测量活动。鉴于目前缺乏利用机器学习（特别是PINN）解决现场逆热问题的研究，我们期望这项工作能成为该领域更多研究的起点。 |
