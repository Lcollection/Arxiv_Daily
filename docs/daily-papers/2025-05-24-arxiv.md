# arxiv 2025-05-24

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| ARB：一个全面的阿拉伯语多模态推理基准测试

（翻译说明：
1. 保留英文缩写"ARB"作为专有名词标识
2. "Comprehensive"译为"全面的"以体现其覆盖范围的完整性
3. "Arabic Multimodal"准确译为"阿拉伯语多模态"，保持计算机视觉-自然语言处理交叉领域的专业术语规范
4. "Reasoning Benchmark"采用"推理基准测试"的学术标准译法，其中"Benchmark"根据计算机科学领域惯例译为"基准测试"而非"标杆"
5. 整体结构保持学术文献标题的简洁性，使用冒号分隔主副标题） | Sara Ghaboura | [PDF](http://arxiv.org/pdf/2505.17021v1) | As Large Multimodal Models (LMMs) become more capable, there is growing
interest in evaluating their [翻译失败] |
| GoT-R1：通过强化学习释放多模态大语言模型的视觉生成推理能力

（翻译说明：
1. "Unleashing Reasoning Capability"译为"释放...推理能力"，准确传达"激发潜在能力"的技术内涵
2. "MLLM"作为专业术语保留缩写形式，并补充完整译名"多模态大语言模型"，符合学术翻译规范
3. "Visual Generation"译为"视觉生成"而非直译"可视化生成"，更符合计算机视觉领域术语
4. 采用"通过强化学习"的主动语态结构，既保持原文技术路线的准确性，又符合中文表达习惯
5. 整体采用"技术方法+目标效果"的标题结构，与中文计算机领域论文标题范式保持一致） | Chengqi Duan | [PDF](http://arxiv.org/pdf/2505.17022v1) | Visual generation models have made remarkable progress in creating realistic
images from text prompt [翻译失败] |
| SophiaVL-R1：通过思维奖励机制增强多模态大语言模型的推理能力  

（翻译说明：  
1. "Reinforcing"译为"增强"，体现模型性能的提升；  
2. "Thinking Reward"采用"思维奖励机制"的译法，既保留"奖励"的核心概念，又通过"机制"体现系统性设计；  
3. "MLLMs"全称展开为"多模态大语言模型"，符合中文技术文献惯例；  
4. 整体采用"通过...实现..."的句式结构，符合中文因果关系的表达习惯）  

关键术语对照：  
- Thinking Reward → 思维奖励机制  
- MLLMs (Multimodal Large Language Models) → 多模态大语言模型  
- Reasoning → 推理能力（补充"能力"使语义更完整） | Kaixuan Fan | [PDF](http://arxiv.org/pdf/2505.17018v1) | Recent advances have shown success in eliciting strong reasoning abilities in
multimodal large langu [翻译失败] |
| 《仿生人会梦见电子羊吗：一种类人的图像隐喻理解与推理框架》

注：
1. 标题翻译保留了原著名科幻小说《Do Androids Dream of Electric Sheep?》的经典译法"仿生人会梦见电子羊吗"，确保学术圈的文化共识
2. "Human-like"译为"类人的"准确表达仿人类认知特性的技术特征
3. "Implication Understanding"采用"隐喻理解"的译法，比直译"隐含意义理解"更符合认知科学术语规范
4. 框架（Framework）作为标准科技术语保留直译
5. 整体采用学术标题的经典冒号结构，主标题体现文化渊源，副标题说明技术实质 | Chenhao Zhang | [PDF](http://arxiv.org/pdf/2505.17019v1) | Metaphorical comprehension in images remains a critical challenge for AI
systems, as existing models [翻译失败] |
| CrossLMM：基于双重交叉注意力机制的长视频序列与大型多模态模型解耦方法

（翻译说明：
1. 专业术语处理：
- "CrossLMM" 保留原名不译，符合计算机领域命名惯例
- "LMMs" 译为"大型多模态模型"，全称对应"Large Multimodal Models"
- "Dual Cross-Attention" 译为"双重交叉注意力"，准确反映机制特征

2. 技术概念传达：
- "Decoupling" 译为"解耦"，精确表达分离/解除耦合关系的技术含义
- 通过增译"方法"二字，使中文标题更符合学术论文命名规范

3. 结构优化：
- 采用主副标题结构，用冒号替代原文介词"via"的表述
- "from"的被动语态转换为主动语态"与...解耦"，更符合中文表达习惯

4. 领域适配性：
- 保留"注意力机制"这一神经网络标准术语
- "长视频序列"的表述与视频处理领域术语体系保持一致） | Shilin Yan | [PDF](http://arxiv.org/pdf/2505.17020v1) | The advent of Large Multimodal Models (LMMs) has significantly enhanced Large
Language Models (LLMs) [翻译失败] |
| 《基于思维链强化学习的图像生成研究：DPO与GRPO算法对比分析》

翻译说明：
1. 标题结构调整为中文常见的"研究+副标题"形式，更符合学术论文标题规范
2. "Delving into"译为"研究"而非字面意义的"深入"，更简洁专业
3. "RL"完整译为"强化学习"（Reinforcement Learning），确保术语准确性
4. "CoT"保留英文缩写但补充完整形式"思维链"（Chain of Thought），首次出现时中英对照
5. "DPO vs. GRPO"译为"对比分析"，体现比较研究的核心内容，同时保留算法缩写
6. 使用书名号《》突出学术论文标题属性
7. 整体采用"方法+对象+研究类型"的学术标题结构，符合中文论文标题习惯

注：若需在正文中首次出现缩写术语，建议采用"思维链（Chain of Thought，CoT）"的完整标注形式，后续可单独使用"CoT"。 | Chengzhuo Tong | [PDF](http://arxiv.org/pdf/2505.17017v1) | Recent advancements underscore the significant role of Reinforcement Learning
(RL) in enhancing the  [翻译失败] |
| 视觉-语言-动作模型的交互式训练后优化

（说明：根据计算机视觉与人工智能领域的术语规范，"Post-Training"译为"训练后优化"更符合中文技术文献表述习惯；"Interactive"采用"交互式"标准译法；"Vision-Language-Action"保持专业领域通用的连字符结构，译为"视觉-语言-动作"以准确体现多模态特性。整体翻译在保持学术严谨性的同时，通过"优化"替代直译的"训练"，更符合中文技术场景下对模型性能提升的表达惯例。） | Shuhan Tan | [PDF](http://arxiv.org/pdf/2505.17016v1) | 我们提出RIPT-VLA——一种基于强化学习的简单可扩展交互式微调范式，仅需稀疏二元成功奖励即可对预训练视觉-语言-动作（VLA）模型进行优化。现有VLA训练流程严重依赖离线专家示范数据和监督式模仿学习，在低数据条件下难以适应新任务与环境。RIPT-VLA通过动态轨迹采样和留一法优势估计的稳定策略优化算法，实现了交互式微调。

该范式具有以下特征：首先，其通用性覆盖各类VLA模型，将轻量级QueST模型性能提升21.2%，并使70亿参数的OpenVLA-OFT模型达到97.5%的空前成功率；其次，具备卓越的计算与数据效率——仅需单次示范即可在15次迭代内，将原本失效的监督微调模型（4%成功率）提升至97%成功率。实验还表明，RIPT-VLA习得的策略能泛化至不同任务场景，并对初始状态具有强鲁棒性。这些成果标志着RIPT-VLA成为通过最小监督实现VLA模型高效微调的实用范式。 |
| 多空间多模态大语言模型：基于多模态大语言模型的多帧空间理解

（翻译说明：
1. 专业术语处理：
- "Multi-Spatial"译为"多空间"，准确表达空间维度多重性
- "MLLM"作为专业缩写保留全称译法"多模态大语言模型"
- "Multi-Frame"译为"多帧"，符合计算机视觉领域术语规范

2. 技术内涵传达：
- 通过冒号结构清晰呈现模型名称与核心功能的对应关系
- "Spatial Understanding"译为"空间理解"准确反映计算机视觉任务特性
- 使用"基于"明确技术实现的依赖关系

3. 学术文本特征：
- 保持术语一致性（如"Multi-Modal"统一译为"多模态"）
- 采用名词化结构（"理解"而非"进行理解"）
- 符合中文科技文献标题的简洁性要求（总字符数控制在合理范围）

4. 创新点突出：
- 通过语序调整强调"多帧"这一技术特征
- 使用破折号替代英文连字符，符合中文标点规范） | Runsen Xu | [PDF](http://arxiv.org/pdf/2505.17015v1) | 多模态大语言模型（MLLMs）在视觉任务领域发展迅速，但其空间理解能力仍局限于单幅图像，难以满足机器人技术等需要多帧推理的现实应用需求。本文提出一个创新框架，通过整合深度感知、视觉对应和动态感知三大能力，为MLLMs构建强大的多帧空间理解体系。该框架的核心是MultiSPA数据集——一个涵盖多样化3D与4D场景、规模超过2700万样本的新型大规模数据集。我们同步推出综合性基准测试体系，采用统一指标评估各类空间任务性能。由此构建的Multi-SpatialMLLM模型在基线测试和商业系统对比中均取得显著优势，展现出可扩展、泛化性强的多帧推理能力。研究还发现该模型具有多任务协同增益效应，在复杂场景中显现出早期涌现能力特征。我们同时演示了该模型作为机器人多帧奖励标注器的应用潜力。

（翻译说明：严格遵循学术文本规范，采用"多模态大语言模型"等标准术语；将"ill-suited"译为"难以满足"既准确又符合中文表达；通过破折号处理数据集名称解释，保持专业性与可读性；"emergent capabilities"译为"涌现能力"符合人工智能领域术语；长难句拆分符合中文多用短句的特点；"reward annotator"译为"奖励标注器"准确体现强化学习语境） |
| 《扩散模型何时遗忘概念？——概念擦除时机探究》

（译文说明：
1. 采用学术论文标题惯用的疑问句式，通过破折号引出研究焦点
2. "erased"译为"遗忘/擦除"双重含义，既体现机器学习特性又保留原文动词力度
3. "Diffusion Models"统一译为专业术语"扩散模型"
4. 添加"时机探究"明确研究维度，符合中文标题强调研究对象的表达习惯
5. 保留原文的现在时态，体现学术研究的普适性特征
6. 使用书名号符合中文期刊标题规范） | Kevin Lu | [PDF](http://arxiv.org/pdf/2505.17013v1) | Concept erasure, the ability to selectively prevent a model from generating
specific concepts, has a [翻译失败] |
| SpatialScore：面向多模态空间理解的统一评估框架

（翻译说明：
1. 专业术语处理：
- "SpatialScore" 采用音意结合译法，保留"Spatial"的空间含义，同时音译"Score"为"评分"，组合为"SpatialScore"
- "Multimodal Spatial Understanding" 译为"多模态空间理解"，准确对应计算机视觉与人工智能领域的专业术语

2. 学术规范体现：
- 使用"面向"而非"为了"，更符合中文论文标题的表达习惯
- "Unified Evaluation" 译为"统一评估框架"，通过增译"框架"二字，使中文标题更完整
- 保留原文的冒号结构，符合中英文学术标题的平行对应关系

3. 技术内涵传达：
- 通过"评估框架"的表述，暗示该研究提出的系统性评价体系
- "多模态"的译法准确反映了涉及视觉、语言等多种数据模态的研究特性
- 使用"空间理解"而非字面的"空间认识"，更符合人工智能领域对"understanding"的技术定义） | Haoning Wu | [PDF](http://arxiv.org/pdf/2505.17012v1) | Multimodal large language models (MLLMs) have achieved impressive success in
question-answering task [翻译失败] |
