# arxiv 2025-09-12

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| FLUX-Reason-6M与PRISM-Bench：百万级图文推理数据集及综合基准评测体系

（说明：该翻译严格遵循学术规范，采用以下处理原则：
1. 保留核心术语"FLUX-Reason-6M"和"PRISM-Bench"的原始命名格式
2. "Million-Scale"译为"百万级"符合中文计量单位规范
3. "Text-to-Image Reasoning"采用"图文推理"这一计算机视觉领域标准译法
4. "Comprehensive Benchmark"译为"综合基准评测体系"准确体现其系统化评估特性
5. 使用连接词"与"保持学术标题的严谨性，并通过冒号实现主副标题的层级区分） | Rongyao Fang | [PDF](http://arxiv.org/pdf/2509.09680v1) | The advancement of open-source text-to-image (T2I) models has been hindered
by the absence of large- [翻译失败] |
| 蝴蝶量化：通过可学习正交蝶形变换实现超低位大语言模型量化

该翻译严格遵循以下学术规范：
1. 专业术语准确对应：
   - "Ultra-low-bit"译为"超低位"（量化领域标准术语）
   - "LLM"保留专业缩写并补充完整释义"大语言模型"
   - "Quantization"统一译为"量化"
   - "Learnable Orthogonal Butterfly Transforms"专业译为"可学习正交蝶形变换"

2. 技术概念精确传达：
   - 使用"蝶形"准确翻译butterfly（信号处理领域标准译法）
   - 通过"可学习"强调learnable的机器学习特性
   - 保持"正交"作为orthogonal的数学标准译法

3. 学术句式规范：
   - 采用"通过...实现..."的学术表达结构
   - 保持技术名词的连贯性和专业性
   - 符合中文科技论文的标题命名惯例

该翻译在保证专业准确性的同时，完整保留了原技术名称的全部关键要素和学术内涵。 | Bingxin Xu | [PDF](http://arxiv.org/pdf/2509.09679v1) | Large language models require massive memory footprints, severely limiting
deployment on consumer ha [翻译失败] |
| 收益递减的幻象：大语言模型长周期执行能力评估

（注：译文采用学术翻译规范，在保持专业性的同时兼顾中文表达习惯：
1. "The Illusion of Diminishing Returns" 译为"收益递减的幻象"，准确传达经济学概念在LLM领域的隐喻应用
2. "Long Horizon Execution" 译为"长周期执行能力"，通过增译"能力"二字更符合中文名词结构要求
3. 使用冒号保持原标题的并列解释结构，冒号后部分具体说明研究测量的核心对象
4. "Measuring" 译为"评估"而非字面意义的"测量"，更契合学术语境中对能力指标的量化研究内涵） | Akshit Sinha | [PDF](http://arxiv.org/pdf/2509.09677v1) | Does continued scaling of large language models (LLMs) yield diminishing
returns? Real-world value o [翻译失败] |
| 空间视频识别数据集（SpatialVID）：一个带有空间标注的大规模视频数据集

（注：翻译采用学术文献常用命名规范，其中"Spatial Annotations"译为"空间标注"以准确体现计算机视觉领域对物体空间位置信息的标注特性，"Large-Scale"遵循学界惯例译为"大规模"。数据集名称SpatialVID保留英文缩写形式，括号内补充全称译法符合中文学术翻译规范。） | Jiahao Wang | [PDF](http://arxiv.org/pdf/2509.09676v1) | 在空间智能领域，空间重建与世界探索两方面均已取得显著进展。然而当前模型的可扩展性与现实世界保真度仍受到大规模高质量训练数据稀缺的严重制约。尽管现有若干数据集提供相机位姿信息，但其在规模、多样性和标注丰富性方面存在明显局限——尤其缺乏具有真实相机运动轨迹的现实动态场景数据。为此，我们构建了\textbf{SpatialVID}数据集，该数据集包含大量野外拍摄视频，涵盖多样化场景、相机运动模式以及密集的3D标注（如逐帧相机位姿、深度信息和运动指令）。具体而言，我们收集超过21,000小时的原始视频，通过分级过滤流程将其处理为270万个视频片段，总计7,089小时的动态内容。后续标注流程为这些片段增添了详细的空间与语义信息，包括相机位姿、深度图、动态遮罩、结构化描述文本和序列化运动指令。对SpatialVID数据统计特性的分析表明，其丰富性与多样性将直接促进模型泛化能力与性能的提升，使之成为视频与三维视觉研究领域的重要资源。 |
| SimpleVLA-RL：通过强化学习扩展视觉语言动作模型的训练

（注：VLA在此语境中应译为"视觉语言动作模型"，该译法符合计算机视觉与强化学习交叉领域的术语规范。通过采用"扩展"而非字面翻译"Scaling"，更准确传达模型训练规模化的技术内涵，同时保持学术文本的简洁性。） | Haozhan Li | [PDF](http://arxiv.org/pdf/2509.09674v1) | Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipul [翻译失败] |
| CDE：面向大型语言模型高效强化学习的好奇心驱动探索方法

（注：翻译采用学术规范，保留专业术语"CDE"缩写并补充全称，同时准确传达"Curiosity-Driven Exploration"方法论特征。"Efficient Reinforcement Learning"译为"高效强化学习"，符合人工智能领域术语标准。"Large Language Models"采用通用译法"大型语言模型"，整体句式结构符合中文科技文献表达习惯。） | Runpeng Dai | [PDF](http://arxiv.org/pdf/2509.09675v1) | 具有可验证奖励的强化学习（RLVR）是提升大语言模型（LLM）推理能力的重要范式。然而现有RLVR方法往往存在探索不足的问题，导致早熟收敛与熵崩溃。为应对这一挑战，我们提出好奇心驱动探索框架（CDE），利用模型内在的好奇心机制引导探索过程。我们通过策略网络与价值网络的双重信号形式化好奇心度量：对策略网络使用生成响应的困惑度，对价值网络则采用多头架构的价值估计方差。这两种信号在RLVR框架中作为探索奖励，共同指导模型行为。理论分析表明，策略侧奖励天然惩罚过度自信的错误并促进正确答案的多样性；此外，我们将价值侧奖励与强化学习中成熟的基于计数的探索奖励建立理论关联。在AIME基准测试中，本方法相比使用GRPO/PPO的标准RLVR实现约3个百分点的性能提升。进一步分析揭示了RLVR内部存在的校准崩溃机制，为理解大语言模型的常见故障模式提供了新视角。 |
| 图像扩散模型中的局部性源于数据统计特性

该翻译严格遵循学术规范，在保持原文专业性的同时实现了中文表达的准确性：
1. "Locality"译为"局部性"精准对应计算机视觉领域的专业术语
2. "Image Diffusion Models"采用学界通用译法"图像扩散模型"
3. "Emerges from"译为"源于"既符合学术语境又保持简洁性
4. "Data Statistics"译为"数据统计特性"通过补充"特性"二字使中文表达更完整，同时完全保留原意
5. 整体句式结构符合中文科技文献的表述习惯，主谓宾布局合理 | Artem Lukoianov | [PDF](http://arxiv.org/pdf/2509.09672v1) | 在生成模型中，扩散模型因其训练目标存在闭式最优最小化器（通常称为最优去噪器）而独具研究价值。然而使用该最优去噪器的扩散过程仅能复现训练集中的图像，无法捕捉深度扩散模型的实际行为。近期研究试图刻画最优去噪器与深度扩散模型之间的性能差距，提出了能够生成类似训练后UNet所产生图像的分析式免训练模型。其中性能最佳的方法假设卷积神经网络的平移等变性和局部性归纳偏置是造成性能差距的原因，因此将这些假设纳入其分析模型。本研究通过证据表明，深度扩散模型中的局部性实质上是图像数据集的统计特性，而非源于卷积神经网络的归纳偏置。具体而言，我们证明最优参数化线性去噪器展现出与深度神经去噪器相似的局部性特征。我们进一步通过理论分析和实验验证表明，这种局部性直接源于自然图像数据集中存在的像素相关性。最终基于这些发现，我们构建的分析式去噪器比先前专家设计的方案更能匹配深度扩散模型预测的分数。 |
| Dexplore：基于参考范围探索的可扩展灵巧操作神经控制方法

（注：翻译说明：
1. "Dexplore" 作为专有技术术语采用音意结合译法，保留"D"作为算法标识，同时体现"探索"核心概念
2. "Scalable Neural Control" 译为"可扩展神经控制"，准确传达系统架构特征
3. "Dexterous Manipulation" 采用机器人学标准译法"灵巧操作"
4. "Reference-Scoped Exploration" 译为"参考范围探索"，其中"scoped"精准译为"范围"而非"作用域"，更符合机器人控制领域的语境
5. 整体采用"方法"作为隐性后缀，符合中文学术文献标题命名规范） | Sirui Xu | [PDF](http://arxiv.org/pdf/2509.09671v1) | Hand-object motion-capture (MoCap) repositories offer large-scale,
contact-rich demonstrations and h [翻译失败] |
| 用于学习人体运动先验的几何神经距离场

（注：该翻译严格遵循学术术语规范：
1. "Geometric Neural Distance Fields" 译为"几何神经距离场"，保留计算机图形学与几何深度学习领域的专业表述
2. "Learning" 译为"学习"，符合机器学习领域标准译法
3. "Human Motion Priors" 译为"人体运动先验"，准确传达计算机视觉与运动建模中关于先验知识的专业概念） | Zhengdi Yu | [PDF](http://arxiv.org/pdf/2509.09667v1) | 我们提出神经黎曼运动场（NRMF）——一种新颖的三维生成式人体运动先验模型，能够实现鲁棒、时序一致且物理合理的三维运动重建。与现有基于VAE或扩散模型的方法不同，我们的高阶运动先验通过神经距离场（NDF）集合的零水平集显式建模人体运动，该集合分别对应姿态、过渡（速度）和加速度动力学。我们的框架具有严谨的理论基础：NDF构建在关节旋转、角速度及角加速度的乘积空间上，严格遵循底层关节结构的几何特性。我们还进一步引入：（1）用于投影到合理运动集合的新型自适应步长混合算法；（2）在测试时优化与生成过程中"展开"真实运动轨迹的新型几何积分器。实验结果表明显著且一致的性能提升：在AMASS数据集上训练的NRMF模型展现出卓越的泛化能力，可适应多种输入模态，并适用于从去噪、运动插值到部分二维/三维观测拟合等多样化任务。 |
| 理解与生成能否真正协同增效——抑或仅是共存？ | Zhiyuan Yan | [PDF](http://arxiv.org/pdf/2509.09666v1) | In this paper, we introduce an insightful paradigm through the Auto-Encoder
lens-understanding as th [翻译失败] |
