# arxiv 2025-10-19

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 耦合扩散采样实现免训练的多视角图像编辑 | Hadi Alzayer | [PDF](http://arxiv.org/pdf/2510.14981v1) | 我们提出一种推理时扩散采样方法，利用预训练的二维图像编辑模型实现多视角一致性图像编辑。现有模型能够对三维场景或物体的多视角图像集进行独立高质量编辑，但无法保持跨视角一致性。传统方法通常通过优化显式三维表征来解决该问题，但这些方法存在优化过程冗长且在稀疏视角设置下不稳定的缺陷。我们采用隐式三维正则化方法，通过约束生成的二维图像序列符合预训练的多视角图像分布来实现一致性。该方法通过耦合扩散采样技术实现——这是一种简单的扩散采样方法，可同时从多视角图像分布和二维编辑图像分布中采样两条轨迹，并利用耦合项强制生成图像间的多视角一致性。我们在三个不同的多视角图像编辑任务上验证了该框架的有效性与通用性，证明了其可适用于多种模型架构，并展现出作为多视角一致性通用解决方案的潜力。 |
| 从像素到词汇——迈向规模化原生视觉语言基元 | Haiwen Diao | [PDF](http://arxiv.org/pdf/2510.14979v1) | 原生视觉语言模型（VLMs）的体系已逐渐成为传统模块化VLMs的有力竞争者，这一发展由不断演进的模型架构与训练范式所推动。然而，仍有两大悬而未决的问题阻碍其广泛探索与推广：第一，原生VLMs与模块化VLMs的根本差异何在？这些差异能在多大程度上被突破？第二，如何降低原生VLMs的研究门槛，实现技术民主化，从而加速该领域发展？本文旨在厘清这些挑战，并提出构建原生VLMs的指导原则。具体而言，一个合格的原生VLM基础架构应满足：（i）在共享语义空间内有效对齐像素与文本表征；（ii）无缝融合传统独立视觉与语言模块的优势；（iii）内在地具备支持统一视觉语言编码、对齐与推理的跨模态特性。基于此，我们推出了NEO——一个从第一性原理构建的全新原生VLM系列。该模型仅通过3.9亿图文样本，就能在密集单体架构中从零高效习得视觉感知能力，同时缓解视觉-语言模态冲突。NEO凭借我们精心设计的基础组件，在多样现实场景中可与顶尖模块化模型媲美。我们将其定位为可扩展强大多模态模型的基石，并配套可复用组件库以构建高性价比、可扩展的生态系统。代码与模型已开源：https://github.com/EvolvingLMMs-Lab/NEO。 |
| 组合式机器的能动性设计 | Wenqian Zhang | [PDF](http://arxiv.org/pdf/2510.14980v1) | 复杂机器的设计既是人类智慧的标志，也是工程实践的基石。随着大语言模型（LLMs）的最新进展，我们提出疑问：它们是否也能学会创造？我们通过组合式机器设计这一视角来探讨该问题——该任务要求通过标准化组件组装机器，使其在模拟物理环境中满足运动或操控等功能需求。为支持这项研究，我们推出了BesiegeField测试平台。该平台基于机器建造游戏《Besiege》构建，支持基于零部件的建造、物理模拟和奖励驱动评估。通过BesiegeField，我们对具备智能体工作流程的尖端大语言模型进行基准测试，识别出成功所需的关键能力，包括空间推理、策略性组装和指令遵循。鉴于当前开源模型存在不足，我们探索了强化学习（RL）作为改进路径：通过构建冷启动数据集、开展RL微调实验，揭示了语言理解、机器设计与物理推理交叉领域面临的开放性挑战。 |
| 训练无需图像编辑对的图像编辑模型 | Nupur Kumari | [PDF](http://arxiv.org/pdf/2510.14978v1) | 近期图像编辑模型在遵循自然语言编辑指令方面已取得显著成果，但这些成果依赖于使用大规模输入-目标配对数据集进行监督微调。这构成了关键瓶颈，因为此类自然生成的配对数据难以大规模整理。当前解决方案通过利用现有模型的零样本能力生成合成训练对，但这种方法会将预训练模型的伪影传播并放大至最终训练模型中。本研究提出了一种全新的训练范式，可完全摆脱对配对数据的依赖。该方法通过训练过程中展开多步扩散模型，并借助视觉语言模型的反馈信号直接优化模型参数。针对每项输入和编辑指令，视觉语言模型会评估编辑结果是否遵循指令并保留未修改内容，从而为端到端优化提供直接梯度。为确保视觉保真度，我们引入分布匹配损失函数，将生成图像约束在预训练模型学习到的图像流形范围内。我们在标准基准测试中评估了本方法，并进行了详尽的消融实验。在无需任何配对数据的情况下，本方法在少步生成设定下的表现与基于大量监督配对数据训练的各类图像编辑扩散模型相当。当使用相同视觉语言模型作为奖励模型时，我们的方法也超越了基于强化学习的技术（如Flow-GRPO）。 |
| Ponimator：展开交互姿态以实现多样化人-人互动动画

（注：该翻译在保持专业术语准确性的基础上，采用"展开交互姿态"对应"unfolding interactive pose"的动态技术特征，"多样化"对应"versatile"的功能覆盖面，同时通过"人-人互动动画"精准传达"human-human interaction animation"的学术概念，符合计算机图形学与动画技术领域的专业表达规范。） | Shaowei Liu | [PDF](http://arxiv.org/pdf/2510.14976v1) | 近距离人际交互姿态能够传递丰富的交互动态上下文信息。基于此类姿态，人类可凭借对行为模式的强先验知识，直观推断交互情境并预测可能的过往与未来动态。受此启发，我们提出Ponimator框架——一种以近距离交互姿态为锚点的通用交互动画生成方案。我们的训练数据源自动作捕捉交互数据集，包含紧密接触的双人姿态及其相邻时序上下文。通过运用交互姿态先验知识，Ponimator采用两个条件扩散模型：(1) 姿态动画器利用时序先验从交互姿态生成动态运动序列；(2) 姿态生成器运用空间先验，在交互姿态缺失时根据单帧姿态、文本描述或二者共同输入合成交互姿态。该框架集成支持多种任务，包括基于图像的交互动画生成、反应动作生成以及文本到交互的合成，有效推动高质量动作捕捉数据中的交互知识向开放场景迁移。跨数据集与多应用的实证实验验证了姿态先验的普适性，以及我们框架的有效性与鲁棒性。 |
| Terra：基于点潜在空间的可探索原生三维世界模型

（注：Terra作为专有名词保留不译，通过冒号后的解释性翻译完整呈现技术特征："Explorable"译为"可探索"体现交互性，"Native 3D World Model"译为"原生三维世界模型"强调底层架构，"Point Latents"译为"点潜在空间"准确传达离散潜在表示的核心技术） | Yuanhui Huang | [PDF](http://arxiv.org/pdf/2510.14977v1) | 世界模型因其对现实世界的综合建模能力而受到日益广泛的关注。然而，现有方法大多仍以像素对齐表示作为世界演化的基础，忽略了物理世界固有的三维特性。这种局限可能削弱世界模型的三维一致性并降低建模效率。本文提出Terra——一个原生三维世界模型，通过内蕴三维潜在空间实现可探索环境的表征与生成。具体而言，我们设计了一种创新的点云-高斯变分自编码器（P2G-VAE），可将三维输入编码为潜在点表征，继而解码为三维高斯基元以联合建模几何结构与外观属性。随后引入稀疏点流匹配网络（SPFlow），通过同步去噪潜在点的空间位置与特征来实现潜在点表征的生成。Terra凭借原生三维表征与架构实现了精确的多视角一致性，仅需单次生成过程即可支持任意视点的灵活渲染。此外，该模型通过潜在点空间中的渐进式生成实现了可探索的世界建模。我们在ScanNet v2数据集中的复杂室内场景上进行了大量实验，结果表明Terra在保持高三维一致性的前提下，于重建与生成任务中均达到了最先进的性能水平。 |
| 与任何人：迈向可控且身份一致性的图像生成

（注：该翻译在保持学术术语准确性的基础上，采用以下处理方式：
1. "WithAnyone"译为"与任何人"，体现开放参与特性
2. "Towards"译为"迈向"，符合学术论文标题的演进性表述
3. "Controllable"和"ID Consistent"分别译为专业术语"可控"与"身份一致性"
4. 整体采用"领域+技术目标"的经典学术标题结构，符合中文计算机视觉领域论文命名规范） | Hengyuan Xu | [PDF](http://arxiv.org/pdf/2510.14975v1) | 身份一致性生成已成为文本到图像研究的重要方向，近期模型在生成与参考身份对齐的图像方面取得显著进展。然而，由于缺乏包含同一人物多张图像的大规模配对数据集，现有方法大多采用基于重建的训练方式。这种训练模式导致我们称之为"复制-粘贴"的失效现象——模型直接复制参考人脸，而非在姿态、表情或光照等自然变化中保持身份一致性。这种过度相似性会削弱可控性并限制生成表现力。为解决这些局限，我们（1）构建了专为多人场景设计的大规模配对数据集MultiID-2M，为每个身份提供多样化参考；（2）提出量化复制-粘贴伪影及身份保真度与变化度权衡的评估基准；（3）引入具有对比性身份损失的新训练范式，利用配对数据平衡保真度与多样性。这些成果最终形成基于扩散模型的WithAnyone系统，在保持高身份相似度的同时有效缓解复制-粘贴问题。大量定性与定量实验表明，WithAnyone显著减少复制-粘贴伪影，提升姿态与表情的可控性，并保持优越的感知质量。用户研究进一步验证本方法在实现高身份保真度的同时，能够完成富有表现力的可控生成。 |
| pi-Flow：基于策略的模仿蒸馏少步生成方法

（解析说明：
1. "Policy-Based"译为"基于策略的"，符合强化学习领域术语规范
2. "Few-Step Generation"采用"少步生成"的译法，既保留"few-step"的量化特征，又符合中文表达习惯
3. "Imitation Distillation"译为"模仿蒸馏"，准确对应机器学习中知识蒸馏与模仿学习的技术概念
4. 整体采用"方法"作为隐性后缀，符合中文论文标题命名惯例
5. 保留原标题的层级结构，通过冒号区分主副标题） | Hansheng Chen | [PDF](http://arxiv.org/pdf/2510.14974v1) | 基于少步扩散或流的生成模型通常会将预测速度的教师模型蒸馏为能够预测去噪数据捷径的学生模型。这种形式不匹配导致了复杂的蒸馏流程，往往面临质量与多样性的权衡问题。为此，我们提出基于策略的流模型（$\pi$-Flow）。该模型通过修改学生流模型的输出层，使其在单个时间步预测无需网络计算的动作策略。该策略随后在后续子步中生成动态流速度，其计算开销可忽略不计，从而无需额外网络评估即可在这些子步上实现快速精确的常微分方程积分。

为使策略的常微分方程轨迹与教师模型对齐，我们提出了一种新颖的模仿蒸馏方法：通过标准的$\ell_2$流匹配损失，使策略生成的速度在自身轨迹上与教师模型保持一致。通过直接模仿教师模型的行为，$\pi$-Flow实现了稳定可扩展的训练，并规避了质量-多样性权衡问题。在ImageNet 256$^2$数据集上，该模型以单步函数评估取得2.85的FID分数，优于同架构DiT的MeanFlow模型。在FLUX.1-12B和Qwen-Image-20B模型上，$\pi$-Flow仅需4步函数评估即可实现较当前最优少步方法显著提升的多样性，同时保持与教师模型相当的质量水平。 |
| 注意力机制是扩散大语言模型中KV缓存的全部所需 | Quan Nguyen-Tri | [PDF](http://arxiv.org/pdf/2510.14973v1) | 本研究探讨如何自适应重构扩散大语言模型（DLM）的键值缓存（KV Cache），以在最大化预测精度的同时最小化解码延迟。现有方法的解码器在每个去噪步骤和每个网络层中都会为所有令牌重新计算QKV，但事实上KV状态在多数步骤（尤其是浅层网络中）变化极小，导致大量冗余计算。我们提出三项关键发现：（1）远端${\bf MASK}$令牌主要起长度偏置作用，可在当前预测窗口外进行分块缓存；（2）KV动态变化随网络深度递增，表明从深层开始选择性刷新即可满足需求；（3）最高关注度令牌的KV漂移最小，这为其他令牌的缓存更新提供了保守下界。基于这些发现，我们提出无需训练、架构无关的${\bf Elastic-Cache}$策略，该策略通过联合决策机制确定${刷新时机}$（基于最高关注度令牌的注意力感知漂移检测）和${刷新范围}$（基于深度感知调度：从选定层开始刷新，同时复用浅层缓存与窗口外MASK缓存）。与固定周期方案不同，Elastic-Cache为扩散大语言模型实现自适应、层级感知的缓存更新，在保证生成质量无损的前提下显著减少冗余计算、加速解码过程。在LLaDA-Instruct、LLaDA-1.5和LLaDA-V模型上的数学推理与代码生成实验表明，该方法持续实现加速效果：GSM8K（256令牌）达$8.7\times$，长序列任务达$45.1\times$，HumanEval达$4.8\times$，且始终保持高于基线模型的精度。相较于现有基于置信度的方法，本方案在保持生成质量的同时实现了显著更高的吞吐量（GSM8K任务达$6.8\times$），为扩散大语言模型的实际部署提供了可行方案。 |
| TokDrift：当大语言模型以子词交流而代码以语法运行 | Yinxi Li | [PDF](http://arxiv.org/pdf/2510.14972v1) | 用于代码处理的大型语言模型依赖子词分词器（如字节对编码），这类分词器通过混合自然语言文本与程序代码训练获得，但其运作受统计规律而非语法规则驱动。因此，语义完全相同的代码片段可能因空格格式或标识符命名等表层差异而产生不同的分词结果。为量化这种错位带来的影响，我们提出TokDrift框架——通过施加保持语义不变的改写规则，生成仅在分词层面存在差异的代码变体。在对九款代码大模型（包括参数量超300亿的大型模型）的测试中，发现即使微小的格式改动也会引发模型行为的显著偏移。分层分析表明，该问题源于嵌入层初期：子词切分未能准确捕捉语法标记边界。本研究揭示了对齐失准的分词机制是阻碍代码可靠理解与生成的潜在瓶颈，指出未来代码大模型需要发展语法感知的分词方案。 |
