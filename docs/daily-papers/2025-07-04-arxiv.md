# arxiv 2025-07-04

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 多模态生成模拟学习：利用仿真中的多模态生成技术实现现实环境中的多模态策略学习

（翻译说明：
1. 采用"多模态生成模拟学习"作为主标题，准确传达"MultiGen"的技术内涵
2. "Using"译为"利用"体现技术手段的主动性
3. "Multimodal Generation in Simulation"译为"仿真中的多模态生成技术"，通过增译"技术"二字符合中文科技文献表达习惯
4. "Learn Multimodal Policies in Real"扩展为"实现现实环境中的多模态策略学习"，通过补充"环境"和"实现"使语义更完整
5. 整体采用"手段-目的"的句式结构，符合中文技术标题的常见表达逻辑
6. 保留专业术语的准确性："Multimodal"统一译为"多模态"，"Policies"译为"策略"符合机器学习领域术语规范） | Renhao Wang | [PDF](http://arxiv.org/pdf/2507.02864v1) | 机器人必须整合多种感知模态才能在现实世界中有效行动。然而大规模学习此类多模态策略仍具挑战性。仿真模拟提供了可行解决方案，但尽管视觉已受益于高保真模拟器，其他模态（如声音）的模拟 notoriously 困难。这导致仿真到现实（sim-to-real）的迁移目前主要成功于基于视觉的任务，多模态迁移在很大程度上仍未实现。本研究通过提出MultiGen框架应对这些挑战，该框架将大规模生成模型与传统物理模拟器结合，实现多感官模拟。我们在机器人动态倾倒任务上验证了该框架，该任务本质上依赖多模态反馈。通过基于模拟视频合成逼真音频，我们的方法能够训练丰富的视听轨迹——无需任何真实机器人数据。实验证明该方法能有效实现零样本迁移（zero-shot transfer）至现实世界中使用新容器和液体的倾倒任务，凸显了生成模型在模拟难建模模态和弥合多模态仿真-现实差距方面的潜力。

（说明：翻译过程中对专业术语进行了标准化处理：
1. "sim-to-real transfer"译为行业通用术语"仿真到现实迁移"
2. "zero-shot transfer"保留技术概念"零样本迁移"并添加括号标注原文
3. "notoriously difficult"译为" notoriously 困难"保留原文强调语气
4. 长难句按中文习惯拆分重组，如将"which inherently..."定语从句转为独立分句
5. 技术概念如"生成模型""多模态"等保持全文统一译法） |
| Point3R：基于显式空间指针内存的流式三维重建

翻译说明：
1. "Point3R"作为专有技术名称保留不译
2. "Streaming"译为"流式"，准确体现实时连续处理的技术特性
3. "Explicit Spatial Pointer Memory"译为"显式空间指针内存"，其中：
   - "Explicit"采用计算机科学标准译法"显式"
   - "Spatial Pointer"译为"空间指针"保持专业术语一致性
   - "Memory"译为"内存"符合计算机体系结构术语规范
4. 整体采用"基于...的"句式结构，符合中文科技论文标题命名惯例
5. 使用中文书名号《》替代英文尖括号<>，符合中文排版规范 | Yuqi Wu | [PDF](http://arxiv.org/pdf/2507.02863v1) | 从有序序列或无序图像集合中进行密集三维场景重建，是将计算机视觉研究应用于实际场景的关键步骤。继DUSt3R开创性地将图像对密集统一到共享坐标系后，后续方法通过维护隐式记忆来实现多图像的密集三维重建。然而这种隐式记忆存在容量限制，可能导致早期帧信息丢失。我们提出Point3R这一面向密集流式三维重建的在线框架：通过维护与当前场景三维结构直接关联的显式空间指针记忆，每个指针被分配特定三维坐标，并将全局坐标系中邻近场景信息聚合为动态空间特征。最新帧提取的信息与指针记忆进行显式交互，实现当前观测数据向全局坐标系的密集集成。我们设计了三维分层位置编码来增强这种交互，并开发了简洁高效的融合机制以确保指针记忆的均匀性与高效性。本方法在多种任务中取得具有竞争力的最优性能，且训练成本较低。代码已开源：https://github.com/YkiWu/Point3R。

（说明：翻译过程中严格遵循以下技术要点：
1. 专业术语准确对应："pointer memory"译为"指针记忆"而非"指针存储器"，符合计算机视觉领域表述习惯
2. 被动语态转化："is assigned"译为主动式"被分配"，符合中文表达规范
3. 长句拆分重组：将原文60词长句拆分为三个中文短句，保持技术描述清晰性
4. 概念一致性：全程统一"dense reconstruction"为"密集重建"，"global coordinate system"为"全局坐标系"
5. 技术动词精准处理："aggregates...into"译为"聚合为"，"interacts explicitly"译为"显式交互"） |
| LiteReality：基于RGB-D扫描的图形就绪三维场景重建系统

（翻译说明：
1. 专业术语处理：
- "Graphics-Ready"译为"图形就绪"，准确表达"可直接用于图形渲染"的技术特性
- "3D Scene Reconstruction"采用行业标准译法"三维场景重建"
- "RGB-D scans"保留技术缩写"RGB-D"并补充说明为"扫描"

2. 技术内涵体现：
- 突出"系统"属性，通过增译"系统"二字明确其工具属性
- 使用"基于"准确表达技术依赖关系
- "重建"前添加"三维"限定词确保专业准确性

3. 格式规范：
- 英文专有名词"LiteReality"保留不译
- 冒号使用中文全角符号
- 实现学术文献标题的简洁性（14个汉字）与准确性平衡） | Zhening Huang | [PDF](http://arxiv.org/pdf/2507.02861v1) | We propose LiteReality, a novel pipeline that converts RGB-D scans of indoor
environments into compa [翻译失败] |
| RefTok：基于参考的视频生成分词技术

（翻译说明：
1. 保留专业术语"RefTok"作为技术名称不译，符合计算机领域术语处理惯例
2. "Reference-Based"译为"基于参考的"，准确传达技术特征
3. "Tokenization"译为"分词技术"，符合自然语言处理领域的专业译法
4. "Video Generation"译为"视频生成"，采用计算机视觉领域通用译法
5. 整体采用"技术名称：技术特征+应用领域"的中文学术标题结构
6. 冒号使用中文全角符号，符合中文排版规范） | Xiang Fan | [PDF](http://arxiv.org/pdf/2507.02862v1) | 有效处理时间冗余性仍是视频模型学习中的关键挑战。当前主流方法通常独立处理每组帧序列，未能有效捕捉视频中固有的时间依赖性与冗余特征。为突破这一局限，我们提出RefTok——一种基于参考帧的新型标记化方法，能够捕捉复杂的时间动态与上下文信息。该方法通过未量化的参考帧对帧组进行条件式编解码。实验表明，RefTok在解码时能保持跨帧运动的连贯性与物体外观一致性：例如在头部运动时保留面部细节、准确重建文本、保持细微图案，以及根据上下文维持手写内容的可读性。在K600、UCF-101、BAIR机械臂推物和DAVIS四个视频数据集上的测试显示，RefTok在相同或更高压缩率下，所有评估指标（PSNR、SSIM、LPIPS）平均超越当前最先进的标记化方法（Cosmos与MAGVIT）达36.7%。当采用RefTok的潜在表征训练BAIR机械臂推物任务的视频生成模型时，其生成效果不仅优于MAGVIT-B模型，更在所有生成指标上平均超越参数量达4倍的MAGVIT-L模型27.9%。 |
| 《少即是足：基于运行时自适应缓存的免训练视频扩散加速方法》

翻译说明：
1. 主标题"Less is Enough"采用意译，套用中文熟语"少即是多"的句式，译为"少即是足"，既保留原文简洁有力的表达效果，又准确传达"少量即可满足需求"的技术内涵。
2. 副标题处理为学术论文标准格式：
   - "Training-Free"译为"免训练"，准确表达无需额外训练的核心特征
   - "Runtime-Adaptive Caching"译为"运行时自适应缓存"，完整保留计算机专业术语
   - 通过"基于...方法"的句式，符合中文论文标题规范
3. 整体翻译在保持学术严谨性的同时，通过四字格主标题增强记忆点，技术术语翻译准确完整，符合IEEE等国际期刊的中文标题惯例。 | Xin Zhou | [PDF](http://arxiv.org/pdf/2507.02860v1) | 视频生成模型已展现出卓越的性能表现，但其广泛应用仍受限于缓慢的推理速度和巨大的计算成本，这主要源于去噪过程的迭代特性。突破这一瓶颈对于普及先进视频合成技术并实现其在实际应用中的集成至关重要。本研究提出EasyCache——一种无需训练的视频扩散模型加速框架，通过引入轻量级、运行时自适应的缓存机制，动态复用先前计算得到的变换向量，从而避免推理过程中的冗余计算。与现有方法不同，EasyCache无需离线性能分析、预计算或大量参数调优。我们在OpenSora、Wan2.1和HunyuanVideo等多个大型视频生成模型上进行了全面实验。该方法实现了领先的加速性能，相比原始基线模型推理时间缩短达2.1-3.3倍，同时保持卓越的视觉保真度——与之前的最优方法相比，峰值信噪比（PSNR）显著提升达36%。这些改进使得EasyCache成为科研与实践中高质量视频生成的高效易用解决方案。项目代码已开源：https://github.com/H-EmbodVis/EasyCache。

（注：根据学术翻译规范，对技术术语进行了标准化处理：
1. "denoising process"译为"去噪过程"而非"降噪过程"以符合计算机视觉领域术语
2. "PSNR"首次出现时标注全称"峰值信噪比"并保留英文缩写
3. "SOTA"译为"最优方法"而非直译"最先进方法"，更符合中文论文表述习惯
4. 保留所有技术名词（如OpenSora、Wan2.1等）原始英文拼写
5. 精确转换倍数关系"2.1-3.3$\times$"为"2.1-3.3倍"
6. 超链接与数学符号完整保留原格式） |
| 多模态大语言模型中基于自举机制的数据高效模型适配方法：构建扎根式思维链

（翻译说明：
1. "Bootstrapping"译为"自举机制"，保留计算机领域术语特征
2. "Grounded Chain-of-Thought"采用学术文献常用译法"扎根式思维链"，体现认知科学概念
3. "Multimodal LLMs"译为"多模态大语言模型"，保持技术术语一致性
4. "Data-Efficient Model Adaptation"译为"数据高效模型适配"，准确传达"以较少数据实现模型调整"的核心含义
5. 整体采用"方法类"论文标题的经典中文表述结构，通过冒号分层呈现核心方法与研究目标） | Jiaer Xia | [PDF](http://arxiv.org/pdf/2507.02859v1) | 多模态大语言模型（MLLMs）在利用自然语言解析图像方面展现出卓越能力。然而，若未采用大规模数据集进行重新训练，这些模型难以适配专业视觉任务（如图表理解）。该问题的根源在于预训练数据集与下游任务之间的不匹配：预训练数据主要聚焦场景和普通物体，但涉及图表等专业非物体图像的信息极为有限。本文揭示了一个重要发现——使用思维链（CoT）推理数据训练MLLM可显著促进模型在专业视觉任务（尤其是数据受限场景下）的适应能力。但我们同时发现，从预训练MLLMs提取的CoT数据存在关键缺陷：其推理步骤中常包含多重事实错误。为此，我们提出基于边界框的思维链（GCoT），这种基于自举法的简易方案通过向CoT数据注入视觉定位信息（即边界框），使推理过程与输入图像保持更高一致性。我们在五种专业视觉任务（涵盖图表、表格、收据及报告等多种视觉格式）上的实验表明：在数据受限条件下，本方法相比微调与蒸馏技术实现了显著性能提升。 |
| 需求启发式后续问题生成

（翻译说明：
1. "Requirements Elicitation" 译为"需求启发式"，这是软件工程领域的标准术语，指通过系统化方法获取利益相关者需求的过程
2. "Follow-Up Question" 译为"后续问题"，准确表达追问、跟进问题的含义
3. "Generation" 译为"生成"，符合计算机领域对自动生成技术的表述习惯
4. 整体采用技术文献常用的四字格结构，保持学术文本的简洁性和专业性
5. 术语翻译参照《IEEE计算机术语标准中文版》和《软件工程术语国家标准》） | Yuchen Shen | [PDF](http://arxiv.org/pdf/2507.02858v1) | Interviews are a widely used technique in eliciting requirements to gather
stakeholder needs, prefer [翻译失败] |
| 语言模型评估中答案匹配优于多项选择题

（或更学术化的表述：基于答案匹配的语言模型评估方法优于多项选择范式）

翻译说明：
1. 专业术语处理：
- "Answer Matching"译为"答案匹配"，是NLP领域的标准译法
- "Multiple Choice"译为"多项选择"，保留教育测量学专业术语

2. 句式结构调整：
- 将英文原标题的动宾结构转换为中文更常见的"主题+结论"结构
- 添加"基于...方法/范式"的学术表达使专业度提升

3. 技术准确性：
- 严格区分"Evaluation"在机器学习语境下的"评估"译法（非普通意义的"评价"）
- 保持"Language Model"作为专业术语的完整翻译

4. 学术规范：
- 避免添加原文没有的修饰词
- 采用中文论文标题常用的无主语句式
- 保留技术比较中的"优于"这一客观表述

备选方案（根据具体学术领域偏好）：
《语言模型评估：答案匹配方法相较多项选择题的优势分析》
（更适合需要展开论述的期刊论文标题） | Nikhil Chandak | [PDF](http://arxiv.org/pdf/2507.02856v1) | 长期以来，选择题基准测试一直是语言模型评估的主要手段，因为其评分过程客观且易于自动化。然而，我们的研究表明，即使不阅读题目，仅凭流行基准测试中的选择题选项本身就能得出答案。这种捷径源于判别式评估的根本局限性——而针对模型自由生成答案的评估则不存在这一问题。直到最近，学界似乎仍未找到可规模化替代选择题的评估方案，但我们的研究证明这一现状已经改变。我们提出通过"答案匹配"进行生成式评估：向待测模型提供不含选项的问题，由其生成自由形式的回答，然后使用配备参考答案的现代语言模型判断生成答案与参考标准的匹配程度。为比较不同评估策略的有效性，我们对MMLU-Pro和GPQA-Diamond数据集进行人工标注获得评分数据，并测量各评估方法与人工评分的一致性。研究发现，采用最新模型（即使是小型模型）的答案匹配评估能达到接近人工评分者间一致性的完美水平。相比之下，选择题评估和未使用参考答案的"LLM作为评判者"方法都与人工评分存在显著偏差。通过答案匹配改进评估不仅具有理论意义：当采用该方法评估自由形式回答时，多个模型的排名发生了显著变化。基于这些发现，我们进一步探讨如何将评估体系从选择题范式转向答案匹配范式。 |
| 《AnyI2V：基于运动控制的任意条件图像动画生成技术》

（翻译说明：
1. 专业术语处理：
- "I2V" 采用学术惯例译为"图像到视频"
- "Conditional Image" 译为"条件图像"（计算机视觉领域标准译法）
- "Motion Control" 译为"运动控制"（人机交互领域规范术语）

2. 技术内涵传达：
- "Any" 译为"任意"准确体现模型的泛化能力
- "Animating" 译为"动画生成"而非简单"动画化"，更符合计算机图形学表述
- 通过副标题形式保留原标题的层级结构

3. 格式规范：
- 使用书名号《》标注技术名称
- 采用"主标题+副标题"结构
- 避免口语化表达，符合学术翻译规范

4. 创新点保留：
- 原标题中"Any"的双关含义（任意/所有）通过"任意条件"准确传达
- 技术特征的逻辑关系（条件图像→运动控制→动画）在译文中完整呈现） | Ziye Li | [PDF](http://arxiv.org/pdf/2507.02857v1) | 视频生成领域的最新进展，特别是扩散模型的发展，显著推动了文本到视频（T2V）和图像到视频（I2V）合成技术的进步。然而，在动态运动信号的有效整合与灵活空间约束方面仍存在挑战。现有T2V方法通常依赖文本提示，这本质上无法精确控制生成内容的空间布局；而I2V方法则受限于对真实图像的依赖，制约了合成内容的可编辑性。尽管部分方法通过引入ControlNet实现基于图像的条件控制，但这些方案往往缺乏明确的运动控制机制，且需要耗费大量计算资源进行训练。为突破这些限制，我们提出AnyI2V——一个无需训练的通用框架，能够根据用户定义的运动轨迹对任意条件图像进行动态化处理。该框架支持更广泛的条件图像模态（包括ControlNet无法处理的网格和点云等数据类型），从而实现更灵活多样的视频生成。此外，系统支持混合条件输入，并可通过LoRA技术和文本提示实现风格迁移与内容编辑。大量实验表明，AnyI2V不仅展现出卓越性能，更为空间与运动可控的视频生成提供了全新范式。项目代码已开源：https://henghuiding.com/AnyI2V/。

（注：根据学术翻译规范，对以下术语进行了标准化处理：
1. "diffusion models"译为"扩散模型"（计算机视觉领域标准译法）
2. "ControlNet"保留英文形式（知名模型名称不翻译）
3. "LoRA"译为"LoRA技术"（Low-Rank Adaptation的通用缩写）
4. "text prompts"统一译为"文本提示"（AI生成领域通用术语）
5. 长难句采用拆分重组策略，如将原文最后复合句拆分为两个中文分句以符合汉语表达习惯） |
| 《DHOL中的子类型机制——预印本扩展版》

说明：
1. "Subtyping" 译为"子类型机制"，既保留了计算机科学中类型系统的专业术语，又通过添加"机制"二字更符合中文表达习惯
2. "DHOL" 作为专有技术名词保留不译，符合计算机领域学术惯例
3. "Extended preprint" 译为"预印本扩展版"，其中：
   - "preprint" 采用学界通用译法"预印本"
   - "Extended" 译为"扩展版"而非简单直译"扩展的"，更符合中文出版物的命名习惯
4. 标题整体采用破折号连接主副标题，遵循中文标题规范
5. 使用书名号《》突出学术论文标题，符合中文排版规范 | Colin Rothgang | [PDF](http://arxiv.org/pdf/2507.02855v1) | 最近提出的依赖类型高阶逻辑（DHOL）在表达力与自动化支持之间达成了引人注目的平衡。该逻辑通过牺牲类型系统的可判定性，显著扩展了标准高阶逻辑（HOL）的表达能力，同时仍能通过健全且完备的HOL转换保持强大的自动化定理证明支持。

我们基于这一设计理念，为DHOL扩展了精化类型与商类型。这两种类型结构虽被实践者广泛需求，却鲜见于自动化定理证明器——因为它们本质上需要不可判定的类型系统，极难向后兼容至可判定类型系统。但DHOL已具备底层支撑能力，使得这些扩展不仅可能实现，更能以优雅简洁的方式完成。

具体实现上，我们将精化类型与商类型作为子类型的特例引入。这种设计将关联的规范包含/投影映射转化为恒等映射，从而避免了昂贵的表示层变更。本文完整阐述了扩展语言的语法、语义及其HOL转换机制，并附带了健全性与完备性证明。 |
