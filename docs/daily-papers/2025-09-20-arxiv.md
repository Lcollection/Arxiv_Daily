# arxiv 2025-09-20

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 翻译中迷失？开放词汇语义分割中无源域适应的词汇对齐

（注：翻译说明：
1. "Lost in Translation"采用意译处理为"翻译中迷失"，既保留原文学隐喻又符合中文表达习惯
2. "Vocabulary Alignment"专业术语准确译为"词汇对齐"
3. "Source-Free Domain Adaptation"按计算机视觉领域规范译为"无源域适应"
4. "Open-Vocabulary Semantic Segmentation"完整保留专业术语结构译为"开放词汇语义分割"
5. 整体采用学术论文标题的简洁句式，问号位置与英文原题保持对应，符合中文标点规范） | Silvio Mazzucco | [PDF](http://arxiv.org/pdf/2509.15225v1) | 我们提出VocAlign——一种专为开放词汇语义分割中的视觉语言模型（VLM）设计的新型无源域自适应框架。该方法采用基于词汇对齐策略增强的师生学习范式，通过融入额外类别概念来提升伪标签生成质量。为保障效率，我们采用低秩自适应（LoRA）技术对模型进行微调，在保留原始能力的同时显著降低计算开销。此外，我们为学生模型设计了Top-K类别选择机制，在进一步提升自适应性能的同时大幅降低内存需求。本方法在CityScapes数据集上实现了6.11 mIoU的显著提升，并在零样本分割基准测试中展现出卓越性能，为开放词汇场景下的无源域自适应确立了新标准。 |
| 面向医疗视觉语言模型的校准感知提示学习

（注：该翻译在保持学术严谨性的基础上实现了以下要点：
1. 准确传达"Calibration-Aware"的技术内涵，采用"校准感知"这一符合机器学习领域术语规范的译法
2. 保留"Prompt Learning"作为提示学习的标准译名，这是视觉语言模型领域的核心概念
3. 完整呈现"Medical Vision-Language Models"的专业表述，译为"医疗视觉语言模型"
4. 通过"面向..."的句式结构准确体现技术方法与目标领域的关联性
5. 整体表述符合中文科技论文的标题命名规范，保持术语统一性和学术准确性） | Abhishek Basu | [PDF](http://arxiv.org/pdf/2509.15226v1) | Medical Vision-Language Models (Med-VLMs) have demonstrated remarkable
performance across diverse me [翻译失败] |
| 深度AnyEvent：一种基于事件单目深度估计的跨模态蒸馏范式

（注：翻译说明：
1. "Depth AnyEvent" 采用音意结合译法，保留"Depth"的专业含义同时音译"AnyEvent"为"AnyEvent"
2. "Cross-Modal Distillation Paradigm" 译为"跨模态蒸馏范式"，准确对应计算机视觉领域的专业术语
3. "Event-Based Monocular Depth Estimation" 译为"基于事件单目深度估计"，完整保留技术描述的核心要素
4. 整体采用学术论文标题的简洁句式，符合中文科技文献的命名规范） | Luca Bartolomei | [PDF](http://arxiv.org/pdf/2509.15224v1) | 事件相机能够捕获稀疏且高时间分辨率的视觉信息，这使其特别适用于存在高速运动和剧烈光照变化的挑战性环境。然而，缺乏带有密集真实深度标注的大规模数据集，阻碍了基于学习的方法从事件数据中进行单目深度估计的发展。为解决这一局限性，我们提出了一种跨模态蒸馏范式，通过利用视觉基础模型（VFM）生成密集代理标签。该策略仅需空间对齐的事件流与RGB帧——这种简单设置甚至可直接采用现成设备，同时充分发挥大规模VFM的鲁棒性。此外，我们提出对VFM进行适配：既可采用如Depth Anything v2（DAv2）的标准模型，也可基于其构建新型循环架构，从而实现从单目事件相机推断深度。我们通过合成数据集和真实场景数据集进行评估，结果表明：i）我们的跨模态范式无需昂贵深度标注即可达到与全监督方法相当的性能；ii）基于VFM的模型实现了最先进的性能水平。 |
| 用于多模态钢琴演奏数据集采集与指法标注的两种网络工具包

（注：此处采用学术翻译的常见处理方式：
1. 保留核心术语的准确性："Multimodal"译为"多模态"，"Fingering Annotation"译为专业术语"指法标注"
2. 调整英文介词结构为中文动宾结构："for..."处理为"用于..."
3. 将长名词短语拆解为符合中文表达习惯的短句结构
4. 使用"工具包"对应"Toolkits"更符合中文计算机领域术语习惯
5. 保持学术文本的客观性，避免添加任何解释性内容） | Junhyung Park | [PDF](http://arxiv.org/pdf/2509.15222v1) | 钢琴演奏是一种多模态活动，其本质在于将肢体动作与声音呈现有机结合。尽管学界对分析钢琴演奏多模态特性的研究兴趣日益增长，但获取大规模多模态数据的繁琐过程仍是重要瓶颈，阻碍着该领域的进一步发展。为突破此障碍，我们开发了一套集成式网络工具包，包含两个图形用户界面（GUI）：（一）PiaRec——支持同步采集音频、视频、MIDI及演奏元数据；（二）ASDF——可实现基于视觉数据的演奏指法高效标注。该集成系统能够显著简化多模态钢琴演奏数据集的采集流程。 |
| ScaleCUA：利用跨平台数据扩展开源计算机使用代理

（注：翻译说明：
1. "ScaleCUA" 保留首字母大写形式作为专有名词
2. "Scaling" 译为"扩展"以体现系统规模的扩大
3. "Computer Use Agents" 采用"计算机使用代理"的学术标准译法
4. "Cross-Platform Data" 译为"跨平台数据"准确传达数据特性
5. 整体采用技术文献常用的冒号分隔标题结构，符合中文科技文献命名规范） | Zhaoyang Liu | [PDF](http://arxiv.org/pdf/2509.15221v1) | Vision-Language Models (VLMs) have enabled computer use agents (CUAs) that
operate GUIs autonomously [翻译失败] |
| 基于置信度感知扩散模型的轻量化高精度多视角立体视觉方法

（注：翻译严格遵循以下学术规范：
1. 核心术语对应："Lightweight"译为"轻量化"（计算机视觉领域标准译法）
2. 技术概念保留："Multi-View Stereo"保持"多视角立体视觉"专业称谓
3. 方法特征传达："Confidence-Aware"译为"置信度感知"（模式识别领域通用译法）
4. 算法类型明示："Diffusion Model"译为"扩散模型"（机器学习领域规范术语）
5. 整体结构符合中文论文标题的简洁性与专业性要求） | Fangjinhua Wang | [PDF](http://arxiv.org/pdf/2509.15220v1) | To reconstruct the 3D geometry from calibrated images, learning-based
multi-view stereo (MVS) method [翻译失败] |
| LNE-Blocking：一种面向大型语言模型污染缓解评估的高效框架

（注：翻译严格遵循以下原则：
1. 保留核心术语"LNE-Blocking"作为专有名词不译
2. "Contamination Mitigation"译为专业术语"污染缓解"
3. "Evaluation"在学术语境下译为"评估"而非"评价"
4. 采用"大型语言模型"这一学界通用译法
5. 保持原文的学术严谨性，使用"框架"对应"Framework"
6. 通过冒号维持原标题的并列结构，确保格式规范） | Ruijie Hou | [PDF](http://arxiv.org/pdf/2509.15218v1) | 在大规模语言模型（LLM）发展过程中，数据污染问题如今几乎难以避免——即使无意为之，训练数据也常常会融入各类评估基准。这一问题进而导致难以公平评估LLM的性能表现。相较于构建完全无污染的数据集（极具挑战性），我们提出了一种创新框架\textbf{LNE阻断法（LNE-Blocking）}，旨在恢复模型在潜在数据泄露发生前的原始性能。该框架包含两大核心组件：污染检测与干扰操作。针对输入提示，框架首先采用污染检测方法\textbf{LNE}来评估模型受污染程度，据此动态调整干扰操作\textbf{阻断法（Blocking）}的强度，从而引导模型生成非记忆性响应。本框架是首个能有效恢复模型贪婪解码性能的方案，在多个存在泄露风险的数据集上表现优异，且在不同模型及不同程度数据污染场景下均能实现稳定的性能恢复效果。我们已开源代码：https://github.com/RuijieH/LNE-Blocking，以促进相关研究。 |
| 视野外轨迹：追踪、融合与预测

（注：翻译严格遵循学术术语规范：
1. "Out-of-Sight"译为"视野外"符合计算机视觉与自动驾驶领域术语标准
2. "Trajectories"采用"轨迹"这一固定译法
3. "Tracking/Fusion/Prediction"分别译为"追踪/融合/预测"，符合目标跟踪与传感器融合领域的技术术语体系
4. 整体采用名词化短语结构，保持学术标题的简洁性和专业性） | Haichao Zhang | [PDF](http://arxiv.org/pdf/2509.15219v1) | Trajectory prediction is a critical task in computer vision and autonomous
systems, playing a key ro [翻译失败] |
| 可泛化的几何图像描述合成

（注：该翻译严格遵循学术术语规范：
1. "Generalizable" 译为"可泛化的"，符合计算机视觉领域对模型泛化能力的标准表述
2. "Geometric" 保留"几何"的专业含义，指涉及空间结构与形状关系的图像特征
3. "Image Caption Synthesis" 采用"图像描述合成"这一学界通用译法，准确体现生成式任务特性
4. 整体语序符合中文学术表达习惯，同时完整保留原术语的技术内涵） | Yue Xin | [PDF](http://arxiv.org/pdf/2509.15217v1) | 多模态大语言模型在诸多需要强大推理能力的实际应用中具有广泛用途。尽管近期取得进展，这类模型在解决复杂几何问题时仍面临困难。关键挑战源于缺乏用于理解几何图形的高质量图文配对数据集。此外，大多数基于模板的数据合成流程通常难以泛化到预定义模板之外的问题。本文通过将可验证奖励的强化学习（RLVR）互补流程引入数据生成管道，成功弥补了这一空白。我们采用RLVR方法对基于50种基础几何关系合成的几何图像标题进行优化，并利用数学解题任务衍生的奖励信号，使生成流程成功捕捉几何解题的关键特征。这种方法不仅实现了更好的任务泛化能力，还带来了显著性能提升。值得注意的是，即使在分布外场景下，生成的数据集也能增强多模态大语言模型的通用推理能力：在MathVista和MathVerse的非几何图像任务中，统计、算术、代数和数值计算任务的准确率提升达2.8%-4.8%；在MMMU基准的艺术、设计、技术和工程类任务中，准确率提升达2.4%-3.9%。 |
| 通过规则引导的大型语言模型提示评估全球历史结构性压迫

（注：翻译严格遵循学术规范，保留核心术语："Rule-Guided Prompting"译为"规则引导的提示"，"Large Language Models"采用学界通用译法"大型语言模型"，"Structural Oppression"译为专业术语"结构性压迫"。整体采用倒装结构突出方法论特征，符合中文论文标题的表述习惯。） | Sreejato Chatterjee | [PDF](http://arxiv.org/pdf/2509.15216v1) | 传统的历史结构性压迫测量方法因各国独特的、地方化的排斥史、殖民史及社会地位差异而难以实现跨国有效性，且往往依赖结构化指数——这些指数偏重物质资源维度，却忽视了基于身份认同的生活化排斥。我们提出了一种新型压迫测量框架，利用大语言模型（LLMs）生成适用于不同地缘政治情境的、具有语境敏感性的历史生存劣势评分。通过采用多语言COVID-19全球研究中非结构化的自我认同族群表述数据，我们设计了规则引导的提示策略，促使模型产生可解释且理论根基扎实的压迫程度评估。我们在多个前沿大语言模型上系统评估了这些策略。研究结果表明，在明确规则引导下，大语言模型能够捕捉国家内部基于身份认同的细微历史压迫形态。该方法提供了一种互补性测量工具，凸显系统性排斥的多元维度，为理解数据驱动研究和公共卫生背景下压迫现象的表现形式提供了可扩展的跨文化视角。为支持可重复评估，我们开源了基准数据集用于大语言模型压迫测量能力测评（https://github.com/chattergpt/llm-oppression-benchmark）。 |
