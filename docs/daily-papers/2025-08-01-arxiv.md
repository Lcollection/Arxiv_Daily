# arxiv 2025-08-01

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 《基于高斯变异场扩散的高保真视频至四维合成方法》

（翻译说明：
1. 专业术语处理：
- "Gaussian Variation Field"译为"高斯变异场"，保留数学概念准确性
- "Diffusion"采用当前学界通用译法"扩散"
- "High-fidelity"译为"高保真"，符合工程领域术语规范
- "Video-to-4D"译为"视频至四维"，其中"4D"指三维空间+时间维度

2. 技术内涵传达：
- 突出"高斯变异场"作为核心数学工具的创新性
- 强调"扩散"过程的动态特性
- 保持"高保真"的质量要求
- 明确"视频→4D"的维度转换特征

3. 句式结构调整：
将英文名词短语转换为中文"基于...的..."句式，符合中文论文标题常用表达范式

4. 领域适配性：
该译法符合计算机图形学/计算机视觉领域的中文论文命名惯例，与SIGGRAPH/CVPR等顶会的中文文献表述风格一致） | Bowen Zhang | [PDF](http://arxiv.org/pdf/2507.23785v1) | 本文提出了一种创新的视频到四维生成框架，能够从单一视频输入创建高质量动态三维内容。直接进行四维扩散建模面临两大核心挑战：昂贵的数据构建成本，以及联合表征三维形状、外观和运动的高维度特性。为解决这些问题，我们提出了直接四维网格到高斯溅射变分场自编码器（Direct 4DMesh-to-GS Variation Field VAE），该模型无需逐实例拟合即可从三维动画数据中直接编码规范高斯溅射（GS）及其时序变化，并将高维动画压缩至紧凑的潜在空间。基于这一高效表征，我们训练了具有时序感知能力的扩散变换器高斯变分场扩散模型，其条件输入为视频和规范高斯溅射。在Objaverse数据集精选的可动画三维对象上进行训练后，本模型展现出优于现有方法的生成质量。尽管仅使用合成数据训练，模型对真实场景视频输入仍表现出卓越的泛化能力，为生成高质量可动画三维内容开辟了新途径。项目页面：https://gvfdiffusion.github.io/

（注：根据学术翻译规范，对以下专业术语进行了标准化处理：
1. "Gaussian Splats (GS)"译为"高斯溅射"（计算机图形学标准译法）
2. "Variation Field VAE"译为"变分场自编码器"（保持VAE标准译法）
3. "canonical"译为"规范的"（数学语境标准译法）
4. "in-the-wild"译为"真实场景"（符合计算机视觉领域惯例）
5. 技术名词首次出现时均保留英文缩写并标注中文全称） |
| 主题：通过合成属性替换评估CBM泛化能力的基准研究

（翻译说明：
1. 专业术语处理：
- "CBM"作为专业缩写保留不译，符合学术惯例
- "Benchmarking"译为"基准研究"体现方法论特征
- "Synthetic Attribute Substitutions"译为"合成属性替换"准确传达技术概念

2. 句式重构：
- 将介词结构"via..."转化为中文主动语态"通过..."
- "Generalization"译为"泛化能力"补充隐含的"能力"范畴词

3. 学术规范：
- 标题采用"主题："前缀符合中文论文标题格式
- 使用"评估...能力"的动宾结构保持学术严谨性

4. 术语统一性：
- 与机器学习领域术语体系保持一致，如"泛化能力""合成属性"等表述符合《人工智能术语》国标） | Jessica Bader | [PDF](http://arxiv.org/pdf/2507.23784v1) | 概念瓶颈模型（Concept Bottleneck Models, CBMs）及其他基于概念的可解释模型在提升人工智能应用透明度方面展现出巨大潜力，这对医学等领域至关重要。尽管这些模型已取得成效，但我们研究发现其在数据分布变化时难以可靠识别正确概念。为评估CBMs对概念变化的鲁棒性，我们提出了SUB基准：一个基于CUB数据集构建的精细化图像与概念评估体系，包含38,400张合成图像。该基准通过选取CUB数据集中33种鸟类和45个视觉概念（如翅膀颜色或腹部花纹），生成具有特定概念替换特征的图像。我们创新性地提出"捆绑扩散引导"（Tied Diffusion Guidance, TDG）方法，通过两个并行去噪过程的噪声共享机制，精确控制生成图像同时满足正确鸟类分类与目标属性特征。这一新型基准为CBMs及类似可解释模型提供了严格评估框架，有助于开发更具鲁棒性的方法。相关代码已开源（https://github.com/ExplainableML/sub），数据集发布于http://huggingface.co/datasets/Jessica-bader/SUB。 |
| 《MonoFusion：基于单目融合的稀疏视角4D重建技术》

翻译说明：
1. 技术术语处理：
- "MonoFusion" 保留技术品牌特征不翻译，采用首字母大写形式
- "Sparse-View" 译为专业术语"稀疏视角"（计算机视觉领域标准译法）
- "4D Reconstruction" 译为"4D重建"，其中4D指三维空间+时间维度
- "Monocular" 译为"单目"（计算机视觉中与"双目"对应的标准术语）

2. 句式结构：
- 使用破折号替代英文介词"via"，更符合中文技术文献表达习惯
- 将技术方法(MonoFusion)置于标题首位，后接功能描述，符合中文"先主体后属性"的语序

3. 专业准确性：
- "融合"一词准确对应"Fusion"在三维重建中的技术含义（多源数据融合）
- 完整保留4D重建的时空维度概念，未简化为"三维"

4. 补充说明：
在计算机视觉领域，该标题涉及三个关键技术特征：
1) 单目视觉系统（与立体视觉系统相对）
2) 稀疏视角条件（与密集多视角系统相对）
3) 动态三维重建（4D区别于静态3D重建） | Zihan Wang | [PDF](http://arxiv.org/pdf/2507.23782v1) | 我们致力于解决稀疏视角视频的动态场景重建问题。现有方法通常需要配备数百个校准摄像机的密集多视角采集系统（如Panoptic Studio）。这类多视角设备构建成本极高，且无法在自然场景中捕捉多样化内容。与此相反，我们的目标是通过少量具有完整场景覆盖的稀疏视角摄像机（例如四台等距布置的静态内向摄像机），重建诸如修理自行车或跳舞等动态人体行为。研究发现，由于视角间重叠区域有限，传统密集多视角重建方法难以适配这种稀疏视角配置。为突破这些限制，我们通过精确对齐各摄像机的独立单目重建结果，生成具有时间一致性和视角一致性的动态场景重建。在PanopticStudio和Ego-Exo4D数据集上的大量实验表明，本方法实现了优于现有技术的重建质量，尤其在渲染新视角时表现突出。相关代码、数据及数据处理脚本已发布于https://github.com/ImNotPrepared/MonoFusion。

（注：根据学术翻译规范，对以下术语进行了标准化处理：
1. "in-the-wild"译为"自然场景"符合计算机视觉领域惯例
2. "novel views"译为"新视角"遵循图形学术语
3. 机构名Panoptic Studio保留原名并补充中文说明
4. 技术术语"monocular reconstructions"统一译为"单目重建"
5. 保持被动语态与原文学术风格一致，如"are available"译为"已发布"） |
| 《Phi-Ground技术报告：图形用户界面感知 grounding 技术的突破性进展》

（翻译说明：
1. 专业术语处理：
- "GUI Grounding"译为"图形用户界面感知grounding"，其中grounding保留英文原词并采用斜体标注，符合计算机视觉领域对专业概念的惯用处理方式
- "Perception"译为"感知"而非字面的"知觉"，更符合人机交互领域的术语规范

2. 技术内涵传达：
- "Advancing"译为"突破性进展"而非简单译作"推进"，突出技术突破性
- 通过增译"技术"二字明确报告的技术属性

3. 格式规范：
- 主副标题结构完整保留
- 英文项目名称"Phi-Ground"保持原貌
- 专业术语首次出现时保持中英对照（通过斜体标注）

注：在正式学术出版物中，建议在首次出现"grounding"时添加脚注说明："grounding技术：指将视觉感知与界面元素语义关联的计算机视觉技术"。 | Miaosen Zhang | [PDF](http://arxiv.org/pdf/2507.23779v1) | With the development of multimodal reasoning models, Computer Use Agents
(CUAs), akin to Jarvis from [翻译失败] |
| 半物理仿真：实现支持物理交互的运动学三维人体模型

翻译说明：
1. "Half-Physics"译为"半物理仿真"，既保留了"物理"的核心概念，又通过"半"准确表达了不完全物理仿真的技术特征，符合中文工程术语习惯。
2. "Kinematic 3D Human Model"译为"运动学三维人体模型"，其中：
   - "Kinematic"采用专业术语"运动学"的规范译法
   - 3D保持"三维"的标准表述
   - "Human Model"译为"人体模型"符合生物力学领域术语
3. "Physical Interactions"译为"物理交互"，既准确传达了物理属性交互的本质，又与计算机图形学领域术语体系保持一致。
4. 整体采用"实现支持...的..."句式结构，既忠实原文的"Enabling"动态语义，又符合中文技术文献的表达规范。 | Li Siyao | [PDF](http://arxiv.org/pdf/2507.23778v1) | 当前通用三维人体模型（如SMPL-X）虽能有效表征精确的人体形状与姿态，但由于其运动学特性，无法实现与环境的物理交互。这导致基于运动学的交互模型常出现物体穿透、非真实动力学等问题。为突破这一局限，我们提出创新方法：将SMPL-X模型嵌入可动态感知物理交互的实体中。具体而言，我们设计"半物理"机制，将三维运动学动作转化为物理模拟。该方法在保持对SMPL-X固有姿态运动学控制的同时，确保与场景物体交互的物理合理性，有效消除穿透现象与非真实物体动力学。相较于需要复杂训练的强化学习方法，我们的半物理机制无需学习过程，可泛化至任意体型与动作，且支持实时运算。此外，该方法在无缝融合物理交互的同时，完整保留了原始运动学动作的保真度。

（翻译说明：采用学术文献的严谨表述风格，通过以下处理确保专业性：
1. 专业术语统一："kinematic"译为"运动学"，"physics simulation"译为"物理模拟"
2. 被动语态转化："are represented"译为主动态"表征"
3. 长句拆分：将原文复合句分解为符合中文表达习惯的短句结构
4. 概念准确传达："half-physics mechanism"创造性译为"半物理机制"，既保留原文意象又符合中文术语构词法
5. 逻辑关系显化：通过冒号、分号等标点明确技术方案的层次关系） |
| XSpecMesh：基于多头推测解码的质量保持型自回归网格生成加速方法

（翻译说明：
1. 技术术语处理：
- "Auto-Regressive"译为"自回归"，保留机器学习领域标准译法
- "Speculative Decoding"译为"推测解码"，采用近期NLP论文通用翻译
- "Multi-Head"译为"多头"，遵循Transformer架构术语惯例

2. 创新性表达：
- "Quality-Preserving"译为"质量保持型"，通过"型"字体现技术特性
- "Acceleration"译为"加速方法"而非简单译作"加速"，明确技术方案属性

3. 结构优化：
- 使用冒号替代原标题中的介词结构，符合中文论文标题常见范式
- 通过"基于"明确技术路径，保持学术严谨性

4. 领域适配性：
- "Mesh Generation"统一译为"网格生成"，符合计算机图形学术语
- 整体表述兼顾计算机图形学与机器学习跨领域特性） | Dian Chen | [PDF](http://arxiv.org/pdf/2507.23777v1) | 当前自回归模型虽能生成高质量、拓扑结构精确的网格，但在推理过程中需要进行数千甚至数万次的下一标记预测，导致显著延迟。我们提出XSpecMesh——一种用于自回归网格生成模型的质量保持加速方法。该方法采用轻量级多头推测解码机制，通过单次前向传播并行预测多个标记，从而实现推理加速。我们进一步提出验证与重采样策略：主干模型对每个预测标记进行验证，并对未达质量标准的标记进行重采样。此外，我们设计了一种蒸馏训练策略，通过从主干模型提取知识来训练轻量级解码头，促使二者预测分布对齐，从而提高推测预测的成功率。大量实验表明，本方法在保持生成质量不变的前提下实现了1.7倍的加速效果。相关代码将予以开源。

（注：根据学术翻译规范，对以下术语进行了标准化处理：
1. "auto-regressive"统一译为"自回归"而非"自动回归"
2. "token"译为"标记"而非"令牌/词元"以符合NLP领域惯例
3. "speculative decoding"译为"推测解码"以区别于"投机解码"的通俗译法
4. "backbone model"译为"主干模型"保持神经网络术语一致性
5. 被动语态转换为中文主动句式（如"are verified"→"进行验证"）
（保留技术细节完整性的同时，通过四字格"质量保持""拓扑结构"等提升文本凝练度） |
| 《级联信息揭示机制在问题解决能力泛化评估中的应用》

（翻译说明：
1. 采用学术论文标题惯用的名词化结构
2. "Cascaded"译为"级联"符合控制论/系统工程术语规范
3. "Information Disclosure"译为"信息揭示"比"披露"更契合评估方法论语境
4. "Generalized Evaluation"译为"泛化评估"突出普适性评价特征
5. 补充"机制"二字使中文标题更完整，同时保留原标题的核心要素
6. 使用书名号符合中文期刊标题规范） | Yunxiang Yan | [PDF](http://arxiv.org/pdf/2507.23776v1) | While question-answering~(QA) benchmark performance is an automatic and
scalable method to compare L [翻译失败] |
| SimuRA：基于大语言模型世界模型的模拟推理架构通用目标导向智能体研究

（翻译说明：
1. 采用学术论文标题的规范译法，保留原缩写"SimuRA"作为专有名词
2. "Simulative Reasoning Architecture"译为"模拟推理架构"，准确传达"Simulative"的技术含义
3. "LLM-Based"译为"基于大语言模型"，符合中文人工智能领域术语规范
4. "General Goal-Oriented Agent"译为"通用目标导向智能体"，其中：
   - "General"译为"通用"而非"一般"，强调普适性
   - "Agent"根据上下文译为"智能体"而非"代理"，符合AI领域术语
5. 使用"研究"作为补充动词，使中文标题更完整
6. 整体采用"主标题+副标题"结构，保持学术严谨性） | Mingkai Deng | [PDF](http://arxiv.org/pdf/2507.23773v1) | 基于大语言模型（LLMs）构建的智能体具有巨大潜力，但当前实践仍局限于"单一任务对应单一智能体"的模式，这不仅难以实现扩展性与通用性，还受到自回归大语言模型固有缺陷的制约。相比之下，人类作为通用智能体，能够通过心理模拟来推演行动与计划的可能结果。为构建更通用、更强大的人工智能体，我们提出SimuRA——一种面向目标的通用智能推理架构。该架构基于任何环境中最优智能体的原理化表述，通过引入可进行模拟规划的世界模型，克服了自回归推理的局限性。这个通用世界模型借助大语言模型实现，能充分利用自然语言概念丰富的潜在空间，在多样化环境中进行灵活规划。在复杂的网页浏览任务实验中，SimuRA将航班搜索成功率从0%提升至32.2%。特别值得注意的是，基于世界模型的规划方法相较自回归规划展现出最高达124%的持续优势，印证了世界模型模拟作为推理范式的优越性。我们期待未来能训练出基于大语言模型的单一通用智能体，使其在所有环境中都展现出超智能表现。作为起点，我们已将基于预训练大语言模型的网页浏览智能体SimuRA作为研究演示版开放供公众测试。

（注：根据学术翻译规范，对原文中未定义的\modelname保持技术一致性处理；百分比数据采用中文排版规范；专业术语如"autoregressive"译为"自回归"；长句按中文表达习惯进行合理切分；被动语态转换为主动表述；保留了技术缩写的首次全称标注） |
| SeqAffordSplat：基于3D高斯泼溅的场景级序列可供性推理

（翻译说明：
1. 专业术语处理：
- "3D Gaussian Splatting"译为"3D高斯泼溅"，这是计算机图形学领域的标准译法
- "Affordance"译为"可供性"，这是人机交互与认知科学领域的规范学术译名
- "Sequential Reasoning"译为"序列推理"，准确表达时序推理含义

2. 技术内涵体现：
- 完整保留"SeqAffordSplat"这个技术命名缩写
- "Scene-level"译为"场景级"以区分于对象级分析
- 使用破折号连接技术名称与说明，符合中文技术文献表述习惯

3. 句式结构调整：
- 将英文介词结构"on..."转换为中文前置定语"基于..."
- 保持"可供性推理"这个核心术语的完整性
- 整体采用"技术名称：技术特征"的标准学术标题格式） | Di Li | [PDF](http://arxiv.org/pdf/2507.23772v1) | 三维功能推理（3D affordance reasoning）——将人类指令与三维物体的功能区域相关联的任务——是具身智能体的一项核心能力。现有基于3D高斯泼溅（3DGS）的方法本质上局限于单物体、单步骤的交互范式，难以满足复杂现实应用中长时程、多物体任务的需求。为填补这一空白，我们提出了"序列化三维高斯功能推理"这一新任务，并构建了包含1800+场景的大规模基准测试集SeqAffordSplat，以支持复杂3DGS环境下的长时程功能理解研究。我们继而提出SeqSplatNet端到端框架，可直接将指令映射为三维功能掩码序列。该框架采用自回归生成文本的大型语言模型，通过交错生成特殊分割标记来引导条件解码器输出对应的三维掩码。针对复杂场景几何，我们提出"条件几何重建"预训练策略，使模型能够从已知几何观测中重建完整功能区域掩码，从而构建强健的几何先验。此外，为消除语义歧义，我们设计了特征注入机制，将二维视觉基础模型（VFM）提取的丰富语义特征提升至三维空间，并以多尺度方式融合到三维解码器中。大量实验表明，我们的方法在挑战性测试集上实现了最先进的性能，成功将功能推理从单步交互推进到场景级的复杂序列任务。 |
| 共识驱动的主动模型选择

翻译说明：
1. "Consensus-Driven"译为"共识驱动的"，准确传达了通过群体共识来引导决策过程的含义
2. "Active Model Selection"译为"主动模型选择"，符合机器学习领域对主动学习(active learning)和模型选择(model selection)的标准译法
3. 整个术语采用技术文献常见的名词化处理方式，保持学术文本的简洁性
4. 使用连接号"的"形成复合术语，符合中文科技术语的构词规范
5. 该译法在机器学习领域具有明确指代性，指代通过共识机制主动选择最优模型的方法论 | Justin Kay | [PDF](http://arxiv.org/pdf/2507.23771v1) | 现成机器学习模型的广泛普及带来一个关键挑战：面对众多可选模型，如何为特定数据分析任务选择最优方案？传统的模型选择方法需要收集并标注验证数据集——这一过程成本高昂且耗时费力。我们提出了一种主动模型选择方法（CODA），通过利用候选模型的预测结果来优先标注那些能高效区分最优模型的数据点。该方法基于概率框架建立分类器、类别与数据点之间的关联，采用共识驱动策略实现主动模型选择：利用候选模型间的共识与分歧指导标签获取过程，并通过贝叶斯推理在信息积累过程中持续更新对最优模型的判断。

为验证方法有效性，我们构建了包含26个基准测试任务的数据集，覆盖多种模型选择场景。实验表明，CODA在主动模型选择方面显著优于现有方法——相较于之前的最优技术，发现最佳模型所需的标注工作量减少了70%以上。相关代码与数据已开源：https://github.com/justinkay/coda。

（注：根据学术翻译规范，关键术语处理如下：
1. "off-the-shelf"译为"现成"而非字面意义的"货架"，更符合中文技术语境
2. "active model selection"统一译为"主动模型选择"，保持术语一致性
3. "consensus-driven"译为"共识驱动"，准确传达方法论特征
4. 长难句进行合理切分，如将原文最后两句合并为实验结论的对比陈述，符合中文论述习惯
5. 技术指标"70%"保留数字形式，确保数据精确性） |
