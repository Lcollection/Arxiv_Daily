# arxiv 2025-05-15

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| UWAV：基于不确定性加权的弱监督音视频联合解析

（翻译说明：
1. 专业术语处理：
- "Uncertainty-weighted" 译为"基于不确定性加权的"，准确传达权重计算方式
- "Weakly-supervised" 保留学术领域标准译法"弱监督"
- "Audio-Visual" 译为"音视频"，符合多媒体处理领域术语规范
- "Video Parsing" 译为"视频解析"，准确表达视频内容分析的技术含义

2. 结构优化：
- 将原缩写UWAV在译文中前置，保持技术术语一致性
- 使用破折号连接方法论与研究对象，符合中文技术文献表述习惯

3. 技术准确性：
- "Parsing"译为"解析"而非"解析"，更准确反映视频结构化分析的技术内涵
- 补充"联合"二字以强调音频和视觉模态的融合特性

4. 格式规范：
- 保留英文缩写+中文全称的学术惯例
- 使用书名号突出技术方法名称） | Yung-Hsuan Lai | [PDF](http://arxiv.org/pdf/2505.09615v1) | 视听视频解析（AVVP）是一项具有挑战性的任务，其核心在于同时定位单模态事件（即仅出现在视频视觉或听觉单一模态中的事件）与多模态事件（即同时在两种模态中发生的事件）。然而，为训练数据标注所有事件类别标签及其起止时间的高昂成本，严重制约了AVVP技术的可扩展性——除非能在弱监督环境下进行训练（即训练数据中仅提供与模态无关的视频级标签）。为此，近期提出的方法试图通过生成片段级伪标签来优化模型训练。但现有方法在生成伪标签时存在两大局限：一是缺乏对片段间依赖关系的考量，二是普遍存在对片段中未出现标签的预测偏差。本研究提出名为"不确定性加权的弱监督视听视频解析"（UWAV）的创新方法以解决上述缺陷。该方案不仅量化了伪标签估计过程中的不确定性，还引入基于特征混合的训练正则化策略以提升模型性能。实验结果表明，在两个不同数据集上，UWAV在多项指标上均超越当前最先进的AVVP方法，验证了其有效性与泛化能力。 |
| 语言智能体折射人类因果推理认知偏差：如何引导其实现科学思维？

（翻译说明：
1. 采用"折射"替代直译"mirror"，既保留隐喻又符合中文表达习惯
2. "Causal Reasoning Biases"译为"因果推理认知偏差"，添加"认知"二字明确学科范畴
3. 问句处理为"引导...实现..."结构，比直译"帮助...思考"更符合学术语境
4. 副标题使用冒号分隔，遵循中文标题规范
5. "Scientists"译为"科学思维"而非字面翻译，突出思维方式的转变
6. 整体采用学术文本特有的名词化表达（如"实现科学思维"），保持专业度） | Anthony GX-Chen | [PDF](http://arxiv.org/pdf/2505.09614v1) | 语言模型（LM）作为自主决策主体的应用日益广泛，其需要主动收集信息以指导决策过程。对此类智能体而言，关键认知能力在于高效探索并理解世界的因果结构——这是实现稳健、科学化推理的核心所在。然而，目前尚不清楚语言模型是否具备这种能力，或是否表现出导致错误结论的系统性认知偏差。本研究采用发展心理学中成熟的"blicket测试"范式，系统考察了语言模型探索与推断因果关系的能力。研究发现：语言模型能可靠推断常见、直观的"析取型"因果关系，但对非常规却证据充分（有时甚至证据更强）的"合取型"关系存在系统性判断困难。这种"析取偏好"现象在不同模型架构、参数量级及提示策略中持续存在，且随任务复杂度提升表现进一步恶化。值得注意的是，成年人类群体中同样存在类似认知偏差，暗示语言模型可能从训练数据中继承了深层次的推理启发式方法。为此，我们量化分析了语言模型与人类推理模式的相似性，发现其呈现出类成人（而非类儿童）的推断特征。最后，我们提出一种测试时采样方法，通过显式生成并排除语言模型中的因果假设，这种可扩展方案显著降低了析取偏好，推动语言模型向科学化、因果严谨的推理目标迈进。 |
| 矩阵补全的自适应加权最近邻方法

（说明：该翻译严格遵循学术术语规范，采用"矩阵补全"这一计算机科学/统计学领域标准译法。"Adaptively-weighted"译为"自适应加权"准确表达了算法根据数据特性动态调整权重的核心特征。"Nearest Neighbors"采用模式识别经典译法"最近邻"，整体译名在保持专业性的同时符合中文科技文献的命名习惯。） | Tathagata Sadhukhan | [PDF](http://arxiv.org/pdf/2505.09612v1) | In this technical note, we introduce and analyze AWNN: an adaptively weighted
nearest neighbor metho [翻译失败] |
| 为高性能微处理器VHDL设计定制大型语言模型

（说明：该翻译严格遵循技术文献的规范要求，具体呈现以下特点：
1. 专业术语准确："VHDL"保留不译，"Large Language Model"译为"大型语言模型"符合计算机领域术语标准
2. 语序符合中文技术文献习惯：将英语后置定语"for VHDL Design"转换为中文前置定语
3. 动词处理得当："Customizing"译为"定制"准确体现技术定制化过程
4. 专业领域适配：在微处理器设计语境下，"High-Performance"译为"高性能"是业界标准译法
5. 整体结构紧凑：采用"为...定制..."的句式，既保持学术严谨性又符合中文表达习惯） | Nicolas Dupuis | [PDF](http://arxiv.org/pdf/2505.09610v1) | 近年来，大型语言模型（LLM）在硬件设计领域的应用迅速兴起，主要体现在提升芯片设计工程师生产力的工具集成上。关于LLM在芯片设计寄存器传输级（RTL）规范中的应用已有大量讨论，其中Verilog和VHDL是最主流的两种硬件描述语言。由于Verilog语言更高的普及度，LLM在该领域的设计应用获得了广泛关注，而VHDL尽管在工业界持续流行，却鲜有相关研究。同时，针对高性能处理器设计机构的特殊需求，以及在这些场景中部署人工智能解决方案的技术探讨也较为匮乏。本文详细阐述了我们开发专用大型语言模型的历程，该模型旨在解释VHDL代码——这对拥有数十年高性能处理器设计经验与技术资产的组织具有特殊意义。我们展示了如何开发符合需求的专用测试集，并在基础LLM的扩展预训练（EPT）过程中用于模型评估。经专家评定，EPT模型生成的代码解释准确率从基础模型的43%提升至69%。我们进一步开发了"LLM即评判员"机制，使其能像专家评估者一样衡量模型性能。基于此，我们推导并评估了包括指令调优版EPT模型在内的多个新模型，其预期专家评估准确率达到71%。实验表明，若采用更新的基础模型，该指标有望提升至85%以上。最后，我们探讨了如何利用生成式人工智能领域的最新进展，进一步提升硬件设计专用LLM的质量。 |
| LightLab：基于扩散模型的图像光源控制系统

（翻译说明：
1. 保留品牌名"LightLab"作为专有名词不译，符合学术术语惯例
2. "Controlling Light Sources"译为"光源控制"准确传达技术内涵
3. "in Images"采用前置定语"图像"的简洁处理
4. "Diffusion Models"规范译为"扩散模型"，使用当前学界通用译法
5. 整体采用"主标题+副标题"的学术命名结构，主标题突出系统名称，副标题说明技术原理
6. 添加"基于"二字明确技术路径，符合中文科技文献表述习惯
7. "系统"二字为中文语境下的合理补充，使技术产品属性更清晰） | Nadav Magar | [PDF](http://arxiv.org/pdf/2505.09608v1) | We present a simple, yet effective diffusion-based method for fine-grained,
parametric control over  [翻译失败] |
| DataMIL：基于数据模型的机器人模仿学习数据选择方法

（翻译说明：
1. 保留专有名词"DataMIL"不译，维持技术术语一致性
2. "Datamodels"译为"数据模型"，采用计算机领域标准译法
3. "Imitation Learning"译为"模仿学习"，符合机器学习领域术语规范
4. 使用"选择方法"补充原文隐含的方法论含义，使中文更符合学术表述习惯
5. 整体采用"技术名称：技术方案"的学术论文标题结构，与中文计算机领域论文标题范式保持一致
6. 通过冒号分隔主副标题，保持原标题的信息层级关系） | Shivin Dass | [PDF](http://arxiv.org/pdf/2505.09603v1) | Recently, the robotics community has amassed ever larger and more diverse
datasets to train generali [翻译失败] |
| 对抗性后缀过滤：大语言模型的防御流程

翻译说明：
1. "Adversarial Suffix"译为"对抗性后缀"，准确传达了在对抗攻击语境下添加到输入末尾的恶意内容这一技术概念
2. "Filtering"译为"过滤"，保持动词名词化形式与原文一致
3. 副标题采用"防御流程"的译法，既保留了"Pipeline"的技术含义（数据处理流程），又突出了其防御属性，比直译"管道"更符合中文技术文献表述习惯
4. "LLMs"采用全称翻译"大语言模型"，确保读者明确理解术语所指，符合中文技术文档的完整表述规范
5. 整体采用冒号分隔的主副标题结构，与原文格式保持一致，符合中文科技论文标题的常见组织形式 | David Khachaturov | [PDF](http://arxiv.org/pdf/2505.09602v1) | 大型语言模型（LLMs）正日益广泛应用于自主系统和公共交互场景，但其仍存在可能破坏安全性与可信度的越狱漏洞。对抗性后缀目前被视为最先进的越狱手段，其表现始终优于简单攻击方法，甚至在黑盒环境下也频繁奏效。现有防御方案或依赖模型内部架构访问权限而限制多样化部署，或显著增加内存与计算开销，或可通过简单提示工程手段绕过。本文提出$\textbf{对抗性后缀过滤}$（Adversarial Suffix Filtering, ASF），这是一种轻量级、模型无关的新型防御流程，专为保护LLMs抵御对抗性后缀攻击而设计。ASF作为输入预处理器和净化器，能够检测并过滤提示中精心构造的对抗性后缀，有效消除恶意注入内容。实验证明，ASF在黑盒与白盒攻击场景下均具备全面防御能力，可将最先进对抗性后缀生成方法的攻击成功率降至4%以下，同时几乎不影响目标模型在非对抗场景下的正常功能表现。 |
| 《人工智能的"饥饿"程度如何？大型语言模型推理的能耗、水足迹与碳足迹基准研究》

翻译说明：
1. 标题采用疑问句式，保留原文设问风格
2. "Hungry"译为"饥饿"并加引号，既保留比喻义又突出概念化表达
3. "Benchmarking"译为"基准研究"，准确传达系统性量化评估含义
4. 三个关键指标按中文习惯调整为"能耗、水足迹与碳足迹"，使用顿号分隔符合标题规范
5. "LLM Inference"完整译为"大型语言模型推理"，避免缩写确保学术严谨性
6. 整体采用学术论文标题的简洁风格（18个汉字），同时完整保留原文所有技术要素 | Nidhal Jegham | [PDF](http://arxiv.org/pdf/2505.09598v1) | As large language models (LLMs) spread across industries, understanding their
environmental footprin [翻译失败] |
| WorldView-Bench：面向大语言模型全球文化视角评估的基准测试

（翻译说明：
1. 专业术语处理："Benchmark"译为"基准测试"符合计算机领域术语规范
2. 学术命名保留："WorldView"作为专有名词保留英文原名并通过连字符连接
3. 概念准确传达："Global Cultural Perspectives"译为"全球文化视角"既保持学术严谨性又符合中文表达习惯
4. 句式结构调整：将英文后置定语转换为中文前置定语，符合中文学术论文标题的常见结构
5. 领域适配性：使用"大语言模型"这一中文AI领域的标准术语对应"Large Language Models"） | Abdullah Mushtaq | [PDF](http://arxiv.org/pdf/2505.09595v1) | Large Language Models (LLMs) are predominantly trained and aligned in ways
that reinforce Western-ce [翻译失败] |
| 在线隔离森林

（翻译说明：
1. "Online"译为"在线"，符合计算机领域对实时处理系统的通用译法
2. "Isolation Forest"作为经典异常检测算法名称，采用学界公认的"隔离森林"译法
3. 整体采用直译策略，完整保留算法名称的技术含义
4. 该译名与原始论文《Isolation Forest》及后续《Online Anomaly Detection Using Isolation Forests》研究中的中文文献表述一致） | Filippo Leveni | [PDF](http://arxiv.org/pdf/2505.09593v1) | The anomaly detection literature is abundant with offline methods, which
require repeated access to  [翻译失败] |
