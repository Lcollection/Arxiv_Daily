# arxiv 2025-11-27

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 重探不同难度水平下的泛化能力：并非易事 | Yeganeh Kordi | [PDF](https://arxiv.org/pdf/2511.21692v1) | 我们研究大型语言模型（LLM）在不同任务难度间的泛化能力，这是影响数据筛选与评估效果的核心问题。现有研究对“使用简单或困难数据训练能否获得更优结果”以及“性能提升体现在简单还是困难测试数据上”等问题尚未达成共识。为解决这一争议，我们通过系统化评估方法，从模型架构、数据集和样本难度细分组别三个维度探究LLMs的泛化表现。基于数千种不同LLMs的输出结果并结合教育测试领域的成熟难度度量标准——项目反应理论（IRT），我们对六个数据集中的样本进行了难度分级。与既往研究不同，我们的难度评级完全基于多种LLMs的自身能力，排除了人类对难度的主观判断。通过更客观、大规模且细粒度的分析，我们证明跨难度泛化能力往往存在局限：仅使用简单或困难数据进行训练，均无法在全部难度范围内实现持续性能提升。这些结果表明，在LLMs的训练与评估数据中保持难度多样性至关重要，任何在难度维度上走捷径的做法都存在风险。 |
| 画布到图像：基于多模态控制的组合式图像生成 | Yusuf Dalva | [PDF](https://arxiv.org/pdf/2511.21691v1) | 尽管现代扩散模型在生成高质量多样化图像方面表现出色，但在实现高保真度的组合式与多模态控制方面仍存在困难——特别是当用户需要同时指定文本提示、主体参照、空间排布、姿态约束和布局标注时。我们提出“画布到图像”统一框架，将这些异构控制要素整合至单一画布界面，使用户能够生成精准反映创作意图的图像。核心创新在于将多样化控制信号编码为复合画布图像，使模型能够直接进行视觉空间推理。我们进一步构建了多任务数据集，并提出多任务画布训练策略，通过统一学习范式优化扩散模型对异构控制信号的理解与整合能力。这种联合训练使模型能够跨越多重控制模态进行推理，而非依赖特定任务启发式方法，并在推理阶段展现出对多控制场景的优异泛化能力。大量实验表明，在多人组合、姿态控制合成、布局约束生成及多控制生成等挑战性基准测试中，Canvas-to-Image在身份保持与控制遵循度方面显著优于现有前沿方法。 |
| TraceGen：三维轨迹空间中的世界建模实现跨具身视频学习

（解析：1. "TraceGen"作为专有名词保留不译；2. "World Modeling"译为"世界建模"符合计算机视觉领域术语规范；3. "3D Trace Space"译为"三维轨迹空间"准确体现三维运动轨迹的数学空间概念；4. "Cross-Embodiment"译为"跨具身"精准传达不同物理实体形态的核心含义，符合机器人学与强化学习领域的术语使用习惯；5. 整体采用"主标题：副标题"的学术论文标题标准格式，确保专业性与可读性的统一） | Seungjae Lee | [PDF](https://arxiv.org/pdf/2511.21690v1) | 仅通过少量演示就能在新平台和新场景中学习新机器人任务仍具挑战性。虽然人类和其他机器人的演示视频资源丰富，但形态差异、摄像头配置及环境变化阻碍了这些视频的直接应用。我们通过引入统一的符号化表征——场景级轨迹的紧凑三维"迹空间"，实现了跨形态、跨环境、跨任务视频的学习，从而解决小数据量难题。我们提出TraceGen世界模型，该模型在迹空间而非像素空间预测未来运动，在保留操作所需几何结构的同时抽象掉外观特征。为大规模训练TraceGen，我们开发了TraceForge数据流水线，将异构的人类与机器人视频转化为统一的三维轨迹，构建包含12.3万条视频和180万个观察-轨迹-语言三元组的数据集。基于该数据集的预训练产生了可迁移的三维运动先验模型，仅需五段目标机器人视频即可实现高效适应：在四项任务中达到80%的成功率，同时推理速度比基于视频的先进世界模型快50-600倍。在更具挑战性的场景中，仅使用手机拍摄的五段未标定人类演示视频，该模型在真实机器人上仍能达到67.5%的成功率，这彰显了TraceGen在不依赖物体检测器或繁重像素空间生成的情况下实现跨形态适应的能力。 |
| 工具交响曲：通过高效模型与工具编排提升智能水平 | Hongjin Su | [PDF](https://arxiv.org/pdf/2511.21689v1) | 大型语言模型是强大的通用系统，但在解决诸如"人类终极考试"（HLE）这类深度复杂问题时，仍面临概念性挑战与高昂计算成本。我们证明，通过小型调度器管理其他模型及多样化工具，既能突破智能水平上限，又能提升复杂智能体任务的解决效率。本文提出ToolOrchestra——一种训练小型调度器协调智能工具的方法。该方法明确采用融合结果感知、效率感知和用户偏好的强化学习奖励机制。基于此，我们开发出Orchestrator模型（80亿参数），该模型在保证更高准确率的同时，较以往工具使用智能体显著降低成本，并能根据用户偏好匹配查询任务的最佳工具。在HLE测试中，Orchestrator以37.1%的得分超越GPT-5（35.1%），且效率提升2.5倍。在tau2-Bench和FRAMES基准测试中，该模型以约30%的成本实现对GPT-5的显著超越。深入分析表明，Orchestrator在多项指标下实现了性能与成本的最佳平衡，并对未见工具展现出强大泛化能力。这些结果证明，通过轻量级调度模型整合多样化工具，比现有方法更具效率与效能，为构建实用可扩展的工具增强推理系统开辟了新路径。 |
| G$^2$VLM：基于几何基础的视觉语言模型——融合统一三维重建与空间推理能力

（注：译文通过"几何基础"对应"Geometry Grounded"的学术内涵，"融合统一"体现"Unified"的技术特性，完整保留专业术语"三维重建"与"空间推理"，并通过破折号构建符合中文论文标题的递进式结构） | Wenbo Hu | [PDF](https://arxiv.org/pdf/2511.21688v1) | 视觉语言模型（VLMs）在空间智能方面仍缺乏鲁棒性，在空间理解与推理任务中表现不佳。我们认为这一缺陷源于缺乏能够从二维图像重建三维空间的视觉几何学习过程。本文提出G$^2$VLM——一个基于几何建模的视觉语言模型，该模型融合了空间智能的两个核心维度：三维空间重建与空间语义理解。G$^2$VLM通过原生调用习得的3D视觉几何特征，既能直接预测三维属性，又能借助上下文学习与交叉推理增强空间推理任务。我们的统一架构在空间理解方面具有高度扩展性：既能利用海量多视角图像和视频数据进行训练，又可获得通常仅能通过难以采集的标注数据才能构建的3D视觉先验优势。实验结果表明，G$^2$VLM在双重任务中均表现优异，其三维重建效果可比肩最先进的前馈式三维重建模型，在空间理解与推理任务中取得领先或具有竞争力的成绩。通过将强语义视觉语言模型与底层三维视觉任务相融合，我们希望G$^2$VLM能成为该领域的强基准，并为三维场景编辑等未来应用开启更多可能性。 |
| 矩阵：点对点多智能体合成数据生成框架 | Dong Wang | [PDF](https://arxiv.org/pdf/2511.21686v1) | 合成数据对于训练大语言模型已变得日益重要，尤其在真实数据稀缺、成本高昂或涉及隐私敏感的场景中。此类生成任务通常需要协调的多智能体工作流，通过专业化智能体的协作来生成质量更高、多样性更强且结构更丰富的数据。然而，现有多智能体合成框架往往依赖中心化编排器，导致可扩展性瓶颈，或是为特定领域硬编码设计，限制了灵活性。我们提出\textbf{Matrix}——一个去中心化框架，将控制流与数据流统一表征为通过分布式队列传递的序列化消息。这种点对点设计消除了中心编排器，每个任务通过轻量级智能体独立推进，而计算密集型操作（如LLM推理或容器化环境）则由分布式服务处理。基于Ray构建的Matrix可扩展至数万个并发智能体工作流，其模块化可配置设计能轻松适配各类数据生成流程。我们在多智能体协作对话、基于网页的推理数据提取、客服场景中的工具使用轨迹生成等多样化合成场景中对Matrix进行评估。在所有案例中，Matrix在相同硬件资源下实现了数据生成吞吐量$2$--$15$倍的提升，且未牺牲输出质量。 |
| 无像素视觉：基于相机轨迹的感知 | Zihui Xue | [PDF](https://arxiv.org/pdf/2511.21681v1) | 能否仅凭相机运动轨迹——即其在空间中划过的路径，而非观察像素信息，就能感知视频内容？本文首次系统性地探讨这个看似不可能的问题。为此，我们提出一种对比学习框架，用以训练专有的编码器CamFormer，该模型将相机位姿轨迹映射到联合嵌入空间，使其与自然语言描述对齐。研究发现，尽管相机轨迹看似简单，实则是揭示视频内容的高度信息化信号。换言之，“如何移动”确实能揭示“正在做什么”（第一人称视角）或“观察什么”（第三人称视角）。我们通过跨模态对齐、分类与时序分析等多样化下游任务，验证了CamFormer嵌入向量的通用性。值得注意的是，我们的表征方法对不同的相机位姿估计策略均具有鲁棒性，既适用于高精度多传感器方案，也兼容标准纯RGB估计器。本研究确立了相机轨迹作为一种轻量化、强鲁棒性且多功能的视频内容感知模态。 |
| 具有成长与精炼多模态语义记忆的自主学习者

解析：
1. "Agentic Learner" 译为"自主学习者"，强调学习主体具有自主性和能动性
2. "Grow-and-Refine" 采用"成长与精炼"的译法，准确传达动态发展过程
3. "Multimodal Semantic Memory" 译为"多模态语义记忆"，保持专业术语的准确性
4. 整体采用偏正结构，符合中文科技文献的命名规范，既保持专业性的同时确保语言流畅自然 | Weihao Bo | [PDF](https://arxiv.org/pdf/2511.21678v1) | 多模态大语言模型在独立查询中展现出强大的推理能力，但其运作始终处于零起点状态——每个问题都需独立求解，且常会重复相同错误。现有记忆增强型智能体主要存储过往轨迹以供复用，然而基于轨迹的记忆存在简略性偏差，会逐渐丢失关键领域知识。更严重的是，即使在真正的多模态问题解决场景中，此类系统仅记录单模态的行为轨迹，未能保留视觉注意力与逻辑推理如何协同促成解决方案。这种机制与人类认知存在根本性错位：语义记忆具有多模态与整合性特质，通过协调而独立的表征流同时保存视觉与抽象知识。为此我们提出ViLoMem双流记忆框架，构建基于图式的紧凑记忆系统。该框架分别编码视觉分心模式与逻辑推理错误，使多模态大语言模型能从成败经验中学习。遵循生长-精炼原则，系统持续积累并更新多模态语义知识——在保持稳定可泛化策略的同时避免灾难性遗忘。在六大多模态基准测试中，ViLoMem持续提升pass@1准确率，并显著减少重复出现的视觉与逻辑错误。消融实验证实了具有显式分心-幻觉分离的双流记忆的必要性，彰显了错误感知型多模态记忆在终身学习与跨域智能体学习中的价值。项目页面详见https://weihao-bo.github.io/ViLoMeo-page。 |
| 基于演化模型的干扰下实验研究 | Sadegh Shirani | [PDF](https://arxiv.org/pdf/2511.21675v1) | 网络系统中的因果效应估计是数据驱动决策的核心问题。在此类场景中，对单个单元实施的干预可能产生溢出效应，而在复杂的物理或社会系统中，驱动这些干扰结构的交互路径大多不可观测。我们认为，要识别群体层面的因果效应，无需还原精确的网络结构；相反，只要刻画这些交互如何影响结果演化即可。基于此原理，我们研究一种基于演化的方法：通过观察多轮实验中干预措施如何引致结果变化，从而弥补缺失的网络信息。借助暴露映射视角，我们给出结果的经验分布遵循低维递归方程的公理化特征，并确定此类演化映射存在所需的最小结构条件。这可视作双重差分法的分布形态对应物——该方法不假设个体单元具有平行路径，而是利用不同处理情境间的平行演化模式来估计反事实轨迹。关键洞见在于：随机化处理除消除潜在混杂因素外，还能通过对隐式干扰通道的隐含抽样，实现异质溢出效应的一致性学习。我们提出因果消息传递作为该方法在稠密网络中的具体实现，并将其扩展至更普遍的干扰结构（包括少数单元主导多数溢出效应的意见领袖网络）。最后我们讨论了该方法的局限性，指出强烈的时间趋势或内生性干扰可能破坏识别效果。 |
| 大型稀疏网络中的事件驱动资格传播：生物现实性塑造的效率

（该翻译在保持专业术语准确性的基础上，采用符合中文计算机科学/神经科学领域论文标题的表述习惯，通过冒号分隔主副标题结构，其中：
1. "Event-driven"译为"事件驱动"符合计算机领域术语规范
2. "Eligibility propagation"译为"资格传播"对应神经网络学习机制术语
3. "Biological realism"译为"生物现实性"体现神经科学领域对生物可信度的强调
4. 主谓结构"efficiency shaped by"转化为"塑造的效率"符合中文标题名词化表达习惯） | Agnes Korcsak-Gorzo | [PDF](https://arxiv.org/pdf/2511.21674v1) | 尽管技术已取得显著进步，人工智能系统仍可从生物原理中获益，例如循环连接结构与高能效机制。受大脑运作机制启发，我们提出一种具有生物合理性的扩展型合格信号传播学习规则，适用于脉冲循环神经网络。通过将时间驱动更新机制转化为事件驱动模式，我们将该学习规则整合至大规模脉冲神经网络仿真平台，并验证其在神经形态MNIST等任务中的适用性。我们通过引入连续动力学与权重更新、严格局部性以及稀疏连接等典型生物特征来扩展该模型。研究结果表明，基于生物学的约束条件可为设计计算高效的人工智能算法提供指导，在保持学习性能的同时实现百万级神经元的可扩展性。这项工作在机器学习与计算神经科学之间架起桥梁，不仅推动了对类脑学习机制的理解，更为开发可持续的生物启发式人工智能系统开辟了新路径。 |
