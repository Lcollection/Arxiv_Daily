# arxiv 2025-07-10

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 迈向多模态理解：以稳定扩散作为任务感知特征提取器

（说明：该翻译严格遵循学术论文标题的规范要求，具体处理如下：
1. "Towards"译为"迈向"符合中文论文标题惯用开场词
2. "Multimodal Understanding"译为"多模态理解"采用计算机视觉领域标准术语
3. "Stable Diffusion"保留技术名称"稳定扩散"的既定译法
4. "Task-Aware Feature Extractor"译为"任务感知特征提取器"准确传达其技术内涵
5. 冒号替代原介词"via"实现中英文标题结构的等效转换
6. 整体采用学术标题常见的名词短语结构，去除英文冠词等冗余成分） | Vatsal Agarwal | [PDF](http://arxiv.org/pdf/2507.07106v1) | 多模态大语言模型（MLLMs）的最新进展已实现基于图像的问答能力。然而，其核心局限在于采用CLIP作为视觉编码器——虽然能捕捉粗略的全局信息，但往往会遗漏与输入查询相关的细粒度细节。为突破这一限制，本研究探索预训练文生图扩散模型是否可作为指令感知的视觉编码器。通过分析其内部表征，我们发现扩散特征不仅语义丰富，还能编码强图像-文本对齐关系。更重要的是，可利用文本条件机制使模型聚焦于与问题相关的图像区域。

随后，我们研究如何将这些特征与大语言模型对齐，并发现存在信息泄漏现象：大语言模型可能无意间还原原始扩散提示信息。我们深入分析泄漏成因并提出缓解策略。基于这些发现，我们设计了一种融合CLIP与条件扩散特征的简单策略。在通用视觉问答（VQA）和专用MLLM基准测试上的实验表明，扩散模型在视觉理解领域（尤其是需要空间与组合推理的视觉中心任务）具有显著优势。项目页面详见https://vatsalag99.github.io/mustafar/。

（注：根据学术翻译规范，对以下术语进行标准化处理：
1. "instruction-aware"译为"指令感知"（人机交互领域标准译法）
2. "leakage phenomenon"译为"信息泄漏现象"（信息安全领域术语）
3. "vision-centric tasks"译为"视觉中心任务"（计算机视觉领域通用表述）
4. 保留CLIP/VQA等专业缩写以符合领域惯例） |
| 4K智能体：任意图像至4K超分辨率的代理增强系统

（翻译说明：
1. 保留专业术语"Agent"的学术规范译法"智能体"，体现人工智能领域特性
2. "Agentic"译为"代理增强"，准确传达原词"具有代理能力"的技术内涵
3. 采用"超分辨率"标准学术译法，避免直译"super-resolution"为"超级分辨率"
4. 使用中文技术文档惯用的"至"替代简单介词"to"，更符合学术表达规范
5. 保持技术命名完整性，通过冒号分隔主副标题，与英文原格式严格对应
6. 整体译文在保持专业性的同时，通过"系统"的补充使技术概念更完整） | Yushen Zuo | [PDF](http://arxiv.org/pdf/2507.07105v1) | We present 4KAgent, a unified agentic super-resolution generalist system
designed to universally ups [翻译失败] |
| 视觉-语言-视觉自动编码器：基于扩散模型的可扩展知识蒸馏

（翻译说明：
1. 采用连字符直译"Vision-Language-Vision"结构，保留技术术语原貌
2. "Auto-Encoder"译为专业术语"自动编码器"
3. "Scalable Knowledge Distillation"采用计算机领域通用译法"可扩展知识蒸馏"
4. "Diffusion Models"使用当前学术圈标准译名"扩散模型"
5. 整体保持学术论文标题的简洁性，通过冒号分层体现主副标题关系
6. 使用"基于"的介词结构准确传达技术方法的从属关系） | Tiezheng Zhang | [PDF](http://arxiv.org/pdf/2507.07104v1) | Building state-of-the-art Vision-Language Models (VLMs) with strong
captioning capabilities typicall [翻译失败] |
| 数据标准化是否会导致视觉组合泛化能力的提升？

（翻译说明：
1. "Data Scaling"译为"数据标准化"，这是机器学习领域对数据进行归一化/标准化处理的通用译法
2. "Visual Compositional Generalization"译为"视觉组合泛化能力"，其中：
   - "compositional"译为"组合"，指模型组合已知概念理解新场景的能力
   - "generalization"译为"泛化能力"，是机器学习标准术语
3. 采用疑问句式完整保留原文的研究问题形式
4. 通过"是否"的措辞准确传达原文探讨因果关系的学术意图
5. 整体符合中文科技论文标题简洁明确的表达规范） | Arnas Uselis | [PDF](http://arxiv.org/pdf/2507.07102v1) | Compositional understanding is crucial for human intelligence, yet it remains
unclear whether contem [翻译失败] |
| 语言模型的小批量训练：普通SGD何时有效及梯度累积为何低效

（翻译说明：
1. 专业术语处理："Vanilla SGD"译为"普通SGD"（保留专业缩写），"Gradient Accumulation"译为"梯度累积"（计算机领域标准译法）
2. 句式重构：将原文疑问句式转换为陈述句式以符合中文标题规范，通过冒号分层保持学术标题的层次性
3. 概念显化："Works"译为"有效"而非字面的"工作"，"Wasteful"译为"低效"以准确传达计算资源浪费的隐含语义
4. 被动语态转换：英文被动结构转换为中文主动表达（如"why...is wasteful"处理为"为何...低效"）
5. 术语统一性：保持"Language Models"、"SGD"等术语在全文中译法的一致性） | Martin Marek | [PDF](http://arxiv.org/pdf/2507.07101v1) | 传统观点认为，小批量训练会导致语言模型预训练和微调过程不稳定，因此需要采用梯度累积技术——通过成比例增加批量大小来减少优化器更新次数。虽然通常会针对较小批量降低学习率，但其他超参数往往保持固定。本研究重新审视了低至批量大小为1的小批量训练，并提出了一套适用于Adam优化器的小批量超参数缩放规则。我们发现小批量训练具有以下优势：(1) 训练过程稳定；(2) 对超参数选择具有更强的鲁棒性；(3) 单位计算量下的性能表现不逊于甚至优于大批量训练；(4) 尤其值得注意的是，即使不存储优化器状态，也能实现基于普通SGD（无需动量项）的稳定语言模型训练。基于这些发现，我们提出了批量大小选择和优化器超参数设置的实用建议。我们进一步建议：除非在多设备并行训练（受限于设备间通信带宽）且需要维护多个模型副本的情况下，否则应避免使用梯度累积技术。

（注：翻译过程中严格遵循以下技术要点：
1. "gradient accumulation"译为专业术语"梯度累积"
2. "vanilla SGD"译为"普通SGD"并括号补充说明"无需动量项"
3. "per-FLOP performance"意译为"单位计算量下的性能表现"
4. 保持"Adam/SGD"等算法名称原文形式
5. "inter-device bandwidth"译为"设备间通信带宽"以准确反映分布式训练场景） |
| 通过双平衡协同专家机制解决不平衡领域增量学习问题

（翻译说明：
1. "Addressing"译为"解决"，准确传达处理问题的核心意图
2. "Imbalanced Domain-Incremental Learning"专业术语完整保留，译为"不平衡领域增量学习"
3. "Dual-Balance Collaborative Experts"采用意译+直译结合：
   - "Dual-Balance"译为"双平衡"既保留数字特征又明确平衡机制
   - "Collaborative Experts"译为"协同专家机制"补充"机制"二字符合中文学术表达习惯
4. 整体采用"通过...解决..."句式，符合中文论文标题常见的"方法-问题"表达结构
5. 添加"问题"二字作为宾语，使标题语义更完整
6. 保持12个汉字的标准学术标题长度，符合中文期刊标题规范） | Lan Li | [PDF](http://arxiv.org/pdf/2507.07100v1) | Domain-Incremental Learning (DIL) focuses on continual learning in
non-stationary environments, requ [翻译失败] |
| 迈向零样本：基于百万级数据的零样本运动生成研究

（翻译说明：
1. "Go to Zero"译为"迈向零样本"，既保留了原文"归零"的核心理念，又明确指向"零样本学习"这一机器学习专业术语
2. "Zero-shot"统一译为专业术语"零样本"，符合人工智能领域术语规范
3. "Million-scale Data"译为"百万级数据"，准确传达数据规模量级
4. 采用"研究"作为隐性增译，符合中文论文标题习惯
5. 整体结构重组为"目标+方法"的中文标题典型范式，保持学术严谨性的同时提升可读性） | Ke Fan | [PDF](http://arxiv.org/pdf/2507.07095v1) | 基于文本描述生成多样化且自然的人体运动序列是计算机视觉、图形学与机器人领域一项基础而富有挑战性的研究课题。尽管该领域已取得显著进展，现有方法在零样本泛化能力方面仍面临严峻挑战，这主要归因于训练数据集的规模限制。此外，由于缺乏系统性评估框架，该任务的改进方向难以明确，从而阻碍了研究进展。本研究致力于将文本驱动运动生成推向新纪元——实现零样本泛化能力。为此，我们首先构建了高效标注流程，并推出MotionMillion数据集（迄今规模最大的人体运动数据库），包含逾2,000小时、200万条高质量运动序列；同时提出MotionMillion-Eval评估基准（当前最全面的零样本运动生成评测体系）。通过可扩展的模型架构，我们将参数规模扩展至70亿，并在MotionMillion-Eval上验证性能。实验结果表明，该模型对域外数据及复杂组合运动展现出强大泛化能力，标志着零样本人体运动生成取得重大突破。代码已开源：https://github.com/VankouF/MotionMillion-Codes。

（翻译说明：1. 专业术语统一处理，如"zero-shot"译为"零样本"；2. 长句按中文习惯拆分重组；3. 被动语态转换为主动表达；4. 括号补充说明保持学术严谨性；5. 数量单位符合中文表述规范；6. 代码链接等专有名词保留原格式） |
| 评估时尚文本到图像生成中的属性混淆问题

（说明：该翻译严格遵循学术术语规范，其中：
1. "Evaluating"译为"评估"体现研究性质
2. "Attribute Confusion"译为"属性混淆"准确对应计算机视觉领域的专业表述
3. "Fashion Text-to-Image Generation"译为"时尚文本到图像生成"完整保留技术概念
4. 添加"问题"二字符合中文研究标题习惯，使语义更完整
5. 整体采用"研究对象+研究问题"的经典学术标题结构） | Ziyue Liu | [PDF](http://arxiv.org/pdf/2507.07079v1) | Despite the rapid advances in Text-to-Image (T2I) generation models, their
evaluation remains challe [翻译失败] |
| 野外测量中的标尺判读

（说明：根据学术翻译规范，此处采用意译处理"in the Wild"这一生态学术语，将其译为"野外测量"以准确表达野外实地研究的语境。专业术语"Ruler"保留其本义译为"标尺"，但根据测绘学科惯例增加"判读"这一专业动作描述，使整个译名既符合中文表达习惯，又完整传递了原文指涉的野外测量技术场景。） | Yimu Pan | [PDF](http://arxiv.org/pdf/2507.07077v1) | Accurately converting pixel measurements into absolute real-world dimensions
remains a fundamental c [翻译失败] |
| 基于图的多智能体课程学习复杂度度量：合作协调环境中任务排序的已验证方法

（翻译说明：
1. 专业术语处理：
- "Graph-Based"译为"基于图的"，准确体现算法基础
- "Complexity Metrics"译为"复杂度度量"，符合计算机科学术语规范
- "Multi-Agent Curriculum Learning"译为"多智能体课程学习"，保留强化学习领域专用概念
- "Validated Approach"译为"已验证方法"，强调方法论经过实证检验

2. 句式结构调整：
- 将原文名词短语转换为中文惯用的"方法+应用场景"结构
- 使用冒号分隔核心方法与具体应用领域
- 保持"合作协调环境"作为状语后置的科技论文表达习惯

3. 技术准确性保障：
- "Task Ordering"译为"任务排序"而非"任务顺序"，更符合机器学习领域表述
- 保留"课程学习"这一特定机器学习范式术语
- "Cooperative Coordination"译为"合作协调"准确区分两种交互模式

4. 学术风格匹配：
- 采用简洁的复合名词结构
- 避免口语化表达
- 保持标题的精确性和信息密度） | Farhaan Ebadulla | [PDF](http://arxiv.org/pdf/2507.07074v1) | 多智能体强化学习（MARL）在任务排序与课程设计领域面临重大挑战，尤其在协作协调场景中更为突出。尽管课程学习在单智能体领域已取得显著成效，但由于缺乏经过验证的任务复杂度度量标准，针对多智能体协调的系统性方法仍存在局限。本研究提出一种基于图的协调复杂度度量方法，该方法融合智能体依赖熵、空间干扰模式与目标重叠分析，用于预测多智能体环境中的任务难度。该复杂度度量标准获得强实证验证（ρ=0.952，p<0.001），其预测复杂度与通过随机智能体性能评估得出的实证难度高度相关。研究采用MADDPG算法在两个典型协调环境中评估课程学习框架：在紧密协调任务（MultiWalker）中实现56倍性能提升，在协作导航任务（Simple Spread）中展现系统性任务进阶。通过系统分析发现，协调紧密度可作为课程学习有效性的预测指标——需要严格智能体相互依赖的环境能从结构化进阶中显著获益。本方法为多智能体课程设计提供了经过验证的复杂度度量标准，并为多机器人协调应用建立了实证指导准则。

（翻译说明：严格保持专业术语一致性，如"curriculum learning"统一译为"课程学习"；复杂句式按中文习惯拆分重组；统计指标保留原始符号格式；技术概念如"agent dependency entropy"采用学界通用译法"智能体依赖熵"；长定语转换为前置短句，如将原文后置的"determined by..."处理为"通过...得出的"前置结构；被动语态转换为主动表述，如"is validated"译为"获得验证"） |
