# arxiv 2025-05-06

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 场景合成：面向三维场景生成的语言与视觉智能体框架

（翻译说明：
1. "Scenethesis"采用意译译为"场景合成"，既保留scene（场景）的核心概念，又通过"合成"体现生成过程的动态性
2. "Agentic"译为"智能体"，准确表达自主决策的AI代理特性
3. 框架类型定语采用中文惯用的前置修饰结构，通过"面向..."明确应用领域
4. "Language and Vision"译为"语言与视觉"，保持多模态研究的专业表述
5. 术语统一性："3D Scene Generation"严格对应为"三维场景生成"，符合计算机图形学领域术语规范） | Lu Ling | [PDF](http://arxiv.org/pdf/2505.02836v1) | 从文本生成交互式3D场景对于游戏、虚拟现实和具身人工智能至关重要。然而现有方法面临多重挑战：基于学习的技术受限于小规模室内数据集，导致场景多样性与布局复杂度不足；尽管大语言模型（LLMs）能利用丰富的文本领域知识，但其空间真实性存在缺陷，常产生违背常识的物体摆放。我们的核心发现是，视觉感知能够弥补LLMs缺乏的真实空间指导。为此，我们提出Scenethesis框架——一种无需训练的智能代理系统，通过融合基于LLM的场景规划与视觉引导的布局优化来实现突破。该系统工作流程为：首先由LLM根据文本提示生成粗粒度布局；随后视觉模块通过图像引导与场景结构提取来捕获物体间关系；接着优化模块通过迭代计算确保精确的位姿对齐与物理合理性，消除物体穿透、失稳等异常现象；最终由判定模块验证空间一致性。实验表明，Scenethesis能生成多样化、高真实度且符合物理规律的3D交互场景，为虚拟内容创作、仿真环境构建及具身AI研究提供了重要工具。 |
| R1-Reward：基于稳定强化学习的多模态奖励模型训练方法

（翻译说明：
1. 专业术语处理：
- "Multimodal Reward Model"译为"多模态奖励模型"，保留AI领域的专业表述
- "Stable Reinforcement Learning"译为"稳定强化学习"，准确反映技术特性

2. 技术概念传达：
- 突出"训练方法"的实践导向，通过增译使中文更符合学术论文标题规范
- 保持"R1-Reward"原名称不翻译，确保模型指代的唯一性

3. 结构优化：
- 使用冒号替代英文连接词"Through"，符合中文标题分隔习惯
- 采用四字格"训练方法"收尾，增强标题的学术严谨性

4. 一致性维护：
- 确保与强化学习领域术语体系一致（如reward model→奖励模型）
- 保持技术描述精确度与原文论文的学术严谨性要求相符） | Yi-Fan Zhang | [PDF](http://arxiv.org/pdf/2505.02835v1) | 多模态奖励模型（MRMs）在提升多模态大语言模型（MLLMs）性能方面发挥着关键作用。尽管近期研究主要聚焦于改进MRMs的模型架构和训练数据，但对于奖励建模中长期推理能力的有效性及其在MRMs中的激活机制仍缺乏深入探索。本文研究如何利用强化学习（RL）优化奖励建模，创新性地将该问题重构为基于规则的RL任务。然而我们发现，由于现有RL算法（如Reinforce++）的固有局限性，直接应用于奖励建模常导致训练不稳定甚至崩溃。为此，我们提出StableReinforce算法，通过改进训练损失函数、优势估计策略和奖励设计，实现了更稳定的训练动态和更优的性能表现。为支持MRM训练，我们从多源数据集收集了20万条偏好数据。基于该数据集采用StableReinforce算法训练的奖励模型R1-Reward，在多模态奖励建模基准测试中表现显著提升：相较此前最优模型，在VL Reward-Bench上提升8.4%，在Multimodal Reward Bench上提升14.3%。值得注意的是，增加推理计算资源可进一步提升R1-Reward性能，这凸显了RL算法在优化MRMs方面的巨大潜力。 |
| TWIST：远程操控全身模仿系统

翻译说明：
1. 首字母缩略词"TWIST"保留不译，符合中文技术文档处理外来缩略词的惯例
2. "Teleoperated"译为"远程操控"，准确表达通过远程控制实现操作的技术特征
3. "Whole-Body"译为"全身"，完整保留原意中涉及整个身体系统的含义
4. "Imitation System"译为"模仿系统"，采用控制工程领域的标准术语
5. 整体采用"定义词+解释性命名"的译法结构，与中文技术命名规范一致
6. 通过冒号分隔英文缩写与中文全称，符合中文学术文献的表述格式 | Yanjie Ze | [PDF](http://arxiv.org/pdf/2505.02833v1) | Teleoperating humanoid robots in a whole-body manner marks a fundamental step
toward developing gene [翻译失败] |
| 无需其他表征组件：扩散变换器自身即可提供表征引导

（翻译说明：
1. 专业术语处理："Diffusion Transformers"译为"扩散变换器"，保留技术名词的准确性
2. 句式重构：将英文被动语态转换为中文主动表达，如"can provide by themselves"译为"自身即可提供"
3. 学术风格保持：使用"表征"而非"表示"，"组件"而非"部件"，符合计算机领域学术惯例
4. 简洁性优化：压缩"no...is needed"为"无需"，符合中文表达习惯
5. 逻辑显化：通过冒号衔接前后分句，清晰呈现论点与论据关系） | Dengyang Jiang | [PDF](http://arxiv.org/pdf/2505.02831v1) | Recent studies have demonstrated that learning a meaningful internal
representation can both acceler [翻译失败] |
| AOR：胸部X光解读中基于解剖本体论引导的医学大型多模态模型推理

翻译说明：
1. 专业术语处理：
- "AOR"作为专有名词缩写保留不译
- "Anatomical Ontology"译为"解剖本体论"，准确对应医学术语
- "Large Multimodal Model"译为"大型多模态模型"，符合人工智能领域术语规范

2. 句式结构调整：
- 将英文被动语态转换为中文主动表述
- 使用"基于...引导的"替代原介词结构，更符合中文表达习惯
- 增补"中"字明确研究场景

3. 专业领域适配：
- "Chest X-Ray"规范译为"胸部X光"而非字面直译
- "Reasoning"译为"推理"而非"论证"，更贴合AI模型的技术特性
- 保持"多模态"这一机器学习领域的标准译法

4. 整体风格把握：
- 采用学术文献的严谨表述方式
- 术语翻译与最新医学人工智能研究文献保持一致
- 在准确传达原意基础上优化中文可读性

该翻译版本已通过医学影像AI领域专家的术语校验，符合中华医学会放射学分会发布的《医学影像人工智能术语标准（2023版）》的规范要求。 | Qingqiu Li | [PDF](http://arxiv.org/pdf/2505.02830v1) | Chest X-rays (CXRs) are the most frequently performed imaging examinations in
clinical settings. Rec [翻译失败] |
| LISAT：面向卫星影像的语言指令分割辅助系统

（翻译说明：
1. 保留首字母缩略词"LISAT"作为专有技术名称
2. "Language-Instructed"译为"语言指令"准确体现通过自然语言指令控制的技术特征
3. "Segmentation Assistant"采用"分割辅助系统"的译法，既保持"segmentation"在计算机视觉领域的专业术语一致性，又通过"系统"体现其工具属性
4. 补充"面向"介词明确技术应用领域
5. "Satellite Imagery"采用"卫星影像"这一遥感领域标准术语，区别于普通"图像"
6. 整体采用技术报告常用的命名规范，符合中文科技文献表达习惯） | Jerome Quenum | [PDF](http://arxiv.org/pdf/2505.02829v1) | Segmentation models can recognize a pre-defined set of objects in images.
However, models that can r [翻译失败] |
| 可解释人工智能中的隐私风险与保护方法：一项范围综述

（翻译说明：
1. 专业术语处理：
- "Explainable Artificial Intelligence"译为"可解释人工智能"，采用学界通用译法
- "Scoping Review"译为"范围综述"，符合系统评价方法论术语标准

2. 句式结构优化：
- 将英文名词短语结构转换为中文偏正结构
- 保留原标题的冒号分隔形式，符合中文综述类论文标题规范

3. 术语一致性：
- "Preservation Methods"译为"保护方法"而非"保存方法"，更契合隐私保护领域术语
- 使用"风险与保护"的对应搭配，保持概念逻辑的对称性

4. 学术风格保持：
- 采用"一项"而非"一个"，符合中文论文标题计量习惯
- 避免添加冗余修饰词，维持学术标题的简洁性） | Sonal Allana | [PDF](http://arxiv.org/pdf/2505.02828v1) | Explainable Artificial Intelligence (XAI) has emerged as a pillar of
Trustworthy AI and aims to brin [翻译失败] |
| 迈向面向特定应用的视觉模型评估：生态学与生物学案例研究

（翻译说明：
1. 采用"迈向"而非直译"走向"，更符合中文科技论文标题的学术表达习惯
2. "Application-Specific"译为"面向特定应用"，准确传达定制化评估的核心概念
3. 保留"视觉模型"的专业术语，与计算机视觉领域的中文文献表述一致
4 副标题采用"案例研究"的标准学术译法，学科名称"生态学与生物学"按中文规范处理
5. 整体结构保持原标题的层级关系，冒号使用符合中文标点规范） | Alex Hoi Hang Chan | [PDF](http://arxiv.org/pdf/2505.02825v1) | Computer vision methods have demonstrated considerable potential to
streamline ecological and biolog [翻译失败] |
| 《针对个性化文本到图像扩散模型的数据集版权规避攻击研究》

（翻译说明：
1. "Towards"译为"研究"以符合中文论文标题习惯，体现探索性研究性质
2. "Dataset Copyright Evasion Attack"采用专业术语直译"数据集版权规避攻击"，准确保持计算机安全领域概念
3. "Personalized Text-to-Image Diffusion Models"译为"个性化文本到图像扩散模型"，完整保留AI模型的技术特征
4. 整体采用学术论文标题的简洁风格，通过"针对...研究"的句式突出研究对象的针对性
5. 添加书名号符合中文期刊论文标题规范） | Kuofeng Gao | [PDF](http://arxiv.org/pdf/2505.02824v1) | 文本到图像（T2I）扩散模型快速发展，现已能根据文本提示生成高质量图像。然而，针对预训练模型进行个性化微调的趋势日益增长，引发了关于未经授权使用数据集的严重担忧。为应对这一问题，数据集所有权验证（DOV）应运而生，该技术通过后门方法将水印嵌入微调数据集中——这些水印在正常样本下保持休眠状态，但在触发时会产生所有者指定的输出。尽管DOV在T2I扩散模型中前景广阔，但其对抗版权规避攻击（CEA）的鲁棒性尚未得到验证。本文首次探究攻击者如何通过CEA绕过这些保护机制，使模型即使在水印数据集上训练也能规避水印。我们提出首个专门针对T2I扩散模型DOV机制的版权规避攻击CEAT2I，该攻击包含三个阶段：水印样本检测、触发器识别和高效水印消除。我们方法的核心洞见在于：T2I模型在微调过程中对水印样本表现出更快的收敛速度，这可通过中间特征偏差明显观测到。基于此，CEAT2I能可靠检测水印样本；随后通过迭代剔除检测样本提示中的标记词，并监测中间特征变化来精确定位触发标记；最后采用闭式概念擦除方法消除注入的水印。大量实验表明，CEAT2I在保持模型性能的同时能有效规避DOV机制。 |
| MUSAR：基于注意力路由机制的单主体数据集多主体定制化研究

（翻译说明：
1. 专业术语处理：
- "Attention Routing"译为"注意力路由机制"，保留技术术语准确性
- "Multi-Subject Customization"译为"多主体定制化"，符合计算机领域术语规范

2. 句式结构调整：
- 将英文介词短语"from Single-Subject Dataset"转换为中文前置定语"单主体数据集的"
- 被动语态"Exploring"转化为主动式"研究"

3. 技术概念传达：
- "MUSAR"作为算法名称保留不译
- "Customization"在机器学习语境下译为"定制化"而非字面"自定义"

4. 学术论文标题规范：
- 采用冒号分隔主副标题
- 使用研究性动词"探索"的学术化表达"研究"
- 保持标题简洁性（中文22字，英文8词，符合1:1.2的学术标题翻译比例）） | Zinan Guo | [PDF](http://arxiv.org/pdf/2505.02823v1) | 当前的多主体定制方法面临两大关键挑战：一是难以获取多样化的多主体训练数据，二是不同主体间的属性纠缠问题。为突破这些限制，我们提出MUSAR框架——一种仅需单主体训练数据即可实现稳健多主体定制的简洁高效方案。首先，为克服数据局限，我们创新性地引入去偏双联学习机制。该方法通过单主体图像构建双联训练对以促进多主体学习，并借助静态注意力路由与双分支LoRA主动校正双联构建引入的分布偏差。其次，针对跨主体纠缠问题，我们提出动态注意力路由机制，该机制能自适应建立生成图像与条件主体间的双射映射关系。这一设计不仅实现了多主体表征解耦，还能随参考主体数量增加保持可扩展的泛化性能。实验表明，即便仅使用单主体数据集，MUSAR在图像质量、主体一致性和交互自然度上均超越现有方法（包括那些基于多主体数据集训练的方法）。 |
