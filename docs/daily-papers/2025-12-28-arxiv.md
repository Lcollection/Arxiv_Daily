# arxiv 2025-12-28

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| HiStream：通过消除冗余流实现高效高分辨率视频生成 | Haonan Qiu | [PDF](https://arxiv.org/pdf/2512.21338v1) | 高分辨率视频生成虽对数字媒体与电影至关重要，但其计算效率受限于扩散模型二次方复杂度的瓶颈，导致实际推理难以实现。为此，我们提出HiStream——一种高效的自回归框架，通过三轴系统性冗余削减策略：i) 空间压缩：在低分辨率下进行去噪，再利用缓存特征进行高分辨率细化；ii) 时序压缩：采用固定尺寸锚点缓存的逐块处理策略，确保稳定的推理速度；iii) 时间步压缩：对后续基于缓存条件的视频块应用更少的去噪步骤。在1080p基准测试中，我们的核心HiStream模型（i+ii）在实现顶尖视觉质量的同时，相比Wan2.1基线模型去噪速度提升最高达76.2倍，且质量损失可忽略不计。我们的加速变体HiStream+融合三项优化（i+ii+iii），相比基线实现107.5倍加速，在速度与质量间达成卓越平衡，从而使高分辨率视频生成兼具实用性与可扩展性。 |
| 超越记忆：揭示视觉语言模型中流行度偏差的多模态序数回归基准测试

（注：翻译力求准确传达原文的学术含义。"Beyond Memorization"译为"超越记忆"，强调突破简单记忆的层面；"Multi-Modal Ordinal Regression Benchmark"译为"多模态序数回归基准测试"，保留专业术语的准确性；"Expose Popularity Bias"译为"揭示流行度偏差"，其中"bias"在机器学习语境中常译为"偏差"而非"偏见"；"Vision-Language Models"采用学界通用译法"视觉语言模型"。整体译文保持学术文本的严谨性，同时符合中文表达习惯。） | Li-Zhong Szu-Tu | [PDF](https://arxiv.org/pdf/2512.21337v1) | 我们揭示了当前最先进的视觉语言模型（VLMs）中存在显著的流行度偏差：这些模型在识别著名建筑时的准确率比普通建筑高出34%，表明其依赖记忆而非可泛化的理解能力。为系统研究此问题，我们构建了该领域最大的开放基准数据集——YearGuessr，包含来自157个国家的55,546张建筑图像，每张图像均标注了连续序数形式的建造年份（1001-2024年）、GPS数据，并以页面浏览量作为流行度代理指标。基于该数据集，我们将建造年份预测任务构建为序数回归问题，并提出融入流行度感知的区间准确率度量方法以量化此类偏差。通过对30余个模型（包括我们提出的YearCLIP模型）的基准测试，证实了VLMs在识别流行记忆项时表现优异，但在处理非知名对象时存在显著困难，这暴露了其推理能力的根本缺陷。项目页面：https://sytwu.github.io/BeyondMemo/ |
| 通过量化不确定性优化掩码扩散模型的解码路径 | Ziyu Chen | [PDF](https://arxiv.org/pdf/2512.21336v1) | 掩码扩散模型（MDMs）具备灵活的非自回归生成能力，但这种自由度也带来了挑战：最终输出质量对解码顺序高度敏感。我们首次将这一问题形式化，指出输出质量的波动源于生成路径中累积的预测不确定性。为量化这种不确定性，我们提出了"去噪熵"这一可计算指标，作为评估生成过程的内部信号。基于该指标，我们设计了两种优化解码路径的算法：一种后验选择方法与一种实时引导策略。实验表明，我们的熵引导方法显著提升了生成质量，在具有挑战性的推理、规划和代码基准测试中持续提高准确率。本研究确立了去噪熵作为理解和控制生成过程的原则性工具，成功将MDMs中的不确定性从缺陷转化为发现高质量解决方案的关键优势。 |
| 计算型即时检测传感器的自主不确定性量化 | Artem Goncharov | [PDF](https://arxiv.org/pdf/2512.21335v1) | 计算型即时检测传感器能够在缺乏中心医疗设施的紧急、偏远及资源有限地区实现快速、低成本且易于获取的诊断。这些系统可利用基于神经网络的算法，从快速诊断测试或传感器产生的信号中准确推断诊断结果。然而，基于神经网络的诊断模型易产生幻觉现象，可能导致错误预测，从而带来误诊和临床决策不准确的风险。为应对这一挑战，本研究提出一种专为即时检测诊断开发的自主不确定性量化技术。我们以用于莱姆病（全球最常见的蜱媒传染病）快速即时诊断的纸基计算型垂直流检测平台作为实验平台。该平台集成了可抛弃式纸基检测装置、手持式光学读取器及基于神经网络的推理算法，仅需20微升患者血清即可在20分钟内实现快速、低成本的莱姆病诊断。通过将基于蒙特卡洛随机失活的不确定性量化方法融入诊断流程，系统能自主识别并排除高不确定性的错误预测，在无需患者真实诊断信息的情况下，显著提升了检测平台的敏感性与可靠性。使用新患者样本的盲测结果显示，诊断敏感性从88.2%提升至95.7%，这证实了基于蒙特卡洛随机失活的不确定性量化方法在增强神经网络驱动的计算型即时检测系统鲁棒性方面的有效性。 |
| 流媒体视频指令调优 | Jiaer Xia | [PDF](https://arxiv.org/pdf/2512.21334v1) | 我们推出Streamo，一款实时流式视频大语言模型，可作为通用交互式助手。与现有仅专注于问答或字幕生成的在线视频模型不同，Streamo能够执行广泛的流式视频任务，包括实时解说、动作理解、事件描述、时序事件定位以及时效性问答。为实现这种多功能性，我们构建了Streamo-Instruct-465K——一个专为流式视频理解定制的大规模指令遵循数据集。该数据集涵盖多样化时序语境与多任务监督机制，支持跨异构流式任务的统一训练。通过端到端的简化流程在指令数据集上完成训练后，Streamo展现出强大的时序推理能力、实时响应特性以及在多种流式基准测试中的广泛泛化性能。大量实验表明，Streamo成功弥合了离线视频感知模型与实时多模态助手之间的鸿沟，为连续视频流中的统一智能视频理解迈出了关键一步。 |
| 快速SAM2结合文本驱动的令牌剪枝 | Avilasha Mandal | [PDF](https://arxiv.org/pdf/2512.21333v1) | Segment Anything Model 2 (SAM2)作为视觉基础模型，在提示驱动的视频目标分割领域取得了显著进展，但其实际部署仍受限于跨时间处理密集视觉标记时的高计算与内存成本。现有SAM2流程通常将图像编码器生成的全部视觉标记传递至下游时序推理模块，无论其与目标对象的相关性如何，这种处理方式因二次内存注意力开销而限制了模型的可扩展性。

本研究提出一种文本引导的标记剪枝框架，通过在时序传播前选择性降低标记密度来提升推理效率，且无需修改底层分割架构。该方法在视觉编码之后、基于记忆的传播之前运行，通过轻量级路由机制对标记进行排序，该机制整合了局部视觉上下文、源自以对象为中心的文本描述（用户提供或自动生成）的语义相关性，以及有助于保留模糊或边界关键区域的不确定性线索。

通过仅保留最具信息量的标记供下游处理，所提方法在维持分割保真度的同时减少了冗余计算。在多个高难度视频分割基准上的大量实验表明，编码后标记剪枝为实现高效、提示感知的视频分割提供了切实有效的路径：与未剪枝的基准SAM2相比，推理速度最高提升42.50%，GPU内存使用降低37.41%，同时保持了具有竞争力的J和F性能指标。这些结果凸显了早期标记选择在提升基于Transformer的视频分割系统可扩展性方面的潜力，尤其适用于实时性与资源受限的应用场景。 |
| C2LLM技术报告：通过自适应交叉注意力池化实现代码检索的新前沿 | Jin Qin | [PDF](https://arxiv.org/pdf/2512.21332v1) | 我们推出C2LLM——对比式代码大语言模型系列，包含0.5B与7B两种规模的代码嵌入模型。该系列基于Qwen-2.5-Coder架构构建，创新性地采用多头注意力池化模块，从词元嵌入中生成序列嵌入。该设计具有三重优势：1）充分利用预训练阶段获得的大语言模型因果表征能力；2）突破传统基于EOS的序列嵌入信息瓶颈，实现序列全词元信息聚合；3）支持嵌入维度的灵活适配，可作为多表示学习方法的替代方案。经过三百万公开数据训练，C2LLM在同等规模模型中刷新了MTEB-Code基准测试纪录，其中C2LLM-7B版本荣登综合排行榜首位。 |
| TICON：用于组织病理学表征学习的切片级图块上下文建模器 | Varun Belagali | [PDF](https://arxiv.org/pdf/2512.21331v1) | 在大型全切片图像（WSI）中解读小图块通常需要更大的图像上下文。我们提出TICON——一种基于Transformer的图块表示上下文化模型，能够为计算病理学中的"任意"应用生成丰富的上下文化嵌入向量。传统的基于图块编码器的流程虽然能提取脱离上下文的图块嵌入，却无法建模对局部和全局任务都至关重要的丰富切片级信息。此外，不同图块编码器在不同下游任务中表现各异，因此需要统一模型来对"任意"图块级基础模型生成的嵌入进行上下文化处理。TICON通过单一共享编码器满足这一需求，该编码器采用掩码建模目标进行预训练，能同时统一并上下文化来自不同图块级病理基础模型的表示。实验表明，经TICON上下文化的嵌入向量在多项任务中显著提升性能，在图块级基准测试（如HEST-Bench、THUNDER、CATCH）和切片级基准测试（如Patho-Bench）中均创下最新最优纪录。最后，我们基于TICON预训练出聚合器构建切片级基础模型，仅使用1.1万张WSI即超越当前最优的切片级基础模型（后者预训练需多达35万张WSI）。 |
| 您的推理基准可能并未真正测试推理：揭示抽象推理基准中的感知瓶颈问题 | Xinhe Wang | [PDF](https://arxiv.org/pdf/2512.21329v1) | 诸如抽象与推理语料库（ARC）及其扩展版本ARC-AGI等推理基准被广泛用于评估人工智能的发展水平，并常被视为对核心“流体”推理能力的检验。尽管这些任务对人类而言看似简单，但对前沿视觉语言模型（VLMs）仍具挑战性，这一差距通常被归因于机器推理能力的不足。我们对此解释提出质疑，并提出假设：这一差距主要源于视觉感知的局限性，而非归纳推理的缺陷。

为验证这一假设，我们设计了一个两阶段实验流程，明确分离感知与推理过程。在感知阶段，每张图像被独立转换为自然语言描述；在推理阶段，模型基于这些描述归纳规则并加以应用。该设计避免了跨图像归纳信号的泄露，并将推理过程与感知瓶颈相隔离。通过在Mini-ARC、ACRE和Bongard-LOGO三个ARC风格数据集上的实验，我们对比两阶段流程与标准端到端单阶段评估，证明感知能力是导致性能差距的主导因素。对VLM输出推理轨迹的人工检查进一步揭示，约80%的模型失败源于感知错误。

综合来看，这些结果表明ARC风格基准将感知与推理挑战混为一谈，而观察到的性能差距可能夸大了机器推理能力的缺陷。我们的发现强调，在评估机器智能进展时，需要建立能够区分感知与推理的评估框架。 |
| 全面测量大语言模型评估中的各类噪音 | Sida Wang | [PDF](https://arxiv.org/pdf/2512.21326v1) | 从噪声中分离信号是实验科学的核心。将成熟的统计方法有效应用于大语言模型评估，需充分考虑其独特的噪声特性。我们明确定义并测量了三种噪声类型：针对给定问题生成不同答案产生的预测噪声、问题抽样形成的数据噪声，以及遵循全方差定律的复合总噪声。为强化相对比较并提升统计效力，我们提出全配对分析方法——该方法对所有大语言模型组合实施配对分析，并基于数百万条跨多评估场景的问题级预测数据，系统测量所有噪声成分。

测量结果呈现出清晰规律：首先，每项评估在所有模型配对中都表现出特征明确且高度可预测的总噪声水平；其次，配对预测噪声通常超过配对数据噪声，这意味着通过均值化降低预测噪声能显著提升统计效力。这些发现使实践者无需定制化测试即可评估显著性，并能在控制实验中检测更微小的效应差异。 |
