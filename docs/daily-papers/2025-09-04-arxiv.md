# arxiv 2025-09-04

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 大型语言模型会说谎吗？超越幻觉现象的研究探析

（注：翻译采用学术论文标题的常见结构，通过问句形式保留原标题的探究性。"Lie"译为"说谎"以保持哲学探讨的尖锐性，"Hallucination"采用计算机领域通用译法"幻觉现象"，"Investigation beyond"译为"超越...的研究探析"既体现研究深度又符合中文论文标题规范。） | Haoran Huan | [PDF](http://arxiv.org/pdf/2509.03518v1) | 大型语言模型（LLMs）在各类任务中展现出卓越能力，但其在现实应用中日益增强的自主性引发了对其可信度的担忧。尽管幻觉现象——即模型无意识产生的谬误——已得到广泛研究，但刻意欺骗行为（即模型为实现隐蔽目标而故意生成虚假信息）仍缺乏深入探索。本研究系统性地考察了LLMs的欺骗行为，将其与幻觉现象区分，并在实际场景中进行测试。通过机制可解释性技术，我们采用逻辑透镜分析、因果干预和对比激活导向等方法，揭示欺骗行为的神经机制并实现对其控制。我们研究了现实世界中的欺骗场景，引入行为导向向量以实现对欺骗倾向的精细调控。此外，我们探索了欺骗行为与终端任务性能之间的权衡关系，建立了通过不诚实行为优化目标实现的帕累托前沿。本研究为人工智能伦理讨论提供了重要见解，揭示了在高风险环境中部署LLMs的风险隐患及潜在防护措施。代码及更多图示详见https://llm-liar.github.io/。

（注：翻译严格遵循以下原则：
1. 专业术语准确对应：LLMs译为"大型语言模型"，mechanistic interpretability译为"机制可解释性"等
2. 学术表述规范：保留"帕累托前沿"等专业概念
3. 长句拆分符合中文表达习惯
4. 被动语态转换为主动表述
5. 概念性内容保持原文学术严谨性） |
| 比思考更易绘画：文本生成图像模型能否搭建舞台，却无法执导戏剧？

（注：译文采用学术化表达，保留原文隐喻修辞。"Set the Stage"译为"搭建舞台"对应模型的基础构建功能，"Not Direct the Play"译为"无法执导戏剧"暗指模型缺乏深层创作指导能力。冒号后的设问句式完整传递原标题的批判性学术探讨语气，同时通过"比...更易"的对比结构准确还原"Easier...Than"的语义关系。） | Ouxiang Li | [PDF](http://arxiv.org/pdf/2509.03516v1) | 文本到图像生成技术旨在根据文本提示合成图像，这些提示既明确规定了需要呈现的内容，又隐含着可推导的信息，对应着构图与推理两大核心能力。然而随着T2I模型在推理能力方面取得超越构图能力的新进展，现有基准测试在跨能力维度和能力内部评估方面均表现出明显局限性。与此同时，这些技术进步使模型能够处理更复杂的提示，而当前基准测试仍局限于低场景密度和简化的一对一推理。为突破这些限制，我们提出T2I-CoReBench——一个全面而复杂的基准测试体系，可同步评估T2I模型的构图与推理能力。为确保全面性，我们以场景图要素（实例、属性和关系）构建构图维度，依据哲学推理框架（演绎、归纳和溯因）建立推理维度，最终形成包含12个评估维度的分类体系。为提升复杂性，我们基于现实场景的固有复杂性，为构图维度设计高组合密度的提示，为推理维度构建多步推断提示。每个提示均配有核查清单，通过独立的是非判断题分别评估每个目标要素，从而实现细粒度且可靠的评估。该基准测试共包含1,080个高难度提示和约13,500个核查问题。对27个现行T2I模型的实验表明：在复杂高密度场景中，模型的构图能力仍存在明显局限，而推理能力作为关键瓶颈更为落后——所有模型都难以从提示中推断隐含要素。项目页面：https://t2i-corebench.github.io/。 |
| Waymo开放运动数据集能否支持真实行为建模？基于自然轨迹的验证研究 | Yanlin Zhang | [PDF](http://arxiv.org/pdf/2509.03515v1) | The Waymo Open Motion Dataset (WOMD) has become a popular resource for
data-driven modeling of auton [翻译失败] |
| 一项用于研究遗传性及家族关系对手写体影响的综合性波斯语离线手写数据库

（注：译文严格遵循学术翻译规范，采用专业术语："offline handwritten"译为"离线手写"（区别于在线笔迹采集），"heritability"译为"遗传性"，"family relationships"译为"家族关系"，"comprehensive"译为"综合性"以准确传达数据库的规模与完整特性，同时保持中文科技文献的表述习惯。） | Abbas Zohrevand | [PDF](http://arxiv.org/pdf/2509.03510v1) | 本文介绍了一个用于研究笔迹遗传效应的综合性数据库。该数据库旨在解答以下问题：笔迹是否具有遗传成分？笔迹能否被继承？家族关系是否会影响笔迹？我们通过专门设计的表格收集了210个家族（包含祖父母、父母、叔伯姑姨、兄弟姐妹、堂表亲及子侄辈）的手写样本，包括数字、字母、图形及自由段落等多种书写要素，并完整记录了所有书写者的亲缘关系。据我们所知，目前尚无同类数据库可供使用。通过对家族成员笔迹特征的比较研究，我们发现其书写特征与风格存在相似性。本数据库已向模式识别研究社区开放获取，期望能为笔迹遗传性与家族关系影响的研究提供基础支撑。 |
| LimiX：释放通用智能的结构化数据建模能力

（注：翻译说明：
1. "Unleashing"译为"释放"准确传达了解放潜能的含义
2. "Structured-Data Modeling Capability"采用专业术语直译为"结构化数据建模能力"
3. "Generalist Intelligence"译为"通用智能"符合人工智能领域的专业表述
4. 保留"LimiX"原名不翻译，符合技术术语处理规范
5. 整体采用学术论文标题的简洁风格，使用冒号分隔主副标题） | Xingxuan Zhang | [PDF](http://arxiv.org/pdf/2509.03505v1) | 我们认为，实现通用智能的进展需要建立在语言、物理世界和结构化数据基础上的互补性基础模型。本报告推出LimiX——我们大型结构化数据模型（LDMs）的首个成果。LimiX将结构化数据视为变量与缺失值的联合分布，从而能够通过基于查询的条件预测，以单一模型处理广泛的表格任务。该模型采用掩码联合分布建模方法进行预训练，具有情景化、上下文条件化的目标设定：通过以数据集特定上下文为条件预测查询子集，支持推理时无需训练的快速适配。我们在10个大型结构化数据基准测试中评估LimiX，这些基准涵盖不同样本量、特征维度、类别数量、分类与数值特征比例、缺失值比例以及样本-特征比等多种场景。如图1和图2所示，凭借单一模型和统一接口，LimiX持续超越包括梯度提升树、深度表格网络、近期表格基础模型和自动化集成在内的强基线模型。其在分类、回归、缺失值插补和数据生成等广泛任务中均保持显著优势，且无需针对特定任务设计架构或进行定制化训练。所有LimiX模型均基于Apache 2.0协议开源发布。 |
| 面向低资源客户端的零阶联邦预训练预热研究

该标题的学术翻译要点如下：
1. "Warming Up" 译为"预热" - 符合机器学习领域对模型初始化阶段的专业表述
2. "Zeroth-Order" 保留"零阶"直译 - 准确传达无需梯度计算的优化方法特性
3. "Federated Pre-Training" 译为"联邦预训练" - 保持联邦学习术语一致性
4. "Low Resource Clients" 处理为"低资源客户端" - 准确描述计算/通信资源受限的参与设备
5. 中文语序调整 - 按照中文学术标题习惯将核心概念前置，使用"面向...的"结构保持专业性与流畅性

该翻译既保持了原文的技术准确性，又符合中文计算机学术论文的标题规范，突出了联邦学习中资源受限场景下的预训练优化这一核心研究内容。 | Gwen Legate | [PDF](http://arxiv.org/pdf/2509.03503v1) | 联邦学习使得众多边缘设备能够在不共享数据的情况下进行协作式模型训练；然而，这些边缘设备的内存与通信限制可能导致其无法参与训练。本文研究了一种特定场景：部分边缘设备的内存或通信能力低于执行模型更新所需的关键阈值。在典型的联邦优化算法中，这些设备会被排除在训练过程之外，导致其数据不可利用并加剧系统固有偏差。我们受MeZO（一种用于内存高效微调的零阶方法）的启发，注意到零阶梯度估计固有的高方差问题曾使此类优化器仅局限于微调领域——这一局限正是我们试图突破的。我们设计了一种联邦式内存高效零阶优化器ZOWarmUp，支持从随机初始化开始进行零阶训练。该算法通过利用客户端异构能力和精细的方差削减技术，促使资源受限的弱势客户端能够参与模型训练。与其他联邦零阶方法类似，ZOWarmUp无需边缘设备向服务器传输完整梯度，仅依赖少量随机种子即可实现通信，使上行链路通信成本可忽略不计。我们通过多数据集和多模型架构的实验表明，ZOWarmUp是一种鲁棒性强的算法，可适用于多种场景。对于存在大量边缘设备可能被排除在训练之外的系统，本算法能够接入更大量且多样化的数据，从而显著提升训练效果。 |
| Strefer：通过合成指令数据赋能视频大语言模型实现时空指代与推理

（注：翻译说明：
1. "Empowering"译为"赋能"符合技术语境
2. "Space-Time Referring and Reasoning"采用"时空指代与推理"的学术表述
3. "Synthetic Instruction Data"译为"合成指令数据"准确传达生成式数据的概念
4. 保持原标题的冒号结构，确保学术规范性
5. "Video LLMs"译为"视频大语言模型"完整保留专业术语） | Honglu Zhou | [PDF](http://arxiv.org/pdf/2509.03501v1) | 新一代人工智能伴侣必须超越通用视频理解能力，以解析动态现实环境中的空间与时间参照。现有视频大语言模型（Video LLMs）虽具备粗粒度理解能力，但在细粒度时空推理方面仍存在不足——尤其当用户查询依赖基于时间的事件参照进行时序锚定，或需要通过手势线索进行空间锚定以明确对象指代及位置时。为填补这一关键空白，我们推出Strefer：一个专为视频大语言模型设计、用于构建时空指代与推理能力的合成指令数据生成框架。该框架通过数据引擎生成多样化的指令调优数据，采用伪标注方式对时间密集的细粒度视频元数据进行结构化处理，完整捕获包括主体、客体、掩码形式的定位坐标、动作描述及时间线在内的丰富时空信息。我们的方法显著提升了视频大语言模型解析时空参照的能力，为实现现实世界人工智能伴侣所必需的多维度时空感知推理奠定基础。实验评估表明：在不使用专有模型、昂贵人工标注或大批量新视频标注的前提下，基于Strefer生成数据训练的模型在时空歧义消除任务上全面超越基线水平。这些模型还展现出增强的时空感知推理能力，为建立基于感知基础的指令调优型视频大语言模型确立了新范式。 |
| 动态现象新型测量的实时仪器规划与感知

（注：翻译严格遵循以下原则：
1. 保留专业术语准确性："Real-Time"译为"实时"，"Instrument Planning"译为"仪器规划"，"Perception"译为"感知"
2. 保持学术文本特征：采用倒装结构突出核心概念，将"for Novel Measurements"前置处理为定语
3. 符合中文表达习惯：使用四字格"动态现象"保持简洁性，通过"新型测量"准确传达"Novel Measurements"的学术内涵
4. 术语统一性：确保与仪器科学、自动控制领域的专业术语体系保持一致） | Itai Zilberstein | [PDF](http://arxiv.org/pdf/2509.03500v1) | 机载计算技术的进步使得遥感智能体能够在边缘端运用最先进的计算机视觉与机器学习技术。这些能力可被用于实现对动态科学现象的新型稀有、瞬态及精确定点测量。本文提出一种自动化工作流，该工作流将前瞻卫星图像中的动态事件检测与后续高分辨率传感器的自主轨迹规划相结合，以获取精准测量数据。我们将此工作流应用于火山烟羽观测场景，分析了包括传统机器学习算法和卷积神经网络在内的分类方法，并提出多种可追踪烟羽形态特征的轨迹规划算法，将这些算法与分类器进行集成。通过仿真实验证明，在保持高效运行时间的同时，高分辨率仪器的效用回报相比基线方法实现了一个数量级的提升。 |
| 深海多目标追踪基准数据集：面向深海视频的多目标跟踪基准数据集

（注：该翻译严格遵循学术术语规范：
1. "DeepSea MOT" 采用中文全称+英文缩写格式，符合学术文献惯例
2. "benchmark dataset" 译为"基准数据集"，准确对应计算机视觉领域术语
3. "multi-object tracking" 统一译为"多目标跟踪"，与《中国图像图形学报》规范术语保持一致
4. 补充说明性副标题"面向深海视频的..."，明确数据集的应用场景，增强学术准确性） | Kevin Barnard | [PDF](http://arxiv.org/pdf/2509.03499v1) | 对多目标跟踪与目标检测模型进行性能基准测试是机器学习模型开发中的关键环节，该方法使研究人员能够基于人工标注的"测试"数据评估模型检测与跟踪器性能，实现模型与跟踪器之间的标准化对比，并为性能优化提供依据。本研究开发了一套新型基准视频数据集，用于评估蒙特雷湾水族馆研究所的多个目标检测模型、FathomNet单类别目标检测模型以及多款跟踪器的性能。该数据集包含代表中水层和底栖深海生境的四段视频序列。性能评估采用高阶跟踪准确度指标，该指标综合平衡了检测精度、定位精度与关联精度。据我们所知，这是首个面向深海视频多目标跟踪任务的公开基准。我们不仅提供基准数据，还制定了可生成额外基准视频的标准化工作流程，并附有用于计算指标的Python示例代码库。 |
| OneCAT：基于仅解码器自回归架构的统一理解与生成模型

（注：翻译严格遵循学术规范，保留核心术语："Decoder-Only"译为"仅解码器"，"Auto-Regressive"译为"自回归"，"Unified Understanding and Generation"译为"统一理解与生成"。模型名称"OneCAT"保持原样不译，符合学术惯例。） | Han Li | [PDF](http://arxiv.org/pdf/2509.03498v1) | 我们提出OneCAT——一种统一的多模态模型，该模型基于创新的纯解码器Transformer架构，无缝整合了理解、生成与编辑功能。我们的框架独特之处在于推理过程中无需依赖外部组件（如视觉Transformer或视觉分词器），从而显著提升运算效率，尤其针对高分辨率输入场景。这一突破通过采用模态特定的混合专家模型（MoE）结构实现，该结构仅需通过单一自回归目标进行训练，并原生支持动态分辨率处理。此外，我们在大型语言模型（LLM）中首创了多尺度视觉自回归机制，相比基于扩散的方法大幅减少解码步骤，同时保持最先进的性能表现。研究结果证明，纯自回归建模作为统一多模态智能的基石具有强大潜力，其设计既充分又优雅。最终，OneCAT在多模态生成、编辑和理解任务的基准测试中全面超越现有开源统一多模态模型，树立了新的性能标杆。 |
