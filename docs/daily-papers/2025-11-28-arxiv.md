# arxiv 2025-11-28

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 重探跨难度水平的泛化能力：并非易事 | Yeganeh Kordi | [PDF](https://arxiv.org/pdf/2511.21692v1) | 我们研究大型语言模型（LLMs）在不同任务难度间的泛化能力，这是影响数据筛选与评估效果的核心问题。现有研究对“使用简单或困难数据训练能否获得更好结果”以及“效果提升体现在简单还是困难测试数据上”等问题尚未达成共识。为解决这一问题，我们通过系统化评估方法，从模型架构、数据集和样本难度细分组别三个维度探究LLMs的泛化表现。基于数千种不同LLMs的输出结果并结合教育测试领域的成熟难度度量标准——项目反应理论（IRT），我们对六个数据集中的样本进行难度分级。与既往研究不同，我们的难度评级完全基于多种LLMs的自身能力，排除了人类对难度的主观判断。通过更客观、大规模、细粒度的分析，我们发现跨难度泛化能力往往存在局限：仅使用简单或困难数据进行训练，均无法在全部难度范围内实现持续改进。这些结果表明，在LLMs的训练和评估数据中保持难度多样性至关重要，任何在难度维度上走捷径的做法都存在风险。 |
| 画布到图像：基于多模态控制的组合式图像生成 | Yusuf Dalva | [PDF](https://arxiv.org/pdf/2511.21691v1) | 尽管现代扩散模型在生成高质量多样化图像方面表现出色，但在实现高保真度的组合式与多模态控制方面仍存在困难——特别是当用户需要同时指定文本提示、主体参照、空间排布、姿态约束和布局标注时。我们提出“画布到图像”统一框架，将这些异构控制要素整合至单一画布界面，使用户能够生成精准反映创作意图的图像。其核心思想是将多样化控制信号编码为复合画布图像，使模型能够直接进行视觉空间整合推理。我们进一步构建了多任务数据集，并提出多任务画布训练策略，通过统一学习范式优化扩散模型对异构控制的理解与整合能力。这种联合训练使Canvas-to-Image能够跨越多重控制模态进行推理，而非依赖特定任务启发式方法，并在推理阶段展现出对多控制场景的优异泛化能力。大量实验表明，在多人组合、姿态控制合成、布局约束生成及多控制生成等挑战性基准测试中，Canvas-to-Image在身份保持与控制遵循度方面显著优于现有前沿方法。 |
| TraceGen：在三维轨迹空间中构建世界模型实现跨具身视频学习

（解析：1. "TraceGen"作为专有名词保留不译；2. "World Modeling"译为"构建世界模型"更符合中文计算机领域表述习惯；3. "3D Trace Space"精准译为"三维轨迹空间"保持专业术语一致性；4. "Cross-Embodiment Videos"译为"跨具身视频"准确传达不同物理实体形态的核心概念，其中"具身"是embodiment在机器人学领域的标准译法；5. 整体采用主副标题结构，通过冒号分隔保持学术论文标题的规范格式） | Seungjae Lee | [PDF](https://arxiv.org/pdf/2511.21690v1) | 仅通过少量演示就能在新平台和新场景中学习新机器人任务仍具挑战性。尽管人类和其他机器人的示范视频资源丰富，但形态结构、相机参数和环境差异阻碍了这些视频的直接使用。我们通过引入统一的符号化表征——场景级轨迹的紧凑三维“轨迹空间”，解决了小数据量问题，该表征支持从跨形态、跨环境和跨任务的视频中学习。我们提出TraceGen世界模型，该模型在轨迹空间而非像素空间预测未来运动，在保留操作所需几何结构的同时抽象掉外观特征。为实现大规模训练，我们开发了TraceForge数据流水线，将异构的人类与机器人视频转化为一致的三维轨迹，构建包含12.3万条视频和180万个观察-轨迹-语言三元组的数据集。基于该数据集的预训练产生了可迁移的三维运动先验模型：仅需五段目标机器人视频，TraceGen在四项任务中达成80%成功率，同时推理速度比基于视频的先进世界模型快50-600倍。在更具挑战性的场景中（仅能通过手持手机获取五段未标定的人类演示视频），该模型在真实机器人上仍达到67.5%的成功率，彰显了TraceGen在不依赖物体检测器或繁重像素空间生成的情况下实现跨形态适应的能力。 |
| 工具交响曲：通过高效模型与工具编排提升智能水平 | Hongjin Su | [PDF](https://arxiv.org/pdf/2511.21689v1) | 大型语言模型是强大的通用系统，但在解决诸如"人类终极考试"这类深度复杂问题时，仍面临概念层面的挑战与高昂的计算成本。我们研究表明，通过小型调度器协调管理其他模型与多样化工具，既能突破智能水平上限，又能提升复杂智能体任务的解决效率。我们提出ToolOrchestra训练方法，专门培养协调智能工具的小型调度器。该方法创新性地采用强化学习框架，综合考量任务结果、执行效率与用户偏好的多维度奖励机制。基于此训练出的Orchestrator模型（参数量80亿）在保证更高准确率的同时，实现了低于既往工具使用智能体的运算成本，并能根据用户偏好自动匹配查询任务的最适工具。在HLE测试中，Orchestrator以37.1%的得分超越GPT-5（35.1%），效率提升2.5倍；在tau2-Bench与FRAMES基准测试中，该模型以约30%的成本实现显著优势。深入分析表明，Orchestrator在多项指标下均达到性能与成本的最佳平衡，并对未见工具展现出强大泛化能力。这些成果验证了轻量级调度模型组合多样化工具的范式，相较现有方法兼具更高效率与更强效能，为构建实用可扩展的工具增强推理系统开辟了新路径。 |
| G$^2$VLM：基于几何基础的视觉语言模型——融合统一三维重建与空间推理能力

（注：译文通过"几何基础"对应"Geometry Grounded"的学术内涵，采用破折号结构明晰技术特性，保留上标格式维持数学表达规范，同时通过"融合""能力"等术语准确传达"Unified"的系统集成特性与模型功能定位。） | Wenbo Hu | [PDF](https://arxiv.org/pdf/2511.21688v1) | 视觉语言模型（VLMs）在空间智能方面仍缺乏鲁棒性，在空间理解与推理任务中表现欠佳。我们认为这一缺陷源于缺乏能够从二维图像重建三维空间的视觉几何学习过程。本文提出G$^2$VLM——一种基于几何基础的视觉语言模型，该模型融合了空间智能的两个核心维度：三维空间重建与空间语义理解。G$^2$VLM原生利用学习得到的三维视觉几何特征，既能直接预测三维属性，又可通过上下文学习与交叉推理增强空间推理任务。我们的统一架构在空间理解方面具有高度扩展性：既能利用海量多视角图像和视频数据进行训练，又能获得通常仅通过难以采集的标注数据才能构建的三维视觉先验优势。实验结果表明，G$^2$VLM在双重任务中均表现卓越，其三维重建效果可比肩最先进的前馈式三维重建模型，在空间理解与推理任务中更是取得领先或具有竞争力的成绩。通过将强语义视觉语言模型与底层三维视觉任务相融合，我们希望G$^2$VLM能成为该领域的强基准，并为三维场景编辑等未来应用开启更多可能性。 |
| 矩阵：点对点多智能体合成数据生成框架 | Dong Wang | [PDF](https://arxiv.org/pdf/2511.21686v1) | 合成数据对于训练大语言模型日益重要，尤其在真实数据稀缺、成本高昂或涉及隐私敏感的场景下。当前多数生成任务需要协调多智能体工作流，通过专业化智能体的协作来生成质量更高、多样性更丰富且结构更复杂的数据。然而，现有多智能体合成框架通常依赖中心化编排器，存在可扩展性瓶颈，或是为特定领域硬编码实现，缺乏灵活性。我们提出\textbf{Matrix}——一种去中心化框架，将控制流与数据流统一表征为通过分布式队列传递的序列化消息。这种点对点设计消除了中心编排器，每个任务通过轻量级智能体独立推进，而计算密集型操作（如LLM推理或容器化环境）则由分布式服务处理。基于Ray构建的Matrix可扩展至数万个并发智能体工作流，其模块化可配置设计能轻松适配各类数据生成流程。我们在多智能体协作对话、基于网页的推理数据提取、客服场景下的工具使用轨迹生成等多样化合成场景中评估Matrix。在所有案例中，Matrix在相同硬件资源下实现了数据生成吞吐量$2$--$15$倍的提升，且输出质量不受影响。 |
| 无像素视觉：基于相机轨迹的感知 | Zihui Xue | [PDF](https://arxiv.org/pdf/2511.21681v1) | 能否仅凭相机运动轨迹——即其在空间中划过的路径，而非观察像素信息，来理解视频内容？本文首次系统性地探讨这个看似不可能的问题。为此，我们提出一种对比学习框架，用以训练专有编码器CamFormer，该模型将相机位姿轨迹映射到联合嵌入空间，使其与自然语言表征对齐。研究发现，相机轨迹虽看似简单，实则是揭示视频内容的高度信息化信号。换言之，“如何移动”确实能揭示“正在做什么”（第一人称视角）或“观察什么”（第三人称视角）。我们在多类下游任务中验证了CamFormer嵌入向量的通用性，涵盖跨模态对齐、分类与时序分析等领域。值得注意的是，我们的表征对不同相机位姿估计方法均具鲁棒性，既适用于高精度多传感器方案，也兼容标准纯RGB估计器。本研究证实：相机轨迹是一种轻量化、强鲁棒性且多功能的视频内容感知模态。 |
| 具有成长与精炼多模态语义记忆的能动学习者

（解析说明：
1. Agentic Learner 译为"能动学习者"，强调学习者的自主性与能动性
2. Grow-and-Refine 采用"成长与精炼"的译法，准确传达"生长完善"与"迭代优化"的双重含义
3. Multimodal Semantic Memory 译为"多模态语义记忆"，保持专业术语的准确性
4. 整体采用"定语前置"的中文表达习惯，通过"的"字结构实现术语的紧凑衔接） | Weihao Bo | [PDF](https://arxiv.org/pdf/2511.21678v1) | 多模态大语言模型在独立查询中展现出强大的推理能力，但其运作始终从零开始——每个问题都独立求解，且常重复相同错误。现有记忆增强智能体主要存储过往轨迹以供复用，然而基于轨迹的记忆存在简略偏差，会逐渐丢失关键领域知识。更严重的是，即使在真正的多模态问题解决场景中，这类系统仅记录单模态的行为轨迹，未能保留视觉注意力与逻辑推理如何协同促成解决方案。这与人类认知存在根本性错位：语义记忆兼具多模态与整合特性，通过协调而独立的表征流同时保存视觉与抽象知识。为此我们提出ViLoMem双流记忆框架，构建基于图式的紧凑记忆系统。该框架分别编码视觉分心模式与逻辑推理错误，使多模态大语言模型能从成败经验中学习。遵循生长-精炼原则，系统持续积累并更新多模态语义知识——在保持稳定、可泛化策略的同时避免灾难性遗忘。在六大多模态基准测试中，ViLoMem持续提升pass@1准确率，并显著减少重复的视觉与逻辑错误。消融实验证实了具有显式分心-幻觉分离的双流记忆的必要性，验证了错误感知多模态记忆在终身学习与跨域智能体学习中的价值。项目页面详见 https://weihao-bo.github.io/ViLoMeo-page。 |
| 基于演化模型的干扰下实验研究 | Sadegh Shirani | [PDF](https://arxiv.org/pdf/2511.21675v1) | 网络系统中的因果效应估计是数据驱动决策的核心问题。在此类场景中，对单个单元实施的干预可能产生溢出效应，而在复杂的物理或社会系统中，驱动这些干扰结构的相互作用路径大多不可观测。我们认为，要识别总体层面的因果效应，无需还原精确的网络结构；相反，只需刻画这些相互作用如何影响结果演化即可。基于此原理，我们研究了一种基于演化的方法：通过观察多轮实验中结果变量如何随干预措施变化，从而弥补缺失的网络信息。借助暴露映射的视角，我们给出了结果变量经验分布遵循低维递归方程的公理化特征，并确定了此类演化映射存在的最小结构条件。这可视作双重差分法的分布形态对应物——该方法并非假设个体单元具有平行路径，而是利用不同处理情境间的平行演化模式来估计反事实轨迹。关键洞见在于：随机化处理除消除潜在混杂因素外，更通过隐式采样隐藏的干扰通道，使异质溢出效应的一致学习成为可能。我们提出因果消息传递作为该方法在稠密网络中的具体实现，并将其扩展至更普遍的干扰结构（包括少数单元主导多数溢出效应的影响者网络）。最后通过论证强烈的时间趋势或内生性干扰可能破坏识别效果，我们揭示了该方法的局限性。 |
| 大型稀疏网络中的事件驱动资格传播：生物现实性塑造的效率

（该翻译在保持专业术语准确性的基础上，采用符合中文计算机科学/神经科学领域论文标题的表述习惯，通过冒号分隔主副标题结构，其中：
1. "Event-driven"译为"事件驱动"符合计算机领域术语规范
2. "Eligibility propagation"译为"资格传播"对应神经网络学习机制术语
3. "Biological realism"译为"生物现实性"体现神经科学领域对生物可信度的关注
4. 主谓结构"efficiency shaped by..."转化为偏正结构"生物现实性塑造的效率"更符合中文标题表达特点） | Agnes Korcsak-Gorzo | [PDF](https://arxiv.org/pdf/2511.21674v1) | 尽管技术已取得显著进步，人工智能系统仍可从生物原理中获益，例如循环连接结构与高能效机制。受大脑运作机制启发，我们提出一种具有生物合理性的扩展型合格信号传播学习规则，适用于脉冲循环神经网络。通过将时间驱动更新机制转化为事件驱动模式，我们将该学习规则整合至大规模脉冲神经网络仿真平台，并验证其在神经形态MNIST等任务中的适用性。我们通过引入连续动力学与权重更新、严格局部性以及稀疏连接等典型生物特征来扩展该模型。研究结果表明，基于生物学的约束条件可为设计计算高效的人工智能算法提供指导，在保持学习性能的同时实现百万级神经元的可扩展性。这项研究搭建了机器学习与计算神经科学之间的桥梁，不仅推动了对类脑学习机制的理解，更为开发可持续的生物启发式人工智能系统开辟了新路径。 |
