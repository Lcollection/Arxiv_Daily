# arxiv 2025-12-15

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 基于矩的三维高斯泼溅：利用顺序无关透射率解决体积遮挡问题 | Jan U. Müller | [PDF](https://arxiv.org/pdf/2512.11800v1) | 近期，三维高斯泼溅（3DGS）技术的突破性进展，通过实现高质量辐射场的快速优化与实时渲染，重塑了新颖视角合成领域。然而，该方法依赖于简化的、顺序相关的阿尔法混合技术，以及在光栅化器中采用粗略的密度积分近似，这限制了其渲染复杂、重叠的半透明物体的能力。本文提出一种基于光栅化的三维高斯表示渲染新方法，通过高精度透射率计算完全避免了光线追踪或逐像素采样排序的需求。基于先前在基于矩量法的顺序无关透明度研究基础上，我们的核心思想是利用基于统计矩量的紧凑连续表示，来刻画每条相机射线上的密度分布。为此，我们从所有参与贡献的三维高斯分布中解析推导并计算出一组逐像素矩量。通过这些矩量，我们为每条射线重建出连续透射函数，进而在每个高斯分布内进行独立采样。由此，我们的方法通过模拟复杂半透明介质中的光衰减过程，弥合了光栅化与物理精度之间的鸿沟，显著提升了整体重建与渲染质量。 |
| V-RGBX：基于内在属性精确控制的视频编辑技术 | Ye Fang | [PDF](https://arxiv.org/pdf/2512.11799v1) | 大规模视频生成模型在模拟真实场景中的逼真外观与光照交互方面展现出显著潜力。然而，能够同时理解场景固有属性（如反照率、法线、材质和辐照度）、利用这些属性进行视频合成，并支持可编辑固有表征的闭环框架仍属空白。我们提出V-RGBX——首个面向固有属性感知视频编辑的端到端框架。V-RGBX集成了三大核心能力：（1）将视频逆向渲染为固有通道；（2）基于固有表征生成逼真视频；（3）以固有通道为条件的关键帧视频编辑。该框架的核心在于交错条件机制，通过用户选择的关键帧实现直观且符合物理规律的视频编辑，支持对任意固有模态的灵活操控。大量定性与定量实验表明，V-RGBX能生成时序连贯的逼真视频，并以符合物理规律的方式将关键帧编辑效果跨序列传播。我们在物体外观编辑与场景级重照明等多样化应用中验证了其有效性，其性能超越现有方法。 |
| 颗粒物：前馈式三维物体关节化 | Ruining Li | [PDF](https://arxiv.org/pdf/2512.11798v1) | 我们提出了一种名为Particulate的前馈方法，该方法能够基于日常物体的单个静态三维网格，直接推断出底层关节结构的所有属性，包括其三维部件、运动学结构以及运动约束。该方法的核心是一个Transformer网络——部件关节变换器，它通过灵活且可扩展的架构处理输入网格的点云数据，以原生多关节支持的方式预测所有上述属性。我们在来自公共数据集的多样化关节三维资产上对网络进行了端到端训练。在推理过程中，Particulate将网络的前馈预测结果映射到输入网格上，在数秒内生成完全关节化的三维模型，这比以往需要逐对象优化的方法快得多。Particulate还能准确推断AI生成的三维资产的关节结构，当与现成的图像到三维生成器结合时，能够从单张（真实或合成）图像中完整提取关节化的三维物体。我们进一步引入了一个基于高质量公共三维资产构建的、具有挑战性的三维关节估计新基准，并重新设计了评估协议，使其更符合人类偏好。定量和定性结果表明，Particulate显著优于当前最先进的方法。 |
| 锚点梦境：将视频扩散模型改造用于具身感知机器人数据合成 | Junjie Ye | [PDF](https://arxiv.org/pdf/2512.11797v1) | 大规模、多样化的机器人演示数据收集仍是模仿学习的主要瓶颈，因为现实世界数据获取成本高昂，而仿真器提供的多样性和保真度有限，且存在显著的仿真与现实差距。尽管生成模型提供了颇具吸引力的解决方案，但现有方法通常仅改变视觉外观而未能创造新行为，或存在本体不一致导致动作不合理的问题。为突破这些限制，我们提出了AnchorDream——一种具备本体感知的世界模型，该模型通过改造预训练视频扩散模型实现机器人数据合成。AnchorDream将扩散过程以机器人运动渲染为条件，通过锚定本体结构防止生成幻觉，同时合成与机器人运动学特性一致的对象和环境。仅需少量人工遥操作演示数据，我们的方法即可将其扩展为大规模、多样化、高质量的数据集，且无需显式环境建模。实验表明，生成数据能持续提升下游策略学习效果：在仿真基准测试中相对提升36.4%，在现实世界研究中性能提升近一倍。这些结果表明，将生成式世界模型锚定于机器人运动，为扩展模仿学习提供了切实可行的路径。 |
| 一种通过随机顺序添加检测高阶交互的通用算法 | Ahmad Shamail | [PDF](https://arxiv.org/pdf/2512.11793v1) | 许多系统在其组件间展现出复杂的相互作用：某些特征或行为会相互增强效果，另一些则提供冗余信息，还有一些独立发挥作用。我们提出一种发现相互作用与冗余性的简单几何方法：当元素以随机顺序依次添加，并在多次试验中绘制其贡献度时，会呈现出独特的L形模式，这些模式直接反映了相互作用结构。该方法量化了每个元素的贡献如何依赖于先添加的元素，在一个统一尺度上揭示了区分相互作用、独立性和冗余性的模式。当将成对贡献可视化为二维点云时，冗余对会形成L形模式——仅先添加的元素产生贡献；而协同对则形成L形模式——仅当元素共同作用时才产生贡献。独立元素则呈现顺序不变的分布特征。我们通过L分数对此进行形式化描述：该连续度量值域为$-1$（完全协同，例如$Y=X_1X_2$）至$0$（独立）至$+1$（完全冗余，$X_1 \approx X_2$）。L形臂的相对比例揭示了特征主导性，即哪些元素能持续提供更多信息。尽管仅通过成对测量计算，但三个及以上元素的高阶相互作用可通过跨对关系（如AB、AC、BC）的一致性自然显现。该方法不依赖具体度量标准，可广泛应用于任何能通过非重复元素序列进行增量性能评估的领域，为揭示相互作用结构提供了统一的几何分析框架。 |
| 从追踪中构建结构：为视频生成提炼结构保持性运动 | Yang Fei | [PDF](https://arxiv.org/pdf/2512.11792v1) | 现实是刚性约束与可变形结构之间的动态博弈。对于视频模型而言，这意味着生成既保持保真度又维持结构完整性的运动。尽管扩散模型已取得进展，但生成具有真实感且保持结构一致的运动仍然具有挑战性，尤其对于人类和动物这类具有关节结构与可变形特性的对象。迄今为止，仅通过扩大训练数据规模仍无法解决物理上不合理的运动过渡问题。现有方法依赖于带有噪声的运动表征作为条件输入，例如光流或通过外部不完美模型提取的骨骼关键点。

为应对这些挑战，我们提出一种算法，将自回归视频跟踪模型（SAM2）中保持结构一致的运动先验知识蒸馏至双向视频扩散模型（CogVideoX）。基于该方法，我们训练出SAM2VideoX模型，其包含两项创新：（1）双向特征融合模块，可从SAM2这类循环模型中提取全局结构保持的运动先验；（2）局部格拉姆流损失函数，用于对齐局部特征的协同运动模式。

在VBench基准测试和人类评估实验中，SAM2VideoX相较于现有基线模型均取得稳定提升（VBench评分提升2.60%，FVD降低21-22%，人类偏好率达71.4%）。具体而言，在VBench上我们获得95.51%的评分，较REPA模型（92.91%）提升2.60%；同时将FVD指标降至360.57，较REPA微调与LoRA微调方法分别提升21.20%和22.46%。项目网站详见 https://sam2videox.github.io/。 |
| 临床照片中白癜风分割的不确定性感知域适应方法 | Wentao Jiang | [PDF](https://arxiv.org/pdf/2512.11791v1) | 在常规临床照片中准确量化白癜风皮损范围，对治疗反应的纵向监测至关重要。我们提出一个可信赖的、具有频率感知能力的分割框架，该框架建立在三个协同支柱之上：(1) 采用数据高效训练策略，结合在ISIC 2019数据集上的域自适应预训练与ROI约束的双任务损失函数，以抑制背景噪声；(2) 通过基于ConvNeXt V2的编码器进行架构优化，引入新型高频谱门控模块及主干跳跃连接以捕捉细微纹理特征；(3) 建立临床信任机制，采用K折集成与测试时增强技术生成像素级不确定性图谱。在专家标注的临床队列上进行广泛验证表明，该方法性能卓越：Dice系数达85.05%，边界误差显著降低（95%豪斯多夫距离从44.79像素改善至29.95像素），持续优于主流CNN与Transformer基线模型。值得注意的是，本框架展现出零灾难性失误的高可靠性，并能提供可解释的熵值图谱以标识需临床医生复核的模糊区域。本研究提出的框架为自动化白癜风评估建立了稳健可靠的新标准。 |
| 在大提示符机制下作为线性注意力的Softmax：基于度量的视角 | Etienne Boursier | [PDF](https://arxiv.org/pdf/2512.11784v1) | Softmax注意力是Transformer架构的核心组件，但其非线性结构给理论分析带来了重大挑战。我们建立了一个统一的、基于测度的框架，用于研究有限提示与无限提示下的单层softmax注意力机制。对于独立同分布的高斯输入，我们依据以下事实展开分析：softmax算子在无限提示极限下收敛为作用于底层输入标记测度的线性算子。基于这一洞见，我们建立了softmax注意力输出与梯度的非渐近集中界，量化了有限提示模型逼近其无限提示对应模型的速度，并证明在具有亚高斯标记的一般上下文学习场景中，这种集中性在整个训练轨迹上保持稳定。针对上下文线性回归场景，我们利用可处理的无限提示动力学来分析有限提示长度下的训练过程。我们的研究结果表明，当提示足够长时，针对线性注意力开发的优化分析可直接迁移至softmax注意力，证明了大提示规模下的softmax注意力继承了其线性对应模型的分析结构。这进而为研究大提示场景下softmax注意力层的训练动力学与统计行为，提供了一个原理性且广泛适用的分析工具包。 |
| 超级后缀：同时绕过文本生成对齐与防护模型 | Andrew Adiletta | [PDF](https://arxiv.org/pdf/2512.11783v1) | 大型语言模型（LLMs）的快速部署，使得机器学习（ML）领域对增强安全与隐私措施的需求日益迫切。当前，LLMs越来越多地被用于处理不可信的文本输入，甚至生成可执行代码，同时往往还具备访问敏感系统控制的权限。为应对这些安全隐患，多家公司已推出防护模型——这类规模较小、专门设计的模型旨在保护文本生成模型免受对抗性或恶意输入的侵害。

本研究通过引入"超级后缀"（Super Suffixes）推进了对对抗性输入的研究。这类后缀能够突破采用不同分词方案的各种模型的多重对齐目标。我们通过联合优化技术，在五个不同的文本生成模型上成功绕过了Llama Prompt Guard 2针对恶意文本和代码生成的防护机制，验证了该方法的有效性。据我们所知，这是首个揭示Llama Prompt Guard 2可通过联合优化被攻破的研究。

此外，通过分析模型在处理词元序列时内部状态与特定概念方向相似度的动态变化，我们提出了一种高效轻量的超级后缀攻击检测方法。研究表明，残差流与特定概念方向之间的余弦相似度可作为模型意图的独特指纹。我们提出的防御方案DeltaGuard显著提升了针对超级后缀生成的恶意提示的检测能力，将非良性分类率提升至近100%。这使得DeltaGuard成为防护模型体系中的重要补充，有效增强了对抗性提示攻击的防御鲁棒性。 |
| MatAnyone 2：通过学习的质量评估器实现视频抠图规模化 | Peiqing Yang | [PDF](https://arxiv.org/pdf/2512.11782v1) | 视频抠图技术仍受限于现有数据集的规模和真实性。尽管利用分割数据可提升语义稳定性，但缺乏有效的边界监督常导致抠图结果呈现类分割效果，缺失精细细节。为此，我们提出一种可学习的抠图质量评估器（MQE），该评估器无需真实标注即可评估阿尔法遮罩的语义与边界质量。它能生成像素级评估图，精准定位可靠区域与错误区域，实现细粒度质量评估。MQE通过两种方式扩展视频抠图能力：（1）作为训练期间的在线抠图质量反馈机制，通过抑制错误区域提供全面监督；（2）作为离线数据筛选模块，融合领先视频与图像抠图模型的优势以提升标注质量。基于此流程，我们构建了大规模真实世界视频抠图数据集VMReal，包含2.8万条视频片段与240万帧图像。为处理长视频中的大幅外观变化，我们提出参考帧训练策略，引入局部窗口外的长程帧进行高效训练。我们的MatAnyone 2模型在合成与真实世界基准测试中均取得最先进性能，各项指标全面超越现有方法。 |
