# arxiv 2025-10-24

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| HoloCine：电影级多镜头长视频叙事的整体生成技术

（注：HoloCine作为专有名词保留原格式，通过冒号后的解释性翻译完整呈现技术内涵。"Holistic Generation"译为"整体生成"以体现系统化创作理念，"Cinematic Multi-Shot Long Video Narratives"采用"电影级多镜头长视频叙事"的译法，既保持学术准确性又符合中文技术表达习惯，通过"电影级"定性、"多镜头"描述技术特征、"长视频"界定载体形式、"叙事"点明创作本质，完整传递原文的技术维度与艺术特质。） | Yihao Meng | [PDF](http://arxiv.org/pdf/2510.20822v1) | 当前最先进的文生视频模型虽能生成独立片段，却难以构建连贯的多镜头叙事——而这正是故事讲述的核心。我们通过HoloCine模型弥合这一"叙事鸿沟"，该模型能够整体生成完整场景，确保从首个镜头到最终画面的全局一致性。我们的架构通过两项创新实现精准导演控制：窗口交叉注意力机制将文本提示定位至特定镜头，而稀疏镜头间自注意力模式（镜头内稠密计算，镜头间稀疏连接）则满足分钟级生成所需的效率要求。除在叙事连贯性方面树立新标杆外，HoloCine还展现出卓越的涌现能力：对角色与场景的持久记忆，以及对电影技法的直观把握。本工作标志着从片段合成到自动化电影制作的关键转变，使端到端的电影创作成为可触及的未来。代码已开源：https://holo-cine.github.io/。 |
| 层组合器：基于空间感知分层画布的交互式个性化文本到图像生成

（注：该翻译采用学术术语规范，保留核心概念"LayerComposer"的直译特征，同时通过"空间感知分层画布"准确传达"Spacially-Aware Layered Canvas"的技术内涵，使用"交互式个性化文本到图像生成"完整对应"Interactive Personalized T2I"的功能描述，符合人机交互与计算机图形学领域的专业表达习惯。） | Guocheng Gordon Qian | [PDF](http://arxiv.org/pdf/2510.20820v1) | 尽管现有个性化生成模型具有令人印象深刻的视觉保真度，但其缺乏对空间构图的交互控制，且在处理多主体场景时扩展性欠佳。为解决这些局限性，我们提出LayerComposer——一个支持交互式个性化多主体文生图的框架。我们的方法包含两大核心贡献：（1）分层画布：一种创新表征形式，将每个主体置于独立图层，实现无遮挡构图；（2）锁定机制：在保持选定图层高保真度的同时，允许其余图层灵活适应周边语境。与专业图像编辑软件类似，所提出的分层画布支持用户通过直观的图层操作来放置、缩放或锁定输入主体。我们的通用锁定机制无需改变模型架构，而是通过固有位置编码与创新的互补数据采样策略实现。大量实验表明，在多主体个性化图像生成任务中，LayerComposer相比现有最优方法实现了更卓越的空间控制与身份特征保持能力。 |
| 迈向通用模态转换：基于对比与预测的潜在扩散桥接方法

（解析：该翻译遵循以下原则：
1. 学术术语精准对应：
   - "Modality Translation"译为"模态转换"（非"模式翻译"）
   - "Latent Diffusion"保留专业术语"潜在扩散"
   - "Contrastive and Predictive"译为"对比与预测"

2. 句式结构优化：
   - 将英文介词结构"Towards..."转化为中文动词导向的"迈向..."
   - 使用冒号实现标题分层，符合中文论文标题规范

3. 专业概念完整传递：
   - "Bridge"译为"桥接方法"体现技术手段
   - 保持"潜在扩散"与"模态转换"的技术逻辑关联

4. 中文表达习惯：
   - 采用四字格"对比与预测"增强节奏感
   - 使用"方法"作为隐性中心词，符合中文标题省略倾向） | Nimrod Berman | [PDF](http://arxiv.org/pdf/2510.20819v1) | 生成建模领域的最新进展使扩散模型成为从复杂数据分布中采样的前沿工具。尽管这些模型在图像、音频等单模态领域取得了显著成功，但将其能力扩展到模态翻译——即在不同感官模态间转换信息——仍是一个待解决的挑战。现有方法通常依赖限制性假设，包括共享维度、高斯源先验和模态特定架构，这限制了其普适性和理论基础。本文提出潜在去噪扩散桥模型（LDDBM），这是一个基于潜在变量扩展的去噪扩散桥模型的通用模态翻译框架。通过在共享潜在空间中操作，我们的方法能够学习任意模态间的桥梁，无需对齐维度。我们引入对比对齐损失来增强配对样本间的语义一致性，并设计了适用于潜在空间噪声预测的领域无关编码器-解码器架构。此外，我们提出预测损失以引导训练实现准确的跨域翻译，并探索了多种提升训练稳定性的策略。该方法支持任意模态对组合，在多视图到三维形状生成、图像超分辨率及多视图场景合成等多样化模态翻译任务中表现优异。全面实验与消融研究验证了我们框架的有效性，为通用模态翻译建立了新的强基线。更多信息请访问项目页面：https://sites.google.com/view/lddbm/home。 |
| VAMOS：一种支持能力调制与可控导航的分层视觉-语言-行动模型

（注：该翻译在保持专业术语准确性的基础上，采用"分层"对应"Hierarchical"以体现系统架构特性，"能力调制"对应"Capability-Modulated"强调动态调节机制，"可控导航"对应"Steerable Navigation"突出路径规划的可控性，整体表述符合中文人工智能领域的学术表达规范。） | Mateo Guaman Castro | [PDF](http://arxiv.org/pdf/2510.20818v1) | 机器人导航领域的一个根本性挑战在于：如何学习能够适应多样化环境，同时符合特定实体独特物理约束与能力（例如四足机器人可攀爬楼梯，但轮式机器人无法实现）的决策策略。我们提出VLA分层框架VAMOS，通过语义规划与实体接地的解耦实现这一目标：通用规划器从多样化的开放世界数据中学习，而专用功能可供性模型则在安全低成本的仿真环境中学习机器人的物理约束与能力。我们通过精心设计交互接口实现这种分离——高层规划器直接在图像空间生成候选路径，功能可供性模型随后对这些路径进行评估与重排序。真实环境实验表明，VAMOS在室内及复杂室外导航任务中的成功率均优于当前最先进的基于模型方法和端到端学习方法。我们的分层设计还实现了腿式与轮式机器人的跨实体导航，并能通过自然语言便捷引导。真实场景消融实验证实，专用模型是实现实体接地的关键，使得单一高层规划器可部署于物理结构迥异的轮式与腿式机器人。最终，该模型通过拒绝物理不可行方案，将单机器人任务成功率提升至三倍，显著增强了系统可靠性。项目网站：https://vamos-vla.github.io/ |
| KL正则化强化学习旨在解决模型坍塌问题 | Anthony GX-Chen | [PDF](http://arxiv.org/pdf/2510.20817v1) | 普遍认为，优化反向KL散度会导致"模式聚焦"行为，而优化前向KL散度则会产生"质量覆盖"效果——若目标是从多个多样化模式中采样，后者通常更受青睐。我们通过数学证明和实验验证表明：这种直觉认知未必适用于基于反向/前向KL正则化的强化学习（例如语言模型中常用的方法）。实际上，反向/前向KL的选择决定了由正则化系数参数化的最优目标分布族。模式覆盖程度主要取决于其他因素，包括正则化强度、奖励函数与参考概率之间的相对尺度等。进一步研究发现，常用设置（如低正则化强度和等值可验证奖励）往往指定单峰目标分布，这意味着优化目标在构造上就缺乏多样性。基于这些发现，我们构建了一个简洁可扩展且理论完备的算法。该算法对奖励量级进行最小化调整，却能优化目标分布使其在所有高质量采样模式上均保持高概率。实验表明，这一简单改进能有效提升大型语言模型与化学语言模型的后期训练效果，在无需外部多样性信号的情况下，同时增强解决方案的质量与多样性，且在使用前向或反向KL散度单独失效时仍能保持良好性能。 |
| GSWorld：面向机器人操作的闭环逼真仿真套件 | Guangqi Jiang | [PDF](http://arxiv.org/pdf/2510.20813v1) | 本文提出GSWorld——一个结合三维高斯泼溅与物理引擎的机器人操作仿真平台，兼具鲁棒性与照片级真实感。该框架实现了操作策略开发的闭环：通过对真实机器人数据学习策略进行可复现评估，并完成无需真实机器人的模拟到现实策略训练。为实现多样化场景的照片级渲染，我们提出名为GSDF的新型资源格式，将网格高斯表征与机器人URDF及各类物体相融合。通过标准化重建流程，我们构建了包含3种单臂/双臂操作机器人模型及40余个物体的GSDF数据库。结合物理引擎，我们展示了以下即时应用场景：（1）通过照片级渲染实现零样本模拟到现实的像素到动作策略学习；（2）自动化高质量DAgger数据采集以适配部署环境策略；（3）仿真环境中可复现的真实机器人操作策略基准测试；（4）通过虚拟遥操作收集仿真数据；（5）零样本模拟到现实的视觉强化学习。项目网站：https://3dgsworld.github.io/。 |
| SpectraMorph：基于结构化隐空间学习的自监督高光谱图像超分辨率方法

（注：翻译在保持专业术语准确性的基础上进行了学术化处理：
1. "Structured Latent Learning"译为"结构化隐空间学习"，体现对潜在表征的结构化建模
2. "Self-Supervised"译为"自监督"，符合机器学习领域标准译法
3. "Hyperspectral Super-Resolution"译为"高光谱图像超分辨率"，补充"图像"二字使专业范畴更明确
4. 整体采用"方法"作为隐性后缀，符合中文论文命名惯例） | Ritik Shah | [PDF](http://arxiv.org/pdf/2510.20814v1) | 高光谱传感器能捕获每个像素的密集光谱，但存在空间分辨率低的缺陷，导致边界模糊和混合像元效应。协同配准的辅助传感器（如多光谱、RGB或全色相机）可提供高分辨率空间细节，这推动了通过高光谱与多光谱图像融合（HSI-MSI）实现高光谱超分辨率的研究。现有基于深度学习的方法虽能实现强劲性能，但依赖缺乏可解释性的黑盒回归器，且当多光谱图像波段数极少时往往失效。我们提出SpectraMorph——一个具有结构化潜空间的物理引导自监督融合框架。该方法不直接进行回归，而是构建解混瓶颈：从低分辨率高光谱图像中提取端元光谱，通过紧凑型多层感知机从多光谱图像预测类丰度图。通过线性混合模型重建光谱，并借助多光谱传感器的光谱响应函数以自监督方式进行训练。SpectraMorph可生成可解释的中间结果，在一分钟内完成训练，即使面对单波段（全色）多光谱图像仍保持稳健性。在合成与真实数据集上的实验表明，SpectraMorph始终优于最先进的无监督/自监督基线方法，同时与监督基线相比仍保持强劲竞争力。 |
| 小稿大判：基于推测的信息密集型视觉推理

（注：该翻译采用学术论文标题常见的对仗式译法：
1. "Small Drafts"译为"小稿"，既保留"草稿/草案"的本义，又通过"小"字呼应原文的对比结构
2. "Big Verdict"译为"大判"，其中"判"字兼具"判断/判决"双重含义，契合法律与认知的双重语境
3. 副标题采用直译保持学术准确性，"Speculation"译为"推测"以体现认知科学中的假设验证过程
4. 整体通过冒号分隔主副标题，符合中文学术标题规范，同时保留原文通过大小对比形成的修辞张力） | Yuhan Liu | [PDF](http://arxiv.org/pdf/2510.20812v1) | 大型视觉语言模型（VLM）在多模态理解领域取得了显著进展，但在处理信息密集型图像时仍面临挑战——这类图像往往密集交织着文本标注与细粒度图形元素。核心难点在于如何精确定位密集布局中的关键线索，并通过多跳推理整合分散的证据。我们提出"推测性决断"（SV）框架，该无需训练的方法受推测解码思想启发，将多个轻量级草案专家与大型决断模型相结合。在草案阶段，小型VLMs作为草案专家生成提供多样化定位候选的推理路径；在决断阶段，强VLM对这些路径进行综合研判以生成最终答案，在恢复正确答案的同时最大限度降低计算成本。为提升效率与准确性，SV引入共识专家选择机制，仅将高一致性的推理路径提交至决断阶段。实验表明，SV在具有挑战性的信息密集型和高分辨率视觉问答基准测试（包括InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K）中持续获得性能提升。通过从多个部分准确的推理路径中综合正确洞见，相较于大型专有模型或训练流程，SV同时实现了错误修正与成本优化。代码已发布于https://github.com/Tinaliu0123/speculative-verdict |
| 关于LLM生成文本的可检测性探究：究竟何为LLM生成文本？ | Mingmeng Geng | [PDF](http://arxiv.org/pdf/2510.20810v1) | 随着大语言模型（LLM）的广泛使用，众多研究者已将目光投向对其生成文本的检测。然而对于检测目标——即“LLM生成文本”——尚未形成统一精确定义。使用场景的差异性与大语言模型本身的多样性，进一步增加了检测难度。当前普遍认定的检测目标，往往仅代表大语言模型潜在产出文本的一个子集。人类对模型输出的编辑行为，以及大语言模型对使用者产生的潜移默化影响，正在模糊机器生成与人工撰写文本的界限。现有基准测试与评估方法未能充分涵盖检测器实际应用中的多样情境，导致检测器的数值结果常被误读，其重要意义正在减弱。因此，检测器在特定条件下仍具实用价值，但对其结果的解读应保持审慎，仅可作为参考依据而非决定性指标。 |
| 人工智能、机器人及前沿领域的深度探索研究 | Xueyan Zou | [PDF](http://arxiv.org/pdf/2510.20809v1) | 随着人工智能与机器人学领域研究迅猛发展（年论文量已突破万篇），研究人员保持知识更新变得日益困难。快速演进的技术趋势、跨学科研究的兴起，以及探索本专业外领域的需求，共同加剧了这一挑战。为应对这些问题，我们提出一种可推广的研究分析流程，能够系统审视任何科研领域：识别新兴趋势，发掘跨领域机遇，并为新研究提供具体切入点。本研究提出"真实深度研究"综合框架，将其应用于人工智能与机器人学领域，特别聚焦基础模型与机器人技术进展，同时将分析范围延伸至其他科学领域。主论文详述了RDR流程的构建方法，附录则呈现各分析主题的详尽结果。我们期望这项工作能为人工智能乃至更广泛领域的研究者提供启示。 |
