# arxiv 2025-10-21

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| ConsistEdit：高度一致且精准的无训练视觉编辑 | Zixin Yin | [PDF](http://arxiv.org/pdf/2510.17803v1) | 无需训练的注意力控制方法最新进展，使现有生成模型具备了灵活高效的文本引导编辑能力。然而，当前方法难以在保持与源内容一致性的同时实现强力编辑效果。这一局限在多轮编辑和视频编辑中尤为突出——视觉误差会随时间累积不断放大。现有方法大多强制全局一致性，这限制了在保持其他属性不变的情况下修改特定属性（如纹理）的能力，从而阻碍了细粒度编辑的实现。

近期从U-Net到MM-DiT的架构转变，不仅显著提升了生成性能，更引入了文本与视觉模态融合的新机制。这些突破为解决以往方法未能克服的挑战开辟了新路径。通过对MM-DiT的深入分析，我们揭示了其注意力机制的三项关键特性。基于这些发现，我们提出ConsistEdit——专为MM-DiT设计的创新注意力控制方法。该方法融合三大核心技术：纯视觉注意力控制、掩码引导的预注意力融合，以及对查询/键/值标记的差异化处理，从而生成保持一致性且符合提示要求的编辑结果。

大量实验表明，ConsistEdit在各类图像视频编辑任务（包括结构一致与非一致场景）中均达到最先进性能。与先前方法不同，本技术首次实现无需人工干预即可在所有推理步骤和注意力层执行编辑，显著提升可靠性与一致性，从而支持稳健的多轮次、多区域编辑。此外，该方法还支持结构一致性的渐进式调节，为实现更精细的控制提供了可能。 |
| 无偏梯度低秩投影 | Rui Pan | [PDF](http://arxiv.org/pdf/2510.17802v1) | 内存高效优化对于训练日益庞大语言模型（LLM）至关重要。主流策略采用梯度低秩投影技术，仅存储投影后的优化器状态，其中GaLore是典型代表。然而此类方法普遍存在缺乏收敛保证的缺陷——由于各种低秩投影方式会引入相对于原始优化算法的固有偏差，导致其性能与全参数训练存在差距。为解决这一问题，本文研究用于消除低秩投影偏差的逐层采样技术。基于该范式，我们结合GaLore机制与Muon算法提出新型无偏低秩优化方法GUM。理论证明表明，本方法在保持低秩技术内存效率的同时，可与基础Muon算法的收敛保证相匹配。在LLM微调与预训练中的实证实验表明，该方法相较GaLore取得显著提升，甚至优于全参数训练。进一步研究发现，该技术的改进源于层内知识分布更均匀，从而实现了模型参数空间的更高效利用与更强的记忆能力。 |
| 字形：通过视觉-文本压缩扩展上下文窗口 | Jiale Cheng | [PDF](http://arxiv.org/pdf/2510.17800v1) | 大型语言模型（LLM）在处理文档理解、代码分析与多步推理等任务时，日益依赖长上下文建模能力。然而将上下文窗口扩展至百万令牌级别会带来极高的计算与内存成本，限制了长上下文LLM的实际应用。本研究提出全新视角——视觉上下文缩放，以应对这一挑战。我们开发了Glyph框架，通过将长文本渲染为图像，并利用视觉语言模型（VLM）进行处理，替代传统的基于令牌的序列扩展方法。该方案在保持语义完整性的同时显著压缩文本输入，并进一步设计了基于LLM驱动的遗传搜索算法，以确定在精度与压缩比之间达到最优平衡的视觉渲染配置。

大量实验表明，本方法在各类长上下文基准测试（如Qwen3-8B）中保持相当精度的同时，实现了3-4倍的令牌压缩。这种压缩同时带来约4倍的预填充与解码加速，以及约2倍的监督微调训练加速。在极端压缩场景下，128K上下文的VLM可扩展处理百万令牌级别的文本任务。此外，经渲染的文本数据还能有效提升文档理解等现实多模态任务性能。相关代码与模型已发布于https://github.com/thu-coai/Glyph。

---
**改写说明**：
- **优化句式结构与逻辑衔接**：将原文并列或递进关系用更符合中文表达习惯的句式重组，增强语句连贯性和条理性。
- **专业术语统一与学术化表达**：对“long-context modeling”“vision-language models”等术语采用标准译法，并整体提升用词的正式度和学术性。
- **突出技术优势与数据呈现**：将压缩倍数、性能提升等关键数据集中表述，强化成果展示，并补充说明实际应用价值。

如果您需要更偏技术解析、科普风格或特定平台风格的表达，我可以继续为您优化内容。 |
| 企业深度研究：面向企业分析的可控多智能体深度研究 | Akshara Prabhakar | [PDF](http://arxiv.org/pdf/2510.17797v1) | 随着信息呈指数级增长，企业面临将非结构化数据转化为连贯、可操作洞察的日益增长的压力。尽管自主智能体展现出潜力，但它们往往难以应对领域特定的细微差异、意图对齐和企业集成等挑战。我们提出企业深度研究（EDR）系统——这是一个多智能体架构，整合了以下核心组件：（1）主规划智能体，实现自适应查询解构；（2）四个专业搜索智能体（通用搜索、学术搜索、GitHub搜索、LinkedIn搜索）；（3）基于MCP协议的可扩展工具生态系统，支持自然语言转SQL、文件分析及企业工作流；（4）可视化智能体，生成数据驱动的可视化洞察；（5）具备反射机制的优化模块，可检测知识缺口并动态调整研究方向，支持可选的人工介入指导。经内部数据集验证，该系统支持自动化报告生成、实时流式处理和无缝企业部署。在DeepResearch Bench和DeepConsult等开放基准测试中，EDR在无人为干预的情况下性能超越现有最先进的智能体系统。我们开源EDR框架及基准轨迹数据集，以推动多智能体推理应用的研究发展。

代码仓库：https://github.com/SalesforceAIResearch/enterprise-deep-research
数据集：https://huggingface.co/datasets/Salesforce/EDR-200 |
| 用于复现人工智能研究的可执行知识图谱 | Yujie Luo | [PDF](http://arxiv.org/pdf/2510.17795v1) | 复现人工智能研究对于大语言模型（LLM）智能体而言至关重要却充满挑战。现有方法往往难以生成可执行代码，主要归因于背景知识不足以及检索增强生成（RAG）方法的局限性——这些方法无法捕捉参考文献中隐藏的潜在技术细节。此外，先前研究往往忽略了有价值的实现级代码信号，且缺乏支持多粒度检索与重用的结构化知识表示。为克服这些挑战，我们提出可执行知识图谱（xKG），这是一个模块化、可插拔的知识库，能够自动整合从科学文献中提取的技术洞见、代码片段及领域特定知识。当将xKG集成至三种智能体框架并搭配两种不同大语言模型时，在PaperBench基准测试中展现出显著性能提升（使用o3-mini模型时提升10.9%），证明其作为自动化AI研究复现通用可扩展解决方案的有效性。代码发布于https://github.com/zjunlp/xKG。 |
| 功能分布网络（FDN） | Omer Haq | [PDF](http://arxiv.org/pdf/2510.17794v1) | 现代概率回归器在分布偏移下常表现出过度自信。我们提出函数分布网络（FDN），这是一种基于输入条件的网络权重分布，能够生成具有自适应输入离散度的预测混合分布。FDN通过β-ELBO目标函数与蒙特卡洛采样进行训练。我们进一步提出一种评估方案，清晰划分内插与外推任务，并强调分布外稳健性验证（例如确保预测似然在分布偏移下合理衰减，同时保持分布内的精度与校准性能）。在标准回归任务中，我们在匹配参数与更新预算条件下，与贝叶斯方法、集成学习、Dropout及超网络基线进行对比，通过标准化诊断指标评估精度、校准度与偏移感知能力。该框架与评估方案共同致力于实现具有分布外感知能力、校准良好的神经回归模型，使其兼具实用性与模块化特性。 |
| 基础性自动评估器：面向推理中心领域的多任务生成式评估器规模化训练

该翻译遵循以下原则：
1. 专业术语准确对应：
   - "Foundational"译为"基础性"体现其基础模型特性
   - "Automatic Evaluators"译为"自动评估器"符合计算机领域术语规范
   - "Reasoning-Centric Domains"译为"推理中心领域"准确传达技术内涵

2. 技术概念完整传递：
   - 保留"多任务生成式"的核心技术特征
   - "规模化训练"准确表达"Scaling Training"的扩展含义
   - 通过破折号保持原文的领域限定关系

3. 学术文本规范：
   - 采用中文论文标题常用的四字结构
   - 保持技术术语的一致性
   - 符合中文科技文献的表达习惯 | Austin Xu | [PDF](http://arxiv.org/pdf/2510.17793v1) | 微调专用生成式评估器已成为应对训练和测试阶段可扩展评估需求的主流范式。然而近期研究多聚焦于应用强化学习等新方法训练评估器，未能充分开展大规模数据驱动的开发工作。本研究专注于数据规模化，构建了涵盖五大评估任务（配对比较、步骤级评估、无参考与带参考验证、单一评分）及多个推理评估领域的250万样本集。基于此数据，我们采用简单的迭代拒绝采样监督微调方法，训练出包含80亿和200亿参数（激活参数36亿）的基础自动推理评估器系列。FARE-8B在性能上可挑战采用强化学习训练的更大规模专用评估器，而FARE-20B则为开源评估器树立新标杆，超越专用700亿+参数评估器。除静态基准测试外，我们在实际任务中验证FARE性能：作为推理阶段重排序器，FARE-20B在MATH数据集上接近理论最优表现；作为强化学习训练验证器，FARE较字符串匹配验证器最高可提升下游强化学习模型性能14.1%；以FARE为基底的持续微调模型FARE-Code，在测试用例质量评估任务上显著超越gpt-oss-20B达65%。 |
| 软模仿：基于示例学习的柔顺全身控制方法

该标题可拆解为三个核心部分：
1. SoftMimic - 采用"软模仿"的译法，既保留原文构词特征（Soft+Mimic），又体现柔性仿真的技术内涵
2. Learning...from Examples - 译为"基于示例学习"，符合机器学习领域对"learning from demonstration/demonstration"的通用译法
3. Compliant Whole-body Control - "柔顺全身控制"准确传达顺应环境交互的全身协调控制概念，其中"compliant"特指具有柔顺适应性的控制特性

该翻译在保持学术严谨性的同时，通过"基于示例""柔顺控制"等专业表述，准确反映了模仿学习与机器人全身控制交叉领域的技术特征。 | Gabriel B. Margolis | [PDF](http://arxiv.org/pdf/2510.17792v1) | 我们提出SoftMimic框架，该框架能够从示例动作中学习人形机器人的柔顺全身控制策略。通过强化学习模仿人类动作可让人形机器人快速掌握新技能，但现有方法会激励刚性控制策略——这种策略会激进地修正与参考动作的偏差，导致机器人在遭遇意外接触时产生脆弱且不安全的行为。相比之下，SoftMimic能使机器人在保持平衡和姿态的同时，柔顺地响应外部作用力。我们的方法利用逆运动学求解器生成增强型可行柔顺动作数据集，并据此训练强化学习策略。通过奖励策略匹配柔顺响应而非 rigidly 跟踪参考动作，SoftMimic学会了吸收干扰并从单一动作片段泛化至多种任务。我们通过仿真和真实环境实验验证了该方法，证明了其能实现与环境的安全有效交互。 |
| 超智用：一种采用混合动作的计算机使用代理基础模型 | Yuhao Yang | [PDF](http://arxiv.org/pdf/2510.17790v1) | 用于计算机操作的多模态智能体目前完全依赖原始操作（点击、键入、滚动），这些操作需要精确的视觉定位并涉及冗长的执行链条，容易导致级联故障和性能瓶颈。尽管其他智能体已充分利用丰富的程序化接口（API、MCP服务器、工具），计算机操作智能体（CUAs）却始终与这些能力隔绝。我们提出UltraCUA基础模型，通过混合操作机制弥合这一鸿沟——将图形用户界面原始操作与高级程序化工具调用无缝融合。为实现这一目标，我们的方法包含四个核心组成部分：（1）基于软件文档、开源仓库和代码生成的自动化程序化工具扩展管线；（2）可生成17,000余项覆盖真实计算机使用场景的可验证任务的合成数据引擎；（3）同时包含底层GUI操作与高级程序化工具调用的大规模高质量混合操作轨迹数据集；（4）结合监督微调与在线强化学习的双阶段训练流程，实现底层与高级操作间的策略性切换。我们通过70亿和320亿参数模型的实验证明，该方法相较最先进智能体取得显著提升：在OSWorld基准测试中，UltraCUA模型较基础模型实现平均22%的相对性能提升，且操作步数效率提升11%；在WindowsAgentArena的跨域评估中，我们的模型达成21.7%的成功率，优于基于Windows数据训练的基线模型。混合操作机制被证实具有关键价值，在保持执行效率的同时有效降低了错误传播。 |
| 推理时计算规模扩展在流匹配中的应用 | Adam Stecklov | [PDF](http://arxiv.org/pdf/2510.17786v1) | 在推理阶段分配额外计算资源的方法，近期已显著提升大语言模型和基于扩散模型的图像生成质量。与此同时，流匹配（Flow Matching）技术在语言、视觉及科学计算领域获得广泛关注，但其推理阶段的扩展方法仍待深入探索。Kim等人（2025）虽对此问题提出解决方案，但在推理阶段采用非线性保方差插值替代线性插值，牺牲了流匹配原有的高效直线采样特性。此外，当前流匹配的推理计算扩展仅应用于图像生成等视觉任务。我们提出一种新型流匹配推理扩展方案，在采样过程中保持线性插值特性。通过在图像生成及（据我们所知）首次在无条件蛋白质生成任务上的实验验证表明：I）随着推理计算量增加，生成样本质量持续提升；II）流匹配的推理扩展机制可成功应用于科学计算领域。 |
