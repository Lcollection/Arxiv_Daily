# arxiv 2025-10-23

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 追踪器是否开启？动态追踪基准协议研究

（注：该翻译在保持学术严谨性的同时，通过"是否开启"的设问形式保留了原文的互动性特征，"基准协议研究"的表述既符合中文科技文献表达习惯，又准确传递了benchmark protocol的核心概念，冒号改为问号更符合中文标题修辞特点。） | Ilona Demler | [PDF](http://arxiv.org/pdf/2510.19819v1) | 我们推出ITTO——一个具有挑战性的新基准测试套件，用于评估和诊断点追踪方法的能力与局限性。我们的视频源既包含现有数据集，也涵盖以自我为中心的真实世界记录，并通过多阶段流程收集了高质量的人工标注数据。ITTO捕捉了真实场景特有的运动复杂性、遮挡模式与物体多样性特征——这些要素在当前主流基准测试中普遍缺失。通过对前沿追踪方法在ITTO上进行严格分析，我们沿着运动复杂性的关键维度解析了算法表现。研究发现：现有追踪器面临显著挑战，尤其在遮挡后重新识别特征点方面暴露出关键缺陷，这揭示了亟待解决的失效模式。这些结果表明，需要开发专门针对真实世界动态特性的新型建模方法。我们期待ITTO成为推动点追踪技术发展、指导构建更强健追踪算法的基石测试平台。 |
| 语义世界模型 | Jacob Berg | [PDF](http://arxiv.org/pdf/2510.19818v1) | 基于世界模型的规划为机器人控制提供了一种强大的范式。传统方法通过训练模型来预测基于当前帧和动作的未来帧，进而用于规划。然而，像素级未来预测的目标常与实际规划目标存在偏差——精确的像素重建并不总能对应优质的规划决策。本文提出，世界模型无需重建未来帧的像素信息，而只需预测与任务相关的未来语义信息。为此，论文将世界建模构建为针对未来帧语义信息的视觉问答问题。这一视角使得世界建模可采用与视觉语言模型相同的技术基础。通过在有图像-动作-文本数据上进行监督微调，视觉语言模型可被训练为“语义化”世界模型，在继承预训练视觉语言模型泛化性与鲁棒性的同时，实现决策规划功能。研究展示了此类语义世界模型如何在开放式机器人任务中实现策略优化，相比基于重建的行动条件世界模型传统范式，取得了显著的泛化性能提升。项目网站详见 https://weirdlabuw.github.io/swm。 |
| olmOCR 2：文档OCR的单元测试奖励机制

（注：olmOCR作为专有技术名词保留原格式，通过添加冒号和意译方式保持技术文档的严谨性，同时确保"Unit Test Rewards"这一核心概念在OCR技术语境下的准确传达） | Jake Poznanski | [PDF](http://arxiv.org/pdf/2510.19817v1) | 我们正式推出olmOCR 2——这是我们强大OCR系统家族的最新成员，专门用于将数字化印刷文档（如PDF）转换为整洁、自然排序的纯文本。该系统由olmOCR-2-7B-1025驱动，这是一个专门训练的70亿参数视觉语言模型（VLM），采用基于可验证奖励的强化学习（RLVR）进行训练，其中奖励信号来自多样化的二元单元测试集。为扩大单元测试创建规模，我们开发了能够生成复杂版式合成文档的流水线，这些文档包含已知真实HTML源代码并可直接提取测试用例。实验表明，基于这些测试用例的强化学习训练使模型在olmOCR-Bench（我们的英文OCR基准测试）中达到最先进性能，相较于前代版本，在数学公式转换、表格解析和多栏布局处理方面实现最大幅度提升。我们将以开放许可协议发布模型、数据及代码。 |
| 如何评估单目深度估计？ | Siyang Wu | [PDF](http://arxiv.org/pdf/2510.19814v1) | 单目深度估计是一个快速发展的研究领域，但其评估方法仍存在开放性问题。现有文献缺乏统一标准，众多评估指标间的权衡关系与特性尚未被充分理解。本文通过量化分析现有指标对真实深度值各类扰动的敏感度展开研究，重点考察其与人类感知的一致性。研究发现，现有指标对曲面扰动（如平面波浪化）存在严重不敏感问题。为此，我们提出基于相对表面法向量的新评估指标，配套开发新型深度可视化工具，并建立构建复合指标的规范化方法以提升人类感知对齐度。代码与数据详见：https://github.com/princeton-vl/evalmde。 |
| 哈勃：一套用于推进大语言模型记忆研究的高级模型套件 | Johnny Tian-Zheng Wei | [PDF](http://arxiv.org/pdf/2510.19811v1) | 我们推出哈勃（Hubble）系列——一套完全开源的大语言模型（LLM），专为LLM记忆机制的科学研究而设计。该系列包含标准版与扰动版两类模型：标准模型基于大型英文语料库进行预训练，扰动模型则采用相同训练方式，但通过受控文本插入（如书籍段落、人物传记及测试集）来模拟关键记忆风险。核心发布包含8个模型（1B/8B参数规格的标准与扰动模型，分别基于100B/500B token进行预训练），证实记忆风险取决于敏感数据在训练语料中的相对频率（例如：相同密码在小规模语料中出现一次比在大规模语料中更易被记忆）。我们还发布6个在不同预训练阶段插入文本的扰动模型，表明缺乏持续曝光的敏感数据会被遗忘。这些发现提出应对记忆风险的两项最佳实践：通过扩大训练语料规模稀释敏感数据，以及安排敏感数据在训练前期出现。除上述实证发现外，哈勃模型支持广泛的记忆研究——例如通过分析传记文本可探究不同类型隐私信息的记忆难易度。我们同时证明，哈勃模型中随机插入的文本使其成为成员推理与机器遗忘研究的理想测试平台，诚邀学界在此基础之上进一步探索、建立基准并拓展研究边界。 |
| Pico-Banana-400K：面向文本引导图像编辑的大规模数据集

（该翻译采用学术文献命名规范，通过连字符保持原名称的层级结构。"Pico-Banana"作为专有名词保留不译，"400K"转换为中文计量单位"万"级表述（400K=40万）。"Text-Guided Image Editing"译为"文本引导图像编辑"准确对应专业术语，整体译名符合数据集命名惯例，同时通过冒号实现主副标题的语义分隔。） | Yusu Qian | [PDF](http://arxiv.org/pdf/2510.19808v1) | 多模态模型的最新进展展现出卓越的文本引导图像编辑能力，以GPT-4o和Nano-Banana为代表的系统创造了全新性能基准。然而研究界的发展仍受制于缺乏基于真实图像构建的大规模、高质量、开放可用的数据集。我们推出Pico-Banana-400K——一个包含40万图像的指令化图像编辑综合数据集。该数据集通过运用Nano-Banana技术从OpenImages图库的真实照片生成多样化编辑配对。相较于既往合成数据集，Pico-Banana-400K的突出优势在于系统化的质量把控与多样性构建：我们采用细粒度图像编辑分类法确保全面覆盖各类编辑操作，同时通过基于多模态大语言模型的质量评分与精细筛选，实现精准内容保持与指令忠实度。除单轮编辑外，本数据集更支持复杂编辑场景研究，包含三大专项子集：（1）7.2万样本的多轮编辑集合，用于研究连续修改过程中的序列化编辑、推理与规划；（2）5.6万样本的偏好子集，适用于对齐研究与奖励模型训练；（3）长短指令配对数据，用于开发指令重写与摘要生成能力。通过提供这种大规模、高质量、多任务的研究资源，Pico-Banana-400K为训练和评估新一代文本引导图像编辑模型奠定了坚实基础。 |
| Scaf-GRPO：基于支架式群体相对策略优化的LLM推理增强方法 | Xichen Zhang | [PDF](http://arxiv.org/pdf/2510.19807v1) | 基于可验证奖励的强化学习已成为增强大语言模型复杂推理能力的重要技术。然而这类方法始终受限于"学习悬崖"现象：当面对远超当前能力的问题时，模型持续失败并产生恒定的零奖励信号。在GRPO等策略优化算法中，这会导致优势函数坍缩为零，使得这些难题在学习梯度中不可见，从而阻碍进展。为突破此限制，我们提出Scaf-GRPO（支架式分组相对策略优化）——一种渐进式训练框架，仅在模型自主学习陷入停滞时策略性地提供最小化指导。该框架首先诊断学习停滞，然后通过注入分层提示（从抽象概念到具体步骤）进行干预，使模型能够自主构建有效解法。在具有挑战性的数学基准测试中，大量实验证明Scaf-GRPO显著提升效果：相较于原始GRPO基线，Qwen2.5-Math-7B模型在AIME24基准上的pass@1分数相对提升44.3%。这一结果表明我们的框架提供了稳健有效的方法论，能够释放模型解决既往无法应对的问题的潜力，是拓展大语言模型自主推理边界的关键进展。 |
| 提问的艺术：面向合成数据的多语言提示优化 | David Mora | [PDF](http://arxiv.org/pdf/2510.19806v1) | 合成数据已成为扩展大语言模型的基石，但其多语言应用仍受限于基于翻译的提示方法。这种策略沿袭了以英语为中心的框架与风格，忽视了文化维度，最终制约了模型的泛化能力。我们认为，被忽视的提示空间——即定义训练分布的核心输入——为提升多语言性能提供了更有效的着力点。我们提出一个轻量级提示空间优化框架，通过系统化重构翻译提示，实现自然度提升、文化适应与难度增强。基于现成的多语言大模型，我们对涵盖7个语系的12种语言提示实施优化。在相同数据条件下，相较于纯翻译基线，我们的方法在多项下游任务中取得显著且稳定的提升：Global-MMLU准确率提升4.7%，Flores XCometXL指标增长2.4%，mArenaHard偏好评估胜率大幅提高35.3%。本研究确立了提示空间优化作为一种简洁而强大的范式，可构建更具鲁棒性、文化适应性及全球胜任力的多语言大模型。 |
| 基于负对比的类感知原型学习用于视觉语言模型的测试时自适应 | Xiaozhen Qiao | [PDF](http://arxiv.org/pdf/2510.19802v1) | 视觉语言模型（VLMs）通过大规模图像-文本预训练展现出卓越的零样本泛化能力，但当部署数据分布与训练数据分布发生偏离时，其性能会出现显著下降。为解决这一问题，测试时自适应（TTA）方法利用未标注目标数据对模型进行更新。然而现有方法往往忽视两个关键挑战：长尾分布中的原型退化问题，以及语义相似类别间的混淆现象。为此，我们提出基于负对比的类别感知原型学习（CPL-NC）——一个专为VLMs设计的轻量化TTA框架，旨在提升模型在分布偏移下的泛化能力。CPL-NC创新性地引入以下机制：首先，通过动态容量调整的类别感知原型缓存模块，根据测试频率和激活历史自适应分配每类存储容量，并采用休眠类别复苏机制以保留稀有类别知识；其次，通过负对比学习机制识别并约束困难的视觉-文本负样本对以增强类别区分度。该框架采用非对称优化策略，仅优化文本原型而保持稳定的视觉特征锚定。在15个基准数据集上的实验表明，无论是在ResNet-50还是ViT-B/16骨干网络下，CPL-NC均持续优于现有TTA方法。 |
| 在全球南方国家训练主权语言模型的可行性：以巴西和墨西哥为例的研究 | Sandra Malagon | [PDF](http://arxiv.org/pdf/2510.19801v1) | 训练大规模语言模型所需计算资源的急剧增长，加剧了高算力辖区与全球南方国家之间的结构性不对称。本文研究了在硬件获取受限、能源供应受限及财政预算受限条件下，巴西和墨西哥开展主权级语言模型训练的技术与财政可行性。通过采用双轴设计变量——加速器代际（英伟达H100与A100对比）与训练周期（90天与150天对比），我们估算了训练包含10万亿标记的模型所需的算力需求、能耗、资本支出及监管兼容性。研究结果表明：虽然所有配置方案均未触及出口管制与电力基础设施阈值，但财政可行性取决于硬件效率。基于H100的方案以800万至1400万美元总成本实现训练可行性，而A100部署因更高的能源与硬件需求需耗费1900万至3200万美元。我们认为，延长训练周期应作为缓解硬件约束的政策杠杆，使其能够在无需参与全球前沿竞争的情况下，产出可用、可审计且符合本地需求的模型。本研究通过揭示适合中等收入国家建立可持续且具备战略充足性人工智能能力的情境化策略，为人工智能算力治理与技术主权领域的讨论提供了新见解。 |
