# arxiv 2025-10-17

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 耦合扩散采样实现免训练的多视角图像编辑 | Hadi Alzayer | [PDF](http://arxiv.org/pdf/2510.14981v1) | 我们提出一种推理时扩散采样方法，利用预训练的二维图像编辑模型实现多视角一致图像编辑。现有模型能够对三维场景或物体的多视角图像集进行独立高质量编辑，但无法保持跨视角一致性。传统方法通常通过优化显式三维表征来解决该问题，但存在优化流程冗长、稀疏视角下稳定性不足的缺陷。我们采用隐式三维正则化方法，通过约束生成的二维图像序列符合预训练多视角图像分布来实现一致性。具体而言，我们提出耦合扩散采样技术——这种简易的扩散采样方法可同时从多视角图像分布和二维编辑图像分布中采样两条轨迹，并利用耦合项强化生成图像间的多视角一致性。通过在三种不同多视角图像编辑任务上验证该框架的有效性与普适性，我们证明了其在不同模型架构间的广泛适用性，凸显了其作为多视角一致性通用解决方案的潜力。 |
| 从像素到词汇——迈向规模化原生视觉语言基元 | Haiwen Diao | [PDF](http://arxiv.org/pdf/2510.14979v1) | 原生视觉语言模型（VLMs）的体系已逐渐成为传统模块化VLMs的有力竞争者，这一发展由不断演进的模型架构与训练范式所推动。然而，仍有两大悬而未决的问题阻碍着其广泛探索与推广：（一）原生VLMs与模块化模型存在哪些根本性差异？这些差异的突破边界何在？（二）如何降低原生VLMs的研究门槛，实现技术民主化，从而加速领域发展？本文旨在厘清这些挑战，并提出构建原生VLMs的指导原则。具体而言，优质的原生VLM基础架构应满足：（i）在共享语义空间中实现像素与文本表征的高效对齐；（ii）无缝融合传统视觉与语言模块的核心优势；（iii）内蕴支持视觉语言统一编码、对齐与推理的跨模态特性。基于此，我们推出全新原生VLM系列NEO——从第一性原理构建的模型体系，在多样化现实场景中可与顶尖模块化模型抗衡。仅通过3.9亿图文样本，NEO即能从零高效习得视觉感知能力，并在我们精心设计的基础架构中，通过稠密单体模型有效缓解视觉-语言模态冲突。我们将NEO定位为可扩展强大多模态模型的基石，配套可复用组件库助力构建高性价比、易扩展的生态系统。代码与模型已开源：https://github.com/EvolvingLMMs-Lab/NEO。 |
| 组合式机器的能动性设计 | Wenqian Zhang | [PDF](http://arxiv.org/pdf/2510.14980v1) | 复杂机器的设计既是人类智慧的标志，也是工程实践的基石。随着大语言模型（LLMs）的最新进展，我们提出疑问：它们是否也能学会创造？我们通过组合式机器设计这一视角来探讨该问题——该任务要求通过标准化组件组装机器，使其在模拟物理环境中满足运动或操控等功能需求。为支持这项研究，我们开发了基于机器建造游戏《Besiege》的测试平台BesiegeField，该平台支持基于零部件的建造、物理模拟和奖励驱动式评估。通过BesiegeField，我们对具备智能体工作流程的尖端大语言模型进行基准测试，识别出成功所需的关键能力，包括空间推理、策略性组装和指令遵循。鉴于当前开源模型存在不足，我们探索将强化学习（RL）作为改进路径：通过构建冷启动数据集、开展RL微调实验，揭示了语言理解、机器设计与物理推理交叉领域面临的开放性挑战。 |
| 训练无需图像编辑对的图像编辑模型 | Nupur Kumari | [PDF](http://arxiv.org/pdf/2510.14978v1) | 近期图像编辑模型在遵循自然语言编辑指令方面取得了显著成果，但这些成果依赖于使用大规模输入-目标配对数据集进行监督微调。这构成了关键瓶颈，因为此类自然生成的配对数据难以大规模整理。当前解决方案采用合成训练对，利用现有模型的零样本生成能力。然而，这种做法会将预训练模型的伪影传播并放大至最终训练模型中。本研究提出了一种全新的训练范式，完全摆脱了对配对数据的依赖。我们的方法通过训练时展开多步扩散模型，并借助视觉语言模型（VLM）的反馈信号直接优化模型参数。针对每个输入图像和编辑指令，VLM会评估编辑结果是否遵循指令并保留未修改内容，从而为端到端优化提供直接梯度。为确保视觉保真度，我们引入分布匹配损失（DMD），将生成图像约束在预训练模型学习到的图像流形范围内。我们在标准基准测试上评估了该方法，并进行了详尽的消融实验。在无需任何配对数据的情况下，我们的方法在少步生成设定下，与基于大量监督配对数据训练的各类图像编辑扩散模型表现相当。当使用相同VLM作为奖励模型时，我们的方法也超越了基于强化学习的技术（如Flow-GRPO）。 |
| Ponimator：展开交互姿态以实现多样化人-人互动动画

（注：Ponimator为专业术语，采用音译加意译的复合译法，既保留术语识别度又体现系统功能特性。"Unfolding Interactive Pose"译为"展开交互姿态"以准确传达动作生成过程的动态特性，"Versatile Human-human Interaction Animation"采用"多样化人-人互动动画"的译法，既保持学术严谨性又符合中文表达习惯） | Shaowei Liu | [PDF](http://arxiv.org/pdf/2510.14976v1) | 近距离人际交互姿态能够传递丰富的互动动态情境信息。基于此类姿态，人类可凭借对行为模式的强先验认知，直观推断互动情境并预测可能的过往与未来动态。受此启发，我们提出Ponimator框架——一种以近距离交互姿态为锚点的通用交互动画生成方案。训练数据源自动作捕捉交互数据集中的紧密接触双人姿态及其时序上下文。通过运用交互姿态先验，Ponimator采用两个条件扩散模型：(1) 姿态动画器利用时序先验从交互姿态生成动态运动序列；(2) 姿态生成器运用空间先验，在交互姿态缺失时根据单帧姿态、文本描述或二者组合合成交互姿态。该集成框架支持多样化任务，包括基于图像的交互动画生成、反应动画合成以及文本到交互的生成，有效推动高质量动作捕捉数据中的交互知识向开放场景迁移。跨数据集与多应用的实证实验验证了姿态先验的普适性，以及我们框架的有效性与鲁棒性。 |
| Terra：基于点潜在空间的可探索原生三维世界模型

（注：Terra作为系统/模型名称保留原文不译。"Explorable Native 3D World Model"译为"可探索原生三维世界模型"，强调其无需转换即可直接探索的特性。"Point Latents"译为"点潜在空间"，指代通过离散点集表征的潜在特征空间，符合计算机图形学与三维重建领域的术语规范） | Yuanhui Huang | [PDF](http://arxiv.org/pdf/2510.14977v1) | 世界模型因其对现实世界的综合建模能力而受到日益广泛的关注。然而，现有方法大多仍以像素对齐表示作为世界演化的基础，忽视了物理世界固有的三维特性。这种局限性可能削弱世界模型的三维一致性并降低建模效率。本文提出Terra——一种原生三维世界模型，能够在固有三维潜在空间中表征并生成可探索环境。具体而言，我们设计了一种新颖的点云-高斯变分自编码器（P2G-VAE），可将三维输入编码为潜在点表示，随后将其解码为三维高斯基元以联合建模几何结构与外观属性。继而提出稀疏点流匹配网络（SPFlow），通过同步去噪潜在点的空间位置与特征来实现潜在点表示的生成。我们的Terra模型凭借原生三维表征与架构实现了精确的多视角一致性，仅需单次生成过程即可支持任意视点的灵活渲染。此外，该模型通过点潜在空间中的渐进式生成实现了可探索的世界建模。我们在ScanNet v2数据集中的复杂室内场景上进行了大量实验，Terra在重建与生成任务中均以卓越的三维一致性达到了最先进的性能水平。 |
| 与任何人：迈向可控且身份一致性的图像生成 | Hengyuan Xu | [PDF](http://arxiv.org/pdf/2510.14975v1) | 身份一致性生成已成为文本到图像研究的重要方向，近期模型在生成与参考身份对齐的图像方面取得显著进展。然而，由于缺乏包含同一人物多张图像的大规模配对数据集，现有方法大多采用基于重建的训练范式。这种训练方式容易引发我们称之为"复制-粘贴"的失效模式——模型直接复制参考人脸，而非在姿态、表情或光照等自然变化中保持身份一致性。这种过度相似性会削弱生成结果的可控性，限制模型的表现力。为解决这些局限，我们（1）构建了专为多人场景设计的大规模配对数据集MultiID-2M，为每个身份提供多样化参考；（2）提出量化复制-粘贴伪影及身份保真度与变化度权衡的评估基准；（3）引入具有对比性身份损失的新型训练范式，利用配对数据平衡保真度与多样性。这些成果最终凝练为WithAnyone模型——一个基于扩散模型的解决方案，能有效缓解复制-粘贴问题同时保持高身份相似度。大量定性与定量实验表明，WithAnyone显著减少复制-粘贴伪影，提升姿态和表情的可控性，并保持优异的感知质量。用户研究进一步验证本方法在实现高身份保真度的同时，能够完成富有表现力的可控生成。 |
| pi-Flow：基于策略的模仿蒸馏少步生成方法

（解析说明：
1. "Policy-Based"译为"基于策略的"，符合强化学习领域术语规范
2. "Few-Step Generation"采用"少步生成"的译法，既保留"few-step"的量化特征，又符合中文表达习惯
3. "Imitation Distillation"译为"模仿蒸馏"，准确对应模仿学习中的专业概念
4. 整体采用"方法"作为隐性后缀，符合中文论文标题命名惯例
5. 保留原标题的层级关系，通过冒号维持主副标题结构） | Hansheng Chen | [PDF](http://arxiv.org/pdf/2510.14974v1) | 基于扩散或流的少步生成模型通常会将预测速度的教师模型蒸馏为能够预测去噪数据捷径的学生模型。这种形式上的不匹配导致了复杂的蒸馏流程，往往面临生成质量与多样性的权衡问题。为解决这一难题，我们提出基于策略的流模型（$\pi$-Flow）。该模型通过修改学生流模型的输出层，使其在单个时间步长预测无需网络计算的策略。该策略随后在后续子步中生成动态流速度，其计算开销可忽略不计，从而无需额外网络评估即可在这些子步上实现快速精确的常微分方程积分。

为使策略的常微分方程轨迹与教师模型对齐，我们提出新型模仿蒸馏方法：通过标准的$\ell_2$流匹配损失，使策略生成的速度沿其自身轨迹与教师模型保持一致。通过直接模仿教师模型的行为，$\pi$-Flow实现了稳定可扩展的训练，并规避了质量-多样性权衡问题。在ImageNet 256$^2$数据集上，其单步评估FID指标达到2.85，优于同架构DiT的MeanFlow模型。在FLUX.1-12B和Qwen-Image-20B的4步评估中，$\pi$-Flow在保持教师级生成质量的同时，相比现有最优少步方法实现了显著更优的多样性表现。 |
| 注意力机制是扩散大语言模型中KV缓存的全部所需 | Quan Nguyen-Tri | [PDF](http://arxiv.org/pdf/2510.14973v1) | 本研究探讨如何自适应重构扩散大语言模型（DLM）的键值缓存（KV Cache），在最大化预测精度的同时最小化解码延迟。现有方法的解码器需在每个去噪步骤和每个网络层为所有令牌重新计算QKV，但事实上多数步骤（尤其是浅层网络中）的KV状态变化极小，导致大量冗余计算。我们提出三点关键发现：（1）远端${\bf MASK}$令牌主要起长度偏置作用，可在当前预测窗口外进行分块缓存；（2）KV动态变化随网络深度递增，表明从深层开始选择性刷新即可满足需求；（3）最高关注度令牌的KV漂移最小，这为其他令牌的缓存更新提供了保守下界。基于这些发现，我们提出无需训练、架构无关的${\bf Elastic-Cache}$策略，该策略通过联合决策机制确定${刷新时机}$（基于最高关注度令牌的注意力感知漂移检测）和${刷新范围}$（基于深度感知调度：从选定层开始重新计算，同时复用浅层缓存和窗口外MASK缓存）。与固定周期方案不同，Elastic-Cache为扩散大语言模型实现自适应、层级感知的缓存更新，在保证生成质量无损的前提下显著减少冗余计算。在LLaDA-Instruct、LLaDA-1.5和LLaDA-V模型上的数学推理与代码生成实验表明：GSM8K任务（256令牌）加速$8.7\times$，长序列任务加速$45.1\times$，HumanEval任务加速$4.8\times$，且始终保持优于基线模型的准确率。相比现有基于置信度的方法，本方法在保持生成质量的同时实现了显著更高的吞吐量（GSM8K任务达$6.8\times$），为扩散大语言模型的实际部署提供了可行方案。 |
| TokDrift：当大语言模型以子词交流而代码以语法表达 | Yinxi Li | [PDF](http://arxiv.org/pdf/2510.14972v1) | 用于代码处理的大型语言模型依赖子词分词器（例如字节对编码），这类分词器通过混合自然语言文本与程序语言代码训练获得，但其运作基于统计规律而非语法规则。这导致语义完全相同的代码片段会因表面差异（如空格位置或标识符命名）而产生不同的分词结果。为量化这种错位带来的影响，我们提出TokDrift框架——通过应用保持语义不变的改写规则，生成仅在分词层面存在差异的代码变体。在对九款代码大模型（包括参数量超过300亿的大型模型）的测试中，发现即使微小的格式改动也会引发模型行为的显著偏移。分层分析表明，该问题源于早期嵌入层中子词切分未能捕捉语法标记边界。我们的研究揭示：未对齐的分词机制是阻碍代码可靠理解与生成的潜在障碍，未来代码大模型需要发展具备语法感知能力的分词方案。 |
