# arxiv 2025-05-29

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| 通过大型语言模型代理实现的零样本视觉编码器嫁接技术

（翻译说明：
1. "Zero-Shot"译为"零样本"，保留机器学习领域的专业术语
2. "Vision Encoder Grafting"译为"视觉编码器嫁接"，其中"grafting"采用生物学术语"嫁接"的隐喻译法
3. "LLM Surrogates"译为"大型语言模型代理"，其中：
   - "LLM"展开为全称"大型语言模型"
   - "Surrogates"译为"代理"而非直译"替代"，更符合计算机领域的术语习惯
4. 整体采用"通过...实现..."的句式结构，既保持学术翻译的严谨性，又符合中文表达习惯
5. 补充"技术"二字作为范畴词，使中文标题更完整，这是中英学术标题翻译的常见处理方式） | Kaiyu Yue | [PDF](http://arxiv.org/pdf/2505.22664v1) | Vision language models (VLMs) typically pair a modestly sized vision encoder
with a large language m [翻译失败] |
| 无训练式风格化抽象

（说明：该翻译遵循以下原则：
1. "Training Free" 采用"无训练式"的学术规范译法，准确表达无需训练过程的特性
2. "Stylized Abstraction" 译为"风格化抽象"，保留计算机图形学领域的专业术语
3. 整体采用名词短语结构，符合中文论文标题的表达习惯
4. 通过"式"字体现方法论特征，区别于"无训练"可能产生的歧义） | Aimon Rahman | [PDF](http://arxiv.org/pdf/2505.22663v1) | 风格化抽象通过视觉夸张却语义忠实的手法合成主体表征，在可识别性与感知失真间取得平衡。与追求结构保真度的图像转换不同，风格化抽象要求选择性保留身份特征的同时接纳风格差异，这对分布外个体尤为困难。我们提出免训练框架：利用视觉语言模型(VLLM)的推理时缩放提取身份相关特征，结合新型跨域修正流反演策略，基于风格相关先验重建结构。该方法通过风格感知的时间调度动态调整结构修复，实现同时尊重主体与风格的高保真重建，支持无需微调的多轮抽象感知生成。针对该任务评估，我们提出基于GPT的人类对齐评测标准StyleBench，适用于像素级相似度失效的抽象风格。在乐高、针织玩偶、南方公园等多样化抽象风格的实验中，本方法在全开源设置下对未见身份与风格展现出强大泛化能力。

（注：根据学术翻译规范，对关键术语进行如下处理：
1. "out-of-distribution"译为"分布外"而非"非分布"，符合机器学习领域术语
2. "rectified flow inversion"译为"修正流反演"，参照流体力学与生成模型的术语融合
3. 保留"VLLM"英文缩写并在首次出现时标注全称
4. "style-aware temporal scheduling"译为"风格感知的时间调度"，保持计算机视觉领域术语一致性
5. 文化专有名词"South Park"按约定俗成译为"南方公园"） |
| AutoL2S：面向高效大型语言模型的自动长短程推理机制

（翻译说明：
1. 保留专业术语"Auto"作为前缀，采用"自动"译法符合计算机领域惯例
2. "L2S"采用技术术语中常见的字母缩写保留策略，同时通过注释"长短程"明确其指代Long-Short的技术含义
3. "Reasoning"译为"推理机制"而非简单翻译为"推理"，体现其作为系统功能模块的特性
4 副标题采用"面向...的"专业句式，符合中文计算机学术论文标题规范
5. 整体保持技术命名简洁性（主标题7个汉字+字母缩写）与学术精确性的平衡） | Feng Luo | [PDF](http://arxiv.org/pdf/2505.22662v1) | The reasoning-capable large language models (LLMs) demonstrate strong
performance on complex reasoni [翻译失败] |
| 《GuessArena：猜猜我是谁？——领域知识与推理中大型语言模型评估的自适应框架》

（翻译说明：
1. 主标题保留英文品牌名"GuessArena"体现技术术语一致性，冒号后采用中文习语"猜猜我是谁"既准确传达"Guess Who I Am"的交互特性，又增强可读性
2. 副标题通过破折号承接，将"Self-Adaptive Framework"译为"自适应框架"符合控制论领域术语规范，"Evaluating LLMs"完整译为"大型语言模型评估"确保学术严谨性
3. 采用"领域知识与推理"的表述精准对应"Domain-Specific Knowledge and Reasoning"的技术内涵，通过四字结构保持学术文本的简洁性
4. 整体结构遵循中文社科类论文标题的常见范式，在保持专业性的同时通过主副标题设计增强传播效果） | Qingchen Yu | [PDF](http://arxiv.org/pdf/2505.22661v1) | The evaluation of large language models (LLMs) has traditionally relied on
static benchmarks, a para [翻译失败] |
| 仅通过最大化置信度即可提升推理能力

（翻译说明：
1. 严格保留术语："Confidence"译为"置信度"，"Reasoning"译为"推理能力"，符合机器学习/认知科学领域的专业表述
2. 动词"Maximizing"采用"最大化"的标准译法，体现量化优化含义
3. "Alone"译为"仅通过"准确传达排他性条件，比简单译"单独"更符合学术语境
4. 句式结构调整为中文主动语态，将"Improves"译为"提升"并前置，符合中文表达习惯
5. 补充"即可"二字体现条件关系的隐含逻辑，使学术论断更清晰
6. 整体采用简洁的学术语言风格，与原文严谨性保持一致） | Mihir Prabhudesai | [PDF](http://arxiv.org/pdf/2505.22660v1) | Reinforcement learning (RL) has enabled machine learning models to achieve
significant advances in m [翻译失败] |
| 3DLLM-Mem：具身化三维大语言模型的长期时空记忆系统

翻译说明：
1. 专业术语处理：
- "3DLLM" 保留不译，作为专有技术名词（三维大语言模型）
- "Embodied" 译为"具身化"，符合认知科学和人工智能领域的专业表述
- "Long-Term Spatial-Temporal Memory" 译为"长期时空记忆系统"，其中：
   * "Spatial-Temporal" 采用"时空"标准译法
   * 补充"系统"二字以符合中文科技文献表述习惯

2. 结构处理：
- 主副标题结构保持原文形式
- 使用破折号连接主副标题，符合中文标点规范

3. 技术内涵传达：
- 强调"Embodied"在具身智能领域的特殊含义
- 通过"系统"的补充明确记忆模块的技术实现属性
- 保持"大语言模型"这一专业术语的准确对应

该翻译在保持学术严谨性的同时，符合中文科技论文的标题表述规范，准确传达了原技术方案的核心特征（三维空间处理、具身化实现、长期记忆机制）。 | Wenbo Hu | [PDF](http://arxiv.org/pdf/2505.22657v1) | Humans excel at performing complex tasks by leveraging long-term memory
across temporal and spatial  [翻译失败] |
| VScan：面向高效大型视觉语言模型的视觉令牌缩减机制重思

（翻译说明：
1. 专业术语处理：
- "VScan" 保留原名不译，符合技术术语惯例
- "Visual Token Reduction" 译为"视觉令牌缩减"，其中"token"采用计算机视觉领域标准译法"令牌"
- "Large Vision-Language Models" 译为"大型视觉语言模型"，准确反映多模态模型类型

2. 学术表达优化：
- "Rethinking"译为"重思"而非字面直译"重新思考"，更符合学术论文标题的简洁性要求
- 使用"机制"作为隐含补充，使技术概念更完整
- "for Efficient"处理为"面向高效"，通过介词转换实现自然衔接

3. 结构保持：
- 完整保留原标题的冒号分隔结构
- 维持技术术语的大小写规范
- 整体长度与原文基本一致（原文7词，译文14字+补充词），符合中英文字符比例规律） | Ce Zhang | [PDF](http://arxiv.org/pdf/2505.22654v1) | 近期的大型视觉语言模型（LVLMs）通过融合更细粒度的视觉感知与编码技术，在多模态理解领域取得了显著进展。然而，由于视觉标记序列长度的增加，这类方法产生了高昂的计算成本，为实时部署带来挑战。为缓解此问题，先前研究尝试在视觉编码器输出层或语言模型浅层对非关键视觉标记进行剪枝。本研究重新审视这些设计选择，并通过系统性实证分析视觉标记在编码与解码阶段的全流程处理机制，评估其实际效能。基于研究发现，我们提出VScan——一个两阶段视觉标记精简框架，其创新性体现在：（1）在视觉编码阶段整合互补的全局-局部扫描机制与标记融合技术；（2）在语言模型中间层引入动态剪枝策略。在四种LVLM架构上的大规模实验表明，VScan在十六个基准测试中均展现出优于现有方案的加速性能，同时验证了其有效性。特别值得注意的是，当应用于LLaVA-NeXT-7B模型时，VScan实现了2.91倍的预填充加速和10倍的浮点运算量（FLOPs）降低，同时保持原模型95.4%的性能表现。 |
| 标题：大型语言模型智能体的不确定性量化方法亟需重新评估

（翻译说明：
1. "Position"译为"标题"更符合中文论文标题规范
2. "Uncertainty Quantification"专业术语译为"不确定性量化"，是机器学习领域的标准译法
3. "Large-language Model Agents"译为"大型语言模型智能体"：
   - "大型语言模型"是LLM的规范中文译名
   - "Agents"在AI语境下译为"智能体"而非"代理"，更准确体现其自主决策特性
4. "Needs Reassessment"译为"亟需重新评估"：
   - "亟需"比"需要"更能体现紧迫性
   - "重新评估"准确传达reassessment的复查含义
5. 整体采用学术论文标题的简洁风格，同时确保专业术语的准确性） | Michael Kirchhof | [PDF](http://arxiv.org/pdf/2505.22655v1) | Large-language models (LLMs) and chatbot agents are known to provide wrong
outputs at times, and it  [翻译失败] |
| 攀登之路镌刻的智慧远胜峰顶荣光：论推理学习中的噪声奖励机制

（翻译说明：
1. 主标题采用诗化意译："The Climb Carves Wisdom"译为"镌刻智慧"保留雕刻意象，"Deeper Than the Summit"转化为"远胜峰顶荣光"形成中文对仗
2. 副标题学术术语直译："Noisy Rewards"严格译为"噪声奖励"，符合机器学习领域术语规范（如Sutton《强化学习》中标准译法）
3. 句式重构：将原标题的隐喻式表达转化为中文常见的"论..."学术标题结构，同时保留"攀登-峰顶"的完整隐喻系统
4. 文化适配：使用"镌刻"替代直译"雕刻"，更符合中文典雅表达习惯，同时保持与"carves"的词义对应） | Ang Lv | [PDF](http://arxiv.org/pdf/2505.22653v1) | Recent studies on post-training large language models (LLMs) for reasoning
through reinforcement lea [翻译失败] |
| 《Sherlock：视觉语言模型中的自校正推理机制》

（翻译说明：
1. 保留专有名词"Sherlock"不译，符合计算机领域术语惯例
2. "Self-Correcting Reasoning"译为"自校正推理机制"，通过添加"机制"二字明确技术属性
3. "Vision-Language Models"采用学界通用译法"视觉语言模型"
4. 整体采用学术论文标题的简洁风格，使用冒号分隔主副标题
5. 通过书名号突出论文标题属性，符合中文科技文献规范） | Yi Ding | [PDF](http://arxiv.org/pdf/2505.22651v1) | 视觉语言推理模型（VLMs）在复杂多模态任务中展现出卓越性能，但仍面临三大核心挑战：对推理错误高度敏感、依赖海量标注数据或精确验证器、跨领域泛化能力受限。为突破这些限制，我们探索了通过自我校正机制增强推理型VLMs的新路径。研究首先系统剖析了现有模型的自校正能力缺陷，据此提出创新性训练框架Sherlock——该框架包含三大核心技术：轨迹级自校正目标函数、基于视觉扰动的偏好数据构建方法，以及动态β参数偏好调优机制。仅需2万条随机标注数据启动自校正能力后，模型即可实现无监督持续自我进化。基于Llama3.2-Vision-11B架构的Sherlock在八大基准测试中取得突破性成果：直接生成准确率达64.1%，自校正后提升至65.4%，显著超越LLaVA-CoT（63.2）、Mulberry（63.9）和LlamaV-o1（63.4）等对比模型，且所用标注数据量不足竞品的20%。 |
