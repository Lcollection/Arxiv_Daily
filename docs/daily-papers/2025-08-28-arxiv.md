# arxiv 2025-08-28

| 标题 | 作者 | PDF链接 |  摘要 |
|------|------|--------|------|
| CODA：基于解耦强化学习的双脑计算机使用代理协调大脑与小脑功能

该标题的翻译要点解析：
1. 专业术语准确对应：
- "Coordinating" 译为"协调"体现神经系统的协同机制
- "Cerebrum and Cerebellum" 采用神经解剖学标准译法"大脑与小脑"
- "Dual-Brain" 译为"双脑"保持概念一致性
- "Decoupled Reinforcement Learning" 译为"解耦强化学习"符合机器学习领域术语规范

2. 学术表达规范：
- 使用"代理"而非"代理器"符合计算机科学术语习惯
- "计算机使用"保持原文"Computer Use"的动宾结构
- 通过冒号分隔主副标题，符合中文科技文献标题格式

3. 技术内涵传达：
- 采用"功能"二字补充隐含的生理学含义
- 保持"协调...机制"的主动语态，突出系统交互特性
- 准确反映解耦学习与双脑协同的技术关联性

该翻译在保持学术严谨性的同时，确保了专业术语的准确性和技术概念的清晰传达，符合IEEE等国际学术机构的翻译规范要求。 | Zeyi Sun | [PDF](http://arxiv.org/pdf/2508.20096v1) | 在科学计算等专业领域中，面向图形用户界面（GUI）的自主智能体面临着重大挑战——这类任务既需要长周期规划能力，又要求精确的执行能力。现有方法存在一种权衡困境：通用型智能体擅长规划但执行能力薄弱，而专用型智能体则表现出相反的特性。近期出现的组合式框架试图通过整合规划器与执行器来弥合这一差距，但这些框架通常采用静态不可训练架构，无法通过经验实现自适应调整。鉴于科学领域高质量数据的稀缺性，这一缺陷显得尤为关键。

为突破这些限制，我们提出CODA——一种创新的可训练组合框架。该框架将通用规划器（Cerebrum）与专用执行器（Cerebellum）相融合，通过专门设计的两阶段流程进行训练：第一阶段"专业化"采用解耦式GRPO方法，基于少量任务轨迹数据，为每个科学应用独立训练专家规划器；第二阶段"泛化"聚合所有专业专家的成功轨迹构建统一数据集，用于最终规划器的监督微调。这种设计使CODA同时具备鲁棒执行能力和跨领域泛化能力。

在ScienceBench基准测试的四个高难度应用上的实验表明，CODA显著超越基线模型，在开源模型中确立了新的性能标杆。 |
| 离散引导扩散：可扩展且安全的多机器人运动规划方法

该标题翻译保持了以下专业特征：
1. 技术术语准确对应：
   - "Discrete-Guided" 译为"离散引导"
   - "Diffusion" 在运筹学语境下译为"扩散"方法
   - "Scalable" 译为"可扩展"
   - "Multi-Robot Motion Planning" 标准译为"多机器人运动规划"

2. 学术标题规范：
   采用中文论文标题常用的冒号分隔形式
   保持术语的精确性和专业性
   符合中文科技文献的表述习惯

3. 领域适应性：
   该翻译适用于机器人学、自动控制、人工智能等领域的学术交流
   准确反映原文在路径规划与多智能体系统方面的技术内涵 | Jinhao Liang | [PDF](http://arxiv.org/pdf/2508.20095v1) | 多机器人运动规划（MRMP）旨在为共享连续工作空间中运行的多个机器人生成无碰撞轨迹。尽管离散多智能体路径寻优（MAPF）方法因其可扩展性而被广泛采用，但其粗粒度离散化严重限制了轨迹质量。相比之下，基于连续优化的规划器能提供更高质量的路径，但受维度灾难影响，导致机器人数量增加时可扩展性急剧下降。本文通过引入融合离散MAPF求解器与约束生成扩散模型的新框架，成功解决了这两种方法的局限性。所提出的离散引导扩散（DGD）框架具有三个关键特征：（1）将原始非凸MRMP问题分解为具有凸配置空间的易处理子问题；（2）结合离散MAPF解与约束优化技术，引导扩散模型捕捉机器人间复杂的时空依赖关系；（3）采用轻量级约束修复机制确保轨迹可行性。该方法在大型复杂环境中实现了最先进的性能表现，可扩展至100个机器人规模，同时保持规划效率和高成功率。 |
| 通过专家知识引导的适应与基础模型先验弥合细粒度蛾类分类的领域差距

（该翻译严格遵循学术术语规范："Bridging Domain Gaps"译为"弥合领域差距"，"Fine-Grained Moth Classification"保留专业表述"细粒度蛾类分类"，"Expert-Informed Adaptation"译为"专家知识引导的适应"，"Foundation Model Priors"译为"基础模型先验"，整体保持学术论文标题的简洁性与准确性。） | Ross J Gardiner | [PDF](http://arxiv.org/pdf/2508.20089v1) | 对自动化相机系统采集的鳞翅目昆虫（蛾类）图像进行标注，对于解明昆虫种群衰退现象具有关键意义。然而由于标本馆精校图像与野外实拍噪声图像之间存在域偏移，导致精确物种识别面临挑战。我们提出一种轻量化分类方法，将有限专家标注的野外数据与高性能BioCLIP2基础模型通过知识蒸馏技术融合至ConvNeXt-tiny架构。基于AMI相机系统采集的101种丹麦蛾类实验表明：BioCLIP2显著优于其他方法，且经蒸馏的轻量化模型在显著降低计算成本的同时保持了相当的准确度。这些发现为开发高效昆虫监测系统、弥合细粒度分类中的域差异提供了实用指导。 |
| AudioStory：利用大型语言模型生成长篇叙事音频

（注：翻译严格遵循了以下原则：
1. 保留专业术语"Large Language Models"的标准译法"大型语言模型"
2. 准确传达"Generating"的技术含义"生成"
3. 将"Narrative Audio"专业表述为"叙事音频"
4. 采用冒号分隔的主副标题结构，符合中文学术标题规范
5. 保持原标题的学术严谨性和技术准确性） | Yuxin Guo | [PDF](http://arxiv.org/pdf/2508.20088v1) | 近年来，文本到音频（TTA）生成技术虽然在合成短音频片段方面取得显著进展，但在生成长篇叙事音频时仍面临挑战——这类生成需要保持时间连贯性与组合推理能力。为弥补这一不足，我们提出AudioStory：一个将大语言模型（LLM）与TTA系统相融合的统一框架，用于生成结构化的长篇音频叙事。AudioStory具备强大的指令跟随与推理生成能力，通过LLM将复杂叙事查询分解为具有上下文提示的时间有序子任务，从而实现连贯的场景转换与情感基调一致性。

该框架具有两大突出特性：（1）解耦式桥接机制：将LLM与扩散模型的协作解耦为两个专用组件——通过桥接查询实现事件内语义对齐，通过残差查询保持事件间连贯性；（2）端到端训练：通过将指令理解与音频生成统一在单一端到端框架内，AudioStory无需模块化训练流程即可增强组件间的协同效应。此外，我们构建了包含动画音景与自然声叙事等多领域的基准数据集AudioStory-10K。大量实验表明，AudioStory在单音频生成和叙事音频生成任务上均优于现有TTA基线模型，在指令跟随能力和音频保真度方面表现卓越。代码已开源：https://github.com/TencentARC/AudioStory。 |
| 通过隐蔽检索器投毒在检索增强生成中禁用自我校正机制

（注：该翻译严格遵循学术术语规范：
1. "Disabling Self-Correction" 译为"禁用自我校正机制"，保留技术概念完整性
2. "Retrieval-Augmented Generation" 采用学界通用译法"检索增强生成"
3. "Stealthy Retriever Poisoning" 译为"隐蔽检索器投毒"，准确传达对抗性攻击特征
4. 介词"via"转化为"通过...在...中"的句式结构，符合中文论文标题表达习惯） | Yanbo Dai | [PDF](http://arxiv.org/pdf/2508.20083v1) | Retrieval-Augmented Generation (RAG) has become a standard approach for
improving the reliability of [翻译失败] |
| Seam360GS：基于真实世界全景图像的无缝360°高斯溅射建模

（注：翻译说明：
1. 保留技术术语"Gaussian Splatting"的专业译法"高斯溅射"，这是计算机图形学中基于高斯核的渲染技术标准译法
2. "Seamless"译为"无缝"准确体现该技术消除拼接痕迹的核心特性
3. "Omnidirectional Images"采用行业通用译法"全景图像"
4. 通过添加"基于"和"建模"使技术描述更符合中文科技文献表达习惯
5. 完整保留英文原名Seam360GS便于学术检索） | Changha Shin | [PDF](http://arxiv.org/pdf/2508.20080v1) | 360度视觉内容在YouTube等平台上被广泛分享，并在虚拟现实、机器人技术和自主导航中扮演核心角色。然而，消费级双鱼眼系统因固有的镜头间距和角度畸变问题，始终难以生成完美的全景图像。本研究提出了一种新颖的校准框架，将双鱼眼相机模型整合到3D高斯溅射管道中。我们的方法不仅能模拟双鱼眼相机产生的真实视觉伪影，还能实现无缝渲染的360度图像合成。通过联合优化3D高斯参数与模拟镜头间隙和角度畸变的校准变量，本框架可将不完美的全向输入转换为无瑕疵的新视角合成。在真实数据集上的大量实验证实，我们的方法即使处理不完美图像也能生成无缝渲染结果，其性能优于现有360度渲染模型。 |
| 网络化赌博机中的异常检测 | Xiaotong Cheng | [PDF](http://arxiv.org/pdf/2508.20076v1) | 社交网络中节点的相互连接通常反映其依赖关系与信息共享行为。然而，在模式或行为方面显著偏离网络大多数节点的异常节点可能引发严重后果。因此，必须设计高效的在线学习算法，在稳健学习用户偏好的同时实现异常检测。

我们提出了一种新颖的赌博机算法来解决该问题。该方法通过网络知识刻画用户偏好与特征信息残差，通过学习和分析这些偏好与残差，为每个用户制定个性化推荐策略并同步检测异常节点。我们严格证明了所提出算法的遗憾上界，并在合成数据集和真实数据集上将其与多种最先进的协作上下文赌博机算法进行了实验对比。 |
| 离散扩散VLA：将离散扩散引入视觉-语言-动作策略中的动作解码

（注：VLA是Vision-Language-Action的缩写，在学术语境中保留英文缩写形式更为规范。译文采用"离散扩散"对应"Discrete Diffusion"，"动作解码"对应"Action Decoding"，完整呈现了原技术名称的核心要素。标题结构保持了原文的技术准确性，同时符合中文科技文献的命名习惯。） | Zhixuan Liang | [PDF](http://arxiv.org/pdf/2508.20072v1) | 视觉-语言-动作（VLA）模型通过适配大型视觉-语言主干网络，将图像与指令映射为机器人动作。然而，当前主流VLA解码器要么采用固定左到右顺序的自回归动作生成方式，要么在主干网络外接续连续扩散或流匹配头，这种设计不仅需要专门训练和迭代采样，还阻碍了统一可扩展架构的实现。我们提出离散扩散VLA——一种采用单一Transformer结构的策略，通过离散扩散对离散化动作块进行建模，并与VLM主干网络使用相同的交叉熵目标进行训练。该设计既保留了扩散模型的渐进优化范式，又天然兼容VLM的离散令牌接口。我们的方法实现了自适应解码顺序：先解析简单动作元素再处理复杂元素，并通过二次重掩码技术在多轮优化中重新评估不确定预测，从而提升一致性并实现强健的误差修正。这种统一解码器保留了预训练视觉语言先验知识，支持并行解码，突破自回归瓶颈，并减少函数评估次数。离散扩散VLA在LIBERO上达到96.3%平均成功率，在SimplerEnv Fractal实现71.2%视觉匹配率，在SimplerEnv Bridge总体达到49.3%性能，全面超越自回归和连续扩散基线方法。这些发现表明，离散扩散动作解码器能支持精确的动作建模和一致性训练，为VLA向更大模型和数据集扩展奠定了基础。 |
| 11Plus-Bench：通过认知启发式分析揭示多模态大语言模型空间推理机制

（注：翻译采用学术规范处理：
1. 保留"11Plus-Bench"专业测试集名称不译
2. "Demystifying"译为"揭示...机制"体现研究深度
3. "Cognitive-Inspired Analysis"译为"认知启发式分析"符合心理学专业术语
4. 整体采用"通过...揭示..."句式保持学术严谨性
5. "Multimodal LLM"统一译为"多模态大语言模型"确保术语一致性） | Chengzu Li | [PDF](http://arxiv.org/pdf/2508.20068v1) | 在人类认知过程中，空间推理与感知能力紧密交织，然而这种相互作用的本质在多模态大语言模型（MLLMs）的评估中仍未得到充分探索。尽管近期MLLMs在推理任务上展现出令人瞩目的性能，但其类人空间认知能力仍存在疑问。本研究引入系统性评估框架，以最先进MLLMs相对于人类表现的空间推理能力为评估目标。我们工作的核心是11Plus-Bench——一个源自真实标准化空间能力测试的高质量基准。该基准同时具备感知复杂性和推理过程的细粒度专家标注，支持对模型行为进行实例级深度分析。通过对14个MLLMs的广泛实验及人类评估，我们发现当前MLLMs已显现出空间认知的早期特征。尽管与人类存在显著性能差距，但MLLMs的认知特征与人类存在相似性：认知努力程度与推理相关复杂度呈现强相关性。然而MLLMs的实例级表现仍具有较大随机性，而人类正确率则具有高度可预测性且受抽象模式复杂度影响。这些发现既揭示了当前MLLMs空间推理能力的新兴特征与局限，也为推进模型设计提供了可操作的见解。 |
| 保罗：噪声对应下鲁棒跨视角地理定位的不确定性引导分区与增强方法

（注：翻译要点说明：
1. 保留专有名词"PAUL"音译为"保罗"
2. "Uncertainty-Guided"译为"不确定性引导"，准确传达通过不确定性进行指导的技术内涵
3. "Partition and Augmentation"译为"分区与增强"，保持计算机视觉领域的术语规范
4. "Robust Cross-View Geo-Localization"译为"鲁棒跨视角地理定位"，其中：
   - "Robust"采用计算机领域惯用译法"鲁棒"
   - "Cross-View"译为"跨视角"符合遥感地理定位领域术语
   - "Geo-Localization"统一译为"地理定位"
5. "Noisy Correspondence"译为"噪声对应"，准确表达存在噪声数据的对应关系问题
6. 整体采用学术论文标题的简洁表达风格，同时完整保留技术术语的准确性） | Zheng Li | [PDF](http://arxiv.org/pdf/2508.20066v1) | 跨视角地理定位是无人机导航、事件检测与航空测绘的关键任务，其核心在于实现无人机捕获图像与卫星影像的匹配。现有方法大多将多模态数据嵌入联合特征空间以最大化配对图像的相似性，但这些方法通常假设训练期间图像对完美对齐，这与现实场景严重不符。实践中，城市峡谷效应、电磁干扰及恶劣天气等因素常引发GPS漂移，导致系统性的对齐偏移——图像对间仅存在部分对应关系。尽管该噪声对应问题普遍存在，当前研究却鲜有关注。本文正式提出并解决跨视角地理定位中的噪声对应问题（NC-CVGL），旨在弥合理想化基准与实际应用之间的差距。为此，我们提出PAUL（基于不确定性学习的分区与增强）框架，通过不确定性感知协同增强与证据协同训练，依据估计的数据不确定性对训练数据进行分区和增强。具体而言，PAUL选择性增强具有高对应置信度的区域，并利用不确定性估计优化特征学习，有效抑制错位配对产生的噪声。与传统过滤或标签校正方法不同，PAUL同时利用数据不确定性和损失差异进行靶向分区与增强，从而为含噪声样本提供鲁棒监督。综合实验验证了PAUL各模块的有效性，其在多种噪声比例下均持续优于其他具有竞争力的噪声对应驱动方法。 |
